---
title: Latest 15 Papers - August 13, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](http://arxiv.org/abs/2508.08127v1)** | 2025-08-11 |  |
| **[Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](http://arxiv.org/abs/2508.08096v1)** | 2025-08-11 | <details><summary>Prepr...</summary><p>Preprint as provided by the authors (19 pages, 12 figures, 9 tables)</p></details> |
| **[Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks](http://arxiv.org/abs/2508.08029v1)** | 2025-08-11 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v3)** | 2025-08-11 |  |
| **[Can You Trick the Grader? Adversarial Persuasion of LLM Judges](http://arxiv.org/abs/2508.07805v1)** | 2025-08-11 | 19 pages, 8 figures |
| **[POEX: Towards Policy Executable Jailbreak Attacks Against the LLM-based Robots](http://arxiv.org/abs/2412.16633v3)** | 2025-08-11 | <details><summary>Homep...</summary><p>Homepage: https://poex-jailbreak.github.io/</p></details> |
| **[Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation](http://arxiv.org/abs/2508.07745v1)** | 2025-08-11 | 23 pages |
| **[Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](http://arxiv.org/abs/2508.06913v1)** | 2025-08-09 |  |
| **[Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](http://arxiv.org/abs/2508.06601v1)** | 2025-08-08 | <details><summary>https...</summary><p>https://deepignorance.ai/</p></details> |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v1)** | 2025-08-08 | v0.1 |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](http://arxiv.org/abs/2508.08127v1)** | 2025-08-11 |  |
| **[Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](http://arxiv.org/abs/2508.08096v1)** | 2025-08-11 | <details><summary>Prepr...</summary><p>Preprint as provided by the authors (19 pages, 12 figures, 9 tables)</p></details> |
| **[Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks](http://arxiv.org/abs/2508.08029v1)** | 2025-08-11 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v3)** | 2025-08-11 |  |
| **[Can You Trick the Grader? Adversarial Persuasion of LLM Judges](http://arxiv.org/abs/2508.07805v1)** | 2025-08-11 | 19 pages, 8 figures |
| **[POEX: Towards Policy Executable Jailbreak Attacks Against the LLM-based Robots](http://arxiv.org/abs/2412.16633v3)** | 2025-08-11 | <details><summary>Homep...</summary><p>Homepage: https://poex-jailbreak.github.io/</p></details> |
| **[Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation](http://arxiv.org/abs/2508.07745v1)** | 2025-08-11 | 23 pages |
| **[Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](http://arxiv.org/abs/2508.06913v1)** | 2025-08-09 |  |
| **[Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](http://arxiv.org/abs/2508.06601v1)** | 2025-08-08 | <details><summary>https...</summary><p>https://deepignorance.ai/</p></details> |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v1)** | 2025-08-08 | v0.1 |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](http://arxiv.org/abs/2508.08040v1)** | 2025-08-11 |  |
| **[Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense](http://arxiv.org/abs/2412.21051v3)** | 2025-08-11 | <details><summary>7 pag...</summary><p>7 pages; Major Revision for IEEE Communications Magazine</p></details> |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v3)** | 2025-08-11 |  |
| **[Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards](http://arxiv.org/abs/2508.05658v2)** | 2025-08-11 | <details><summary>This ...</summary><p>This paper has been accepted by ACM MM 2025</p></details> |
| **[FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](http://arxiv.org/abs/2501.15509v4)** | 2025-08-11 |  |
| **[Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017](http://arxiv.org/abs/2506.19877v2)** | 2025-08-11 | <details><summary>submi...</summary><p>submitted to IEEE CNS 2025</p></details> |
| **[Multimodal Deception in Explainable AI: Concept-Level Backdoor Attacks on Concept Bottleneck Models](http://arxiv.org/abs/2410.04823v2)** | 2025-08-10 |  |
| **[Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](http://arxiv.org/abs/2508.07173v1)** | 2025-08-10 | <details><summary>20 pa...</summary><p>20 pages, 8 figures, 12 tables</p></details> |
| **[Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models](http://arxiv.org/abs/2508.07115v1)** | 2025-08-09 |  |
| **[Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](http://arxiv.org/abs/2508.06913v1)** | 2025-08-09 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](http://arxiv.org/abs/2508.08040v1)** | 2025-08-11 |  |
| **[Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense](http://arxiv.org/abs/2412.21051v3)** | 2025-08-11 | <details><summary>7 pag...</summary><p>7 pages; Major Revision for IEEE Communications Magazine</p></details> |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v3)** | 2025-08-11 |  |
| **[Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards](http://arxiv.org/abs/2508.05658v2)** | 2025-08-11 | <details><summary>This ...</summary><p>This paper has been accepted by ACM MM 2025</p></details> |
| **[FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](http://arxiv.org/abs/2501.15509v4)** | 2025-08-11 |  |
| **[Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017](http://arxiv.org/abs/2506.19877v2)** | 2025-08-11 | <details><summary>submi...</summary><p>submitted to IEEE CNS 2025</p></details> |
| **[Multimodal Deception in Explainable AI: Concept-Level Backdoor Attacks on Concept Bottleneck Models](http://arxiv.org/abs/2410.04823v2)** | 2025-08-10 |  |
| **[Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](http://arxiv.org/abs/2508.07173v1)** | 2025-08-10 | <details><summary>20 pa...</summary><p>20 pages, 8 figures, 12 tables</p></details> |
| **[Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models](http://arxiv.org/abs/2508.07115v1)** | 2025-08-09 |  |
| **[Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](http://arxiv.org/abs/2508.06913v1)** | 2025-08-09 |  |

