---
title: Latest 15 Papers - February 25, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BarrierSteer: LLM Safety via Learning Barrier Steering](https://arxiv.org/abs/2602.20102v1)** | 2026-02-23 | <details><summary>This ...</summary><p>This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs</p></details> |
| **[AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs](https://arxiv.org/abs/2509.06326v2)** | 2026-02-23 | accept to DAC 2026 |
| **[LLM-enabled Applications Require System-Level Threat Monitoring](https://arxiv.org/abs/2602.19844v1)** | 2026-02-23 | 26 pages |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](https://arxiv.org/abs/2510.10987v3)** | 2026-02-23 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 (Oral)</p></details> |
| **[SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891v2)** | 2026-02-22 | ICLR 2026 |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |
| **[MANATEE: Inference-Time Lightweight Diffusion Based Safety Defense for LLMs](https://arxiv.org/abs/2602.18782v1)** | 2026-02-21 |  |
| **[Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092v1)** | 2026-02-20 | 39 pages, 10 figures |
| **[Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778v1)** | 2026-02-19 | Pre-print |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BarrierSteer: LLM Safety via Learning Barrier Steering](https://arxiv.org/abs/2602.20102v1)** | 2026-02-23 | <details><summary>This ...</summary><p>This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs</p></details> |
| **[AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs](https://arxiv.org/abs/2509.06326v2)** | 2026-02-23 | accept to DAC 2026 |
| **[LLM-enabled Applications Require System-Level Threat Monitoring](https://arxiv.org/abs/2602.19844v1)** | 2026-02-23 | 26 pages |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](https://arxiv.org/abs/2510.10987v3)** | 2026-02-23 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 (Oral)</p></details> |
| **[SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891v2)** | 2026-02-22 | ICLR 2026 |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |
| **[MANATEE: Inference-Time Lightweight Diffusion Based Safety Defense for LLMs](https://arxiv.org/abs/2602.18782v1)** | 2026-02-21 |  |
| **[Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092v1)** | 2026-02-20 | 39 pages, 10 figures |
| **[Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778v1)** | 2026-02-19 | Pre-print |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models](https://arxiv.org/abs/2602.19818v1)** | 2026-02-23 |  |
| **[Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing](https://arxiv.org/abs/2506.01783v2)** | 2026-02-23 | Accepted to CVPR2026 |
| **[Sampling-aware Adversarial Attacks Against Large Language Models](https://arxiv.org/abs/2507.04446v4)** | 2026-02-22 |  |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](https://arxiv.org/abs/2505.16789v3)** | 2026-02-22 | <details><summary>Secon...</summary><p>Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI 2026)</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v2)** | 2026-02-22 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |
| **[Learning to Detect Language Model Training Data via Active Reconstruction](https://arxiv.org/abs/2602.19020v1)** | 2026-02-22 |  |
| **[LoMime: Query-Efficient Membership Inference using Model Extraction in Label-Only Settings](https://arxiv.org/abs/2602.18934v1)** | 2026-02-21 |  |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](https://arxiv.org/abs/2505.16670v4)** | 2026-02-21 |  |
| **[When World Models Dream Wrong: Physical-Conditioned Adversarial Attacks against World Models](https://arxiv.org/abs/2602.18739v1)** | 2026-02-21 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models](https://arxiv.org/abs/2602.19818v1)** | 2026-02-23 |  |
| **[Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing](https://arxiv.org/abs/2506.01783v2)** | 2026-02-23 | Accepted to CVPR2026 |
| **[Sampling-aware Adversarial Attacks Against Large Language Models](https://arxiv.org/abs/2507.04446v4)** | 2026-02-22 |  |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](https://arxiv.org/abs/2505.16789v3)** | 2026-02-22 | <details><summary>Secon...</summary><p>Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI 2026)</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v2)** | 2026-02-22 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |
| **[Learning to Detect Language Model Training Data via Active Reconstruction](https://arxiv.org/abs/2602.19020v1)** | 2026-02-22 |  |
| **[LoMime: Query-Efficient Membership Inference using Model Extraction in Label-Only Settings](https://arxiv.org/abs/2602.18934v1)** | 2026-02-21 |  |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](https://arxiv.org/abs/2505.16670v4)** | 2026-02-21 |  |
| **[When World Models Dream Wrong: Physical-Conditioned Adversarial Attacks against World Models](https://arxiv.org/abs/2602.18739v1)** | 2026-02-21 |  |

