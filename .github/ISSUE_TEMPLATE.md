---
title: Latest 15 Papers - April 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](http://arxiv.org/abs/2504.06575v2)** | 2025-04-10 |  |
| **[LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks](http://arxiv.org/abs/2410.02916v3)** | 2025-04-09 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v2)** | 2025-04-09 |  |
| **[StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](http://arxiv.org/abs/2504.05804v1)** | 2025-04-08 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v1)** | 2025-04-08 |  |
| **[ShadowCoT: Cognitive Hijacking for Stealthy Reasoning Backdoors in LLMs](http://arxiv.org/abs/2504.05605v1)** | 2025-04-08 | <details><summary>Zhao ...</summary><p>Zhao et al., 16 pages, 2025, uploaded by Hanzhou Wu, Shanghai University</p></details> |
| **[How to evaluate control measures for LLM agents? A trajectory from today to superintelligence](http://arxiv.org/abs/2504.05259v1)** | 2025-04-07 |  |
| **[SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection](http://arxiv.org/abs/2504.07135v1)** | 2025-04-07 |  |
| **[Safety Layers in Aligned Large Language Models: The Key to LLM Security](http://arxiv.org/abs/2408.17003v5)** | 2025-04-07 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025. The code is available at https://github.com/listen0425/Safety-Layers</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](http://arxiv.org/abs/2504.06575v2)** | 2025-04-10 |  |
| **[AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment](http://arxiv.org/abs/2410.11283v2)** | 2025-04-09 | <details><summary>Publi...</summary><p>Published at the Neurips Safe Generative AI Workshop 2024</p></details> |
| **[LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks](http://arxiv.org/abs/2410.02916v3)** | 2025-04-09 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v2)** | 2025-04-09 |  |
| **[StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](http://arxiv.org/abs/2504.05804v1)** | 2025-04-08 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v1)** | 2025-04-08 |  |
| **[ShadowCoT: Cognitive Hijacking for Stealthy Reasoning Backdoors in LLMs](http://arxiv.org/abs/2504.05605v1)** | 2025-04-08 | <details><summary>Zhao ...</summary><p>Zhao et al., 16 pages, 2025, uploaded by Hanzhou Wu, Shanghai University</p></details> |
| **[How to evaluate control measures for LLM agents? A trajectory from today to superintelligence](http://arxiv.org/abs/2504.05259v1)** | 2025-04-07 |  |
| **[SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection](http://arxiv.org/abs/2504.07135v1)** | 2025-04-07 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v2)** | 2025-04-10 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Code Generation with Small Language Models: A Deep Evaluation on Codeforces](http://arxiv.org/abs/2504.07343v1)** | 2025-04-09 |  |
| **[Privacy Attacks on Image AutoRegressive Models](http://arxiv.org/abs/2502.02514v3)** | 2025-04-09 | <details><summary>Code:...</summary><p>Code: https://github.com/sprintml/privacy_attacks_against_iars</p></details> |
| **[JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](http://arxiv.org/abs/2504.03770v2)** | 2025-04-08 |  |
| **[Model Inversion Attack against Federated Unlearning](http://arxiv.org/abs/2502.14558v3)** | 2025-04-08 |  |
| **[Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models](http://arxiv.org/abs/2504.05815v1)** | 2025-04-08 |  |
| **[Separator Injection Attack: Uncovering Dialogue Biases in Large Language Models Caused by Role Separators](http://arxiv.org/abs/2504.05689v1)** | 2025-04-08 |  |
| **[Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing](http://arxiv.org/abs/2504.05657v1)** | 2025-04-08 | <details><summary>This ...</summary><p>This manuscript has been submitted for peer review</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v2)** | 2025-04-10 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Code Generation with Small Language Models: A Deep Evaluation on Codeforces](http://arxiv.org/abs/2504.07343v1)** | 2025-04-09 |  |
| **[Privacy Attacks on Image AutoRegressive Models](http://arxiv.org/abs/2502.02514v3)** | 2025-04-09 | <details><summary>Code:...</summary><p>Code: https://github.com/sprintml/privacy_attacks_against_iars</p></details> |
| **[JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](http://arxiv.org/abs/2504.03770v2)** | 2025-04-08 |  |
| **[Model Inversion Attack against Federated Unlearning](http://arxiv.org/abs/2502.14558v3)** | 2025-04-08 |  |
| **[Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models](http://arxiv.org/abs/2504.05815v1)** | 2025-04-08 |  |
| **[Separator Injection Attack: Uncovering Dialogue Biases in Large Language Models Caused by Role Separators](http://arxiv.org/abs/2504.05689v1)** | 2025-04-08 |  |
| **[Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing](http://arxiv.org/abs/2504.05657v1)** | 2025-04-08 | <details><summary>This ...</summary><p>This manuscript has been submitted for peer review</p></details> |

