---
title: Latest 15 Papers - June 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v1)** | 2025-06-18 |  |
| **[MAD-MAX: Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming](http://arxiv.org/abs/2503.06253v2)** | 2025-06-18 | <details><summary>Data ...</summary><p>Data in Generative Models Workshop: The Bad, the Ugly, and the Greats (DIG-BUGS) at ICML 2025</p></details> |
| **[RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](http://arxiv.org/abs/2506.15253v1)** | 2025-06-18 | 12 pages, 8 figures |
| **[From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](http://arxiv.org/abs/2506.15170v1)** | 2025-06-18 |  |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v6)** | 2025-06-18 |  |
| **[IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2505.12442v3)** | 2025-06-17 |  |
| **[Excessive Reasoning Attack on Reasoning LLMs](http://arxiv.org/abs/2506.14374v1)** | 2025-06-17 |  |
| **[LLM-Powered Intent-Based Categorization of Phishing Emails](http://arxiv.org/abs/2506.14337v1)** | 2025-06-17 |  |
| **[Mind the Inconspicuous: Revealing the Hidden Weakness in Aligned LLMs' Refusal Boundaries](http://arxiv.org/abs/2405.20653v3)** | 2025-06-17 | <details><summary>publi...</summary><p>published at USENIX Security 25</p></details> |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v2)** | 2025-06-16 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v1)** | 2025-06-18 |  |
| **[MAD-MAX: Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming](http://arxiv.org/abs/2503.06253v2)** | 2025-06-18 | <details><summary>Data ...</summary><p>Data in Generative Models Workshop: The Bad, the Ugly, and the Greats (DIG-BUGS) at ICML 2025</p></details> |
| **[RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](http://arxiv.org/abs/2506.15253v1)** | 2025-06-18 | 12 pages, 8 figures |
| **[From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](http://arxiv.org/abs/2506.15170v1)** | 2025-06-18 |  |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v6)** | 2025-06-18 |  |
| **[IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2505.12442v3)** | 2025-06-17 |  |
| **[Excessive Reasoning Attack on Reasoning LLMs](http://arxiv.org/abs/2506.14374v1)** | 2025-06-17 |  |
| **[LLM-Powered Intent-Based Categorization of Phishing Emails](http://arxiv.org/abs/2506.14337v1)** | 2025-06-17 |  |
| **[Mind the Inconspicuous: Revealing the Hidden Weakness in Aligned LLMs' Refusal Boundaries](http://arxiv.org/abs/2405.20653v3)** | 2025-06-17 | <details><summary>publi...</summary><p>published at USENIX Security 25</p></details> |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v2)** | 2025-06-16 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](http://arxiv.org/abs/2506.15674v1)** | 2025-06-18 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v5)** | 2025-06-18 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Jailbreak Large Vision-Language Models Through Multi-Modal Linkage](http://arxiv.org/abs/2412.00473v5)** | 2025-06-18 |  |
| **[RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?](http://arxiv.org/abs/2506.14261v2)** | 2025-06-18 |  |
| **[PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](http://arxiv.org/abs/2506.15112v1)** | 2025-06-18 |  |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v6)** | 2025-06-18 |  |
| **[Narrowing the Gap between TEEs Threat Model and Deployment Strategies](http://arxiv.org/abs/2506.14964v1)** | 2025-06-17 |  |
| **[Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](http://arxiv.org/abs/2506.14919v1)** | 2025-06-17 |  |
| **[Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](http://arxiv.org/abs/2506.14913v1)** | 2025-06-17 | 18 pages, 12 figures |
| **[AIRTBench: Measuring Autonomous AI Red Teaming Capabilities in Language Models](http://arxiv.org/abs/2506.14682v1)** | 2025-06-17 | <details><summary>43 pa...</summary><p>43 pages, 13 figures, 16 tables</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](http://arxiv.org/abs/2506.15674v1)** | 2025-06-18 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v5)** | 2025-06-18 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Jailbreak Large Vision-Language Models Through Multi-Modal Linkage](http://arxiv.org/abs/2412.00473v5)** | 2025-06-18 |  |
| **[RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?](http://arxiv.org/abs/2506.14261v2)** | 2025-06-18 |  |
| **[PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning](http://arxiv.org/abs/2506.15112v1)** | 2025-06-18 |  |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v6)** | 2025-06-18 |  |
| **[Narrowing the Gap between TEEs Threat Model and Deployment Strategies](http://arxiv.org/abs/2506.14964v1)** | 2025-06-17 |  |
| **[Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models](http://arxiv.org/abs/2506.14919v1)** | 2025-06-17 |  |
| **[Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning](http://arxiv.org/abs/2506.14913v1)** | 2025-06-17 | 18 pages, 12 figures |
| **[AIRTBench: Measuring Autonomous AI Red Teaming Capabilities in Language Models](http://arxiv.org/abs/2506.14682v1)** | 2025-06-17 | <details><summary>43 pa...</summary><p>43 pages, 13 figures, 16 tables</p></details> |

