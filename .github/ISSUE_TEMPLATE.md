---
title: Latest 15 Papers - November 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning](https://arxiv.org/abs/2509.11816v2)** | 2025-11-13 |  |
| **[Speech-Audio Compositional Attacks on Multimodal LLMs and Their Mitigation with SALMONN-Guard](https://arxiv.org/abs/2511.10222v1)** | 2025-11-13 |  |
| **[Unlearning Imperative: Securing Trustworthy and Responsible LLMs through Engineered Forgetting](https://arxiv.org/abs/2511.09855v1)** | 2025-11-13 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, 4 tables</p></details> |
| **[From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289v3)** | 2025-11-13 |  |
| **[Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation](https://arxiv.org/abs/2501.18638v3)** | 2025-11-12 | <details><summary>14 pa...</summary><p>14 pages, 5 figures; published in EMNLP 2025 ; Code at: https://github.com/dsbuddy/GAP-LLM-Safety</p></details> |
| **[MCP-RiskCue: Can LLM Infer Risk Information From MCP Server System Logs?](https://arxiv.org/abs/2511.05867v2)** | 2025-11-12 |  |
| **[Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment](https://arxiv.org/abs/2511.09105v1)** | 2025-11-12 | <details><summary>accep...</summary><p>accepted for AAAI 2026 Special Track on AI Alignment</p></details> |
| **[iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905v1)** | 2025-11-12 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](https://arxiv.org/abs/2503.01908v3)** | 2025-11-12 |  |
| **[Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives](https://arxiv.org/abs/2511.06626v2)** | 2025-11-11 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning](https://arxiv.org/abs/2509.11816v2)** | 2025-11-13 |  |
| **[Speech-Audio Compositional Attacks on Multimodal LLMs and Their Mitigation with SALMONN-Guard](https://arxiv.org/abs/2511.10222v1)** | 2025-11-13 |  |
| **[Unlearning Imperative: Securing Trustworthy and Responsible LLMs through Engineered Forgetting](https://arxiv.org/abs/2511.09855v1)** | 2025-11-13 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, 4 tables</p></details> |
| **[From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289v3)** | 2025-11-13 |  |
| **[Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation](https://arxiv.org/abs/2501.18638v3)** | 2025-11-12 | <details><summary>14 pa...</summary><p>14 pages, 5 figures; published in EMNLP 2025 ; Code at: https://github.com/dsbuddy/GAP-LLM-Safety</p></details> |
| **[MCP-RiskCue: Can LLM Infer Risk Information From MCP Server System Logs?](https://arxiv.org/abs/2511.05867v2)** | 2025-11-12 |  |
| **[Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment](https://arxiv.org/abs/2511.09105v1)** | 2025-11-12 | <details><summary>accep...</summary><p>accepted for AAAI 2026 Special Track on AI Alignment</p></details> |
| **[iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905v1)** | 2025-11-12 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](https://arxiv.org/abs/2503.01908v3)** | 2025-11-12 |  |
| **[Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives](https://arxiv.org/abs/2511.06626v2)** | 2025-11-11 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v2)** | 2025-11-13 |  |
| **[On Stealing Graph Neural Network Models](https://arxiv.org/abs/2511.07170v2)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted at AAAI 2026</p></details> |
| **[Enhanced Privacy Leakage from Noise-Perturbed Gradients via Gradient-Guided Conditional Diffusion Models](https://arxiv.org/abs/2511.10423v1)** | 2025-11-13 |  |
| **[MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models](https://arxiv.org/abs/2511.10098v1)** | 2025-11-13 | <details><summary>AAAI2...</summary><p>AAAI2026, with supplementary material</p></details> |
| **[Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Backdoor Attacks Against Speech Language Models](https://arxiv.org/abs/2510.01157v2)** | 2025-11-13 |  |
| **[EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted by IEEE Symposium on Security and Privacy (S&P) 2026</p></details> |
| **[Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations](https://arxiv.org/abs/2511.09749v1)** | 2025-11-12 |  |
| **[Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682v1)** | 2025-11-12 |  |
| **[RFNNS: Robust Fixed Neural Network Steganography with Universal Text-to-Image Models](https://arxiv.org/abs/2505.04116v2)** | 2025-11-12 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v2)** | 2025-11-13 |  |
| **[On Stealing Graph Neural Network Models](https://arxiv.org/abs/2511.07170v2)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted at AAAI 2026</p></details> |
| **[Enhanced Privacy Leakage from Noise-Perturbed Gradients via Gradient-Guided Conditional Diffusion Models](https://arxiv.org/abs/2511.10423v1)** | 2025-11-13 |  |
| **[MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models](https://arxiv.org/abs/2511.10098v1)** | 2025-11-13 | <details><summary>AAAI2...</summary><p>AAAI2026, with supplementary material</p></details> |
| **[Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Backdoor Attacks Against Speech Language Models](https://arxiv.org/abs/2510.01157v2)** | 2025-11-13 |  |
| **[EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted by IEEE Symposium on Security and Privacy (S&P) 2026</p></details> |
| **[Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations](https://arxiv.org/abs/2511.09749v1)** | 2025-11-12 |  |
| **[Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682v1)** | 2025-11-12 |  |
| **[RFNNS: Robust Fixed Neural Network Steganography with Universal Text-to-Image Models](https://arxiv.org/abs/2505.04116v2)** | 2025-11-12 |  |

