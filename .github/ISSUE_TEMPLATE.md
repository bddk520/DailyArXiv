---
title: Latest 15 Papers - November 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs](https://arxiv.org/pdf/2404.07242v1)** | 2024-10-22 |  |
| **[Goal-Oriented Prompt Attack and Safety Evaluation for LLMs](https://arxiv.org/pdf/2309.11830v2)** | 2023-12-11 |  |
| **[Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM](https://arxiv.org/pdf/2405.05610v1)** | 2024-05-10 |  |
| **[Adaptive Attacks Break Defenses Against Indirect Prompt Injection Attacks on LLM Agents](https://arxiv.org/pdf/2503.00061v2)** | 2025-03-05 | <details><summary>17 pa...</summary><p>17 pages, 5 figures, 6 tables (NAACL 2025 Findings)</p></details> |
| **[FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs](https://arxiv.org/pdf/2403.13507v2)** | 2024-03-22 |  |
| **[An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks](https://arxiv.org/pdf/2511.02356v1)** | 2025-11-05 |  |
| **[COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability](https://arxiv.org/pdf/2402.08679v2)** | 2024-06-10 | <details><summary>Accep...</summary><p>Accepted to ICML 2024</p></details> |
| **[Model Leeching: An Extraction Attack Targeting LLMs](https://arxiv.org/pdf/2309.10544v1)** | 2023-09-20 |  |
| **[RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework](https://arxiv.org/pdf/2511.06212v1)** | 2025-11-11 |  |
| **[An LLM can Fool Itself: A Prompt-Based Adversarial Attack](https://arxiv.org/pdf/2310.13345v1)** | 2023-10-23 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents](https://arxiv.org/pdf/2402.11208v2)** | 2024-10-30 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2024, camera ready version. Code and data are available at https://github.com/lancopku/agent-backdoor-attacks</p></details> |
| **[Instruction Backdoor Attacks Against Customized LLMs](https://arxiv.org/pdf/2402.09179v3)** | 2024-05-29 |  |
| **[Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems](https://arxiv.org/pdf/2510.11246v1)** | 2025-10-14 |  |
| **[DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent](https://arxiv.org/pdf/2502.12575v2)** | 2025-10-14 |  |
| **[Breaking PEFT Limitations: Leveraging Weak-to-Strong Knowledge Transfer for Backdoor Attacks in LLMs](https://arxiv.org/pdf/2409.17946v4)** | 2025-07-10 |  |
| **[Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation](https://arxiv.org/pdf/2410.14425v2)** | 2025-05-21 |  |
| **[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](https://arxiv.org/pdf/2504.11182v1)** | 2025-04-16 |  |
| **[TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning](https://arxiv.org/pdf/2404.19597v3)** | 2025-03-18 | work in progress |
| **[BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://arxiv.org/pdf/2406.03007v1)** | 2024-06-06 | Accepted by ACL 2024 |
| **[When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations](https://arxiv.org/pdf/2411.12701v3)** | 2025-02-18 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Attack-SAM: Towards Attacking Segment Anything Model With Adversarial Examples](https://arxiv.org/pdf/2305.00866v2)** | 2023-05-09 | <details><summary>The f...</summary><p>The first work to attack Segment Anything Model with adversarial examples</p></details> |
| **[Adversarial Attack Framework on Graph Embedding Models with Limited Knowledge](https://arxiv.org/pdf/2105.12419v2)** | 2022-03-02 | <details><summary>Journ...</summary><p>Journal extension of GF-Attack, accepted by TKDE</p></details> |
| **[Response Attack: Exploiting Contextual Priming to Jailbreak Large Language Models](https://arxiv.org/pdf/2507.05248v1)** | 2025-07-08 | <details><summary>21 pa...</summary><p>21 pages, 9 figures. Code and data available at https://github.com/Dtc7w3PQ/Response-Attack</p></details> |
| **[UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models](https://arxiv.org/pdf/2502.13141v1)** | 2025-02-19 | <details><summary>18 Pa...</summary><p>18 Pages, 8 Figures, 5 Tables, Keywords: Attack Defending, Security, Prompt Injection, Backdoor Attacks, Adversarial Attacks, Prompt Trigger Attacks</p></details> |
| **[Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models](https://arxiv.org/pdf/2002.04784v2)** | 2021-06-24 | <details><summary>IJCAI...</summary><p>IJCAI 2021. Code is available at https://github.com/chisam0217/Graph-Universal-Attack</p></details> |
| **[Modeling and performance evaluation of stealthy false data injection attacks on smart grid in the presence of corrupted measurements](https://arxiv.org/pdf/1605.06180v1)** | 2016-05-23 | <details><summary>Keywo...</summary><p>Keywords: Smart grid, False data injection, Blind attack, Principal component analysis (PCA), Journal of Computer and System Sciences, Elsevier, 2016</p></details> |
| **[The last Dance : Robust backdoor attack via diffusion models and bayesian approach](https://arxiv.org/pdf/2402.05967v7)** | 2025-04-22 | <details><summary>Prepr...</summary><p>Preprint (Last update, will never be modified again( correction of a sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained models. This attack incorporates state-of-the-art Bayesian techniques, a modified Fokker-Planck equation (via Yang-Mills), and a diffusion model approach</p></details> |
| **[A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](https://arxiv.org/pdf/2503.10635v2)** | 2025-10-28 | <details><summary>NeurI...</summary><p>NeurIPS 2025. Code at: https://github.com/VILA-Lab/M-Attack</p></details> |
| **[Sample Attackability in Natural Language Adversarial Attacks](https://arxiv.org/pdf/2306.12043v1)** | 2023-06-26 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2301.12896</p></details> |
| **[Adversary Model: Adaptive Chosen Ciphertext Attack with Timing Attack](https://arxiv.org/pdf/1409.6556v1)** | 2016-07-05 | <details><summary>Exten...</summary><p>Extended paper for 'A Secure TFTP Protocol with Security Proofs', in Lecture Notes in Engineering and Computer Science: Proceedings of The World Congress on Engineering 2014, (WCE 2014), 2014, vol. 1</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models](https://arxiv.org/pdf/2502.13141v1)** | 2025-02-19 | <details><summary>18 Pa...</summary><p>18 Pages, 8 Figures, 5 Tables, Keywords: Attack Defending, Security, Prompt Injection, Backdoor Attacks, Adversarial Attacks, Prompt Trigger Attacks</p></details> |
| **[The last Dance : Robust backdoor attack via diffusion models and bayesian approach](https://arxiv.org/pdf/2402.05967v7)** | 2025-04-22 | <details><summary>Prepr...</summary><p>Preprint (Last update, will never be modified again( correction of a sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained models. This attack incorporates state-of-the-art Bayesian techniques, a modified Fokker-Planck equation (via Yang-Mills), and a diffusion model approach</p></details> |
| **[Exploring Backdoor Vulnerabilities of Chat Models](https://arxiv.org/pdf/2404.02406v1)** | 2024-04-04 | <details><summary>Code ...</summary><p>Code and data are available at https://github.com/hychaochao/Chat-Models-Backdoor-Attacking</p></details> |
| **[Rethink the Evaluation for Attack Strength of Backdoor Attacks in Natural Language Processing](https://arxiv.org/pdf/2201.02993v2)** | 2022-02-17 |  |
| **[Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning](https://arxiv.org/pdf/2404.13946v1)** | 2024-04-23 |  |
| **[Backdoor Attack with Invisible Triggers Based on Model Architecture Modification](https://arxiv.org/pdf/2412.16905v3)** | 2025-09-24 |  |
| **[Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based Artificial Bias](https://arxiv.org/pdf/2303.01504v3)** | 2024-07-02 |  |
| **[Clean-Label Backdoor Attacks on Video Recognition Models](https://arxiv.org/pdf/2003.03030v2)** | 2020-06-17 | CVPR2020 |
| **[Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models](https://arxiv.org/pdf/2504.05815v3)** | 2025-09-12 |  |
| **[BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models](https://arxiv.org/pdf/2010.03007v2)** | 2020-10-09 |  |

