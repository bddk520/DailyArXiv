---
title: Latest 15 Papers - May 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Suffix Filtering: a Defense Pipeline for LLMs](http://arxiv.org/abs/2505.09602v1)** | 2025-05-14 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v2)** | 2025-05-14 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |
| **[ACE: A Security Architecture for LLM-Integrated App Systems](http://arxiv.org/abs/2504.20984v2)** | 2025-05-07 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; clarify relation to indirect prompt injection attacks</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Suffix Filtering: a Defense Pipeline for LLMs](http://arxiv.org/abs/2505.09602v1)** | 2025-05-14 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v2)** | 2025-05-14 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v6)** | 2025-05-12 | <details><summary>40 pa...</summary><p>40 pages, 38 figures An earlier revision of this paper was accepted at ICML 2025. Since then, it has been updated to include new results on training dynamics (4.7) and base models (4.8)</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v2)** | 2025-05-14 | <details><summary>Submi...</summary><p>Submitted for review in January 22, 2025</p></details> |
| **[FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](http://arxiv.org/abs/2505.09415v1)** | 2025-05-14 |  |
| **[Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning](http://arxiv.org/abs/2501.16393v2)** | 2025-05-14 | <details><summary>Accep...</summary><p>Accepted by "Combining AI and OR/MS for Better Trustworthy Decision Making" Bridge Program co-organized by AAAI and INFORMS as poster and demo</p></details> |
| **[Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems](http://arxiv.org/abs/2505.09048v1)** | 2025-05-14 |  |
| **[On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction](http://arxiv.org/abs/2505.08847v1)** | 2025-05-13 |  |
| **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](http://arxiv.org/abs/2504.15026v2)** | 2025-05-13 | 18 pages, 8 figures |
| **[Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem](http://arxiv.org/abs/2403.03593v2)** | 2025-05-13 | 18 pages |
| **[GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models](http://arxiv.org/abs/2501.10985v2)** | 2025-05-13 |  |
| **[LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](http://arxiv.org/abs/2505.08204v1)** | 2025-05-13 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2501.02968v3)** | 2025-05-13 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v2)** | 2025-05-14 | <details><summary>Submi...</summary><p>Submitted for review in January 22, 2025</p></details> |
| **[FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](http://arxiv.org/abs/2505.09415v1)** | 2025-05-14 |  |
| **[Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning](http://arxiv.org/abs/2501.16393v2)** | 2025-05-14 | <details><summary>Accep...</summary><p>Accepted by "Combining AI and OR/MS for Better Trustworthy Decision Making" Bridge Program co-organized by AAAI and INFORMS as poster and demo</p></details> |
| **[Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems](http://arxiv.org/abs/2505.09048v1)** | 2025-05-14 |  |
| **[On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction](http://arxiv.org/abs/2505.08847v1)** | 2025-05-13 |  |
| **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](http://arxiv.org/abs/2504.15026v2)** | 2025-05-13 | 18 pages, 8 figures |
| **[Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem](http://arxiv.org/abs/2403.03593v2)** | 2025-05-13 | 18 pages |
| **[GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models](http://arxiv.org/abs/2501.10985v2)** | 2025-05-13 |  |
| **[LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](http://arxiv.org/abs/2505.08204v1)** | 2025-05-13 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2501.02968v3)** | 2025-05-13 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |

