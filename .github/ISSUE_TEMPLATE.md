---
title: Latest 15 Papers - March 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Foot-In-The-Door: A Multi-turn Jailbreak for LLMs](http://arxiv.org/abs/2502.19820v1)** | 2025-02-27 | 19 pages, 8 figures |
| **[Demystifying RCE Vulnerabilities in LLM-Integrated Apps](http://arxiv.org/abs/2309.02926v4)** | 2025-02-27 |  |
| **[Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](http://arxiv.org/abs/2404.01833v3)** | 2025-02-26 | <details><summary>Accep...</summary><p>Accepted at USENIX Security 2025</p></details> |
| **[Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](http://arxiv.org/abs/2502.19041v1)** | 2025-02-26 | 15 pages, 12 figures |
| **[Investigating Generalization of One-shot LLM Steering Vectors](http://arxiv.org/abs/2502.18862v1)** | 2025-02-26 | <details><summary>20 pa...</summary><p>20 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro</p></details> |
| **[Efficient Safety Retrofitting Against Jailbreaking for LLMs](http://arxiv.org/abs/2502.13603v2)** | 2025-02-25 |  |
| **[Towards Effective Evaluations and Comparisons for LLM Unlearning Methods](http://arxiv.org/abs/2406.09179v2)** | 2025-02-25 |  |
| **[Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM](http://arxiv.org/abs/2502.17763v1)** | 2025-02-25 |  |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v4)** | 2025-02-24 |  |
| **[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](http://arxiv.org/abs/2502.16730v1)** | 2025-02-23 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Foot-In-The-Door: A Multi-turn Jailbreak for LLMs](http://arxiv.org/abs/2502.19820v1)** | 2025-02-27 | 19 pages, 8 figures |
| **[Demystifying RCE Vulnerabilities in LLM-Integrated Apps](http://arxiv.org/abs/2309.02926v4)** | 2025-02-27 |  |
| **[Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](http://arxiv.org/abs/2404.01833v3)** | 2025-02-26 | <details><summary>Accep...</summary><p>Accepted at USENIX Security 2025</p></details> |
| **[Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](http://arxiv.org/abs/2502.19041v1)** | 2025-02-26 | 15 pages, 12 figures |
| **[Investigating Generalization of One-shot LLM Steering Vectors](http://arxiv.org/abs/2502.18862v1)** | 2025-02-26 | <details><summary>20 pa...</summary><p>20 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro</p></details> |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v2)** | 2025-02-25 | 10 pages, 9 figures |
| **[Efficient Safety Retrofitting Against Jailbreaking for LLMs](http://arxiv.org/abs/2502.13603v2)** | 2025-02-25 |  |
| **[Towards Effective Evaluations and Comparisons for LLM Unlearning Methods](http://arxiv.org/abs/2406.09179v2)** | 2025-02-25 |  |
| **[Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM](http://arxiv.org/abs/2502.17763v1)** | 2025-02-25 |  |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v4)** | 2025-02-24 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace](http://arxiv.org/abs/2410.13910v2)** | 2025-02-27 | <details><summary>arxiv...</summary><p>arxiv version of ICLR2025</p></details> |
| **[Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets](http://arxiv.org/abs/2502.20246v1)** | 2025-02-27 |  |
| **[Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models](http://arxiv.org/abs/2502.19883v1)** | 2025-02-27 | 12 pages. 6 figures |
| **[The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1](http://arxiv.org/abs/2502.12659v3)** | 2025-02-27 |  |
| **[Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training](http://arxiv.org/abs/2502.19726v1)** | 2025-02-27 |  |
| **[Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models](http://arxiv.org/abs/2502.18290v2)** | 2025-02-27 |  |
| **[SAP-DIFF: Semantic Adversarial Patch Generation for Black-Box Face Recognition Models via Diffusion Models](http://arxiv.org/abs/2502.19710v1)** | 2025-02-27 |  |
| **[MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models](http://arxiv.org/abs/2502.08079v2)** | 2025-02-27 |  |
| **[Improving Adversarial Transferability in MLLMs via Dynamic Vision-Language Alignment Attack](http://arxiv.org/abs/2502.19672v1)** | 2025-02-27 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2403.09766</p></details> |
| **[H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2.0 Flash Thinking](http://arxiv.org/abs/2502.12893v2)** | 2025-02-27 | <details><summary>Websi...</summary><p>Website: https://maliciouseducator.org/</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace](http://arxiv.org/abs/2410.13910v2)** | 2025-02-27 | <details><summary>arxiv...</summary><p>arxiv version of ICLR2025</p></details> |
| **[Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets](http://arxiv.org/abs/2502.20246v1)** | 2025-02-27 |  |
| **[Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models](http://arxiv.org/abs/2502.19883v1)** | 2025-02-27 | 12 pages. 6 figures |
| **[The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1](http://arxiv.org/abs/2502.12659v3)** | 2025-02-27 |  |
| **[Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training](http://arxiv.org/abs/2502.19726v1)** | 2025-02-27 |  |
| **[Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models](http://arxiv.org/abs/2502.18290v2)** | 2025-02-27 |  |
| **[SAP-DIFF: Semantic Adversarial Patch Generation for Black-Box Face Recognition Models via Diffusion Models](http://arxiv.org/abs/2502.19710v1)** | 2025-02-27 |  |
| **[MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models](http://arxiv.org/abs/2502.08079v2)** | 2025-02-27 |  |
| **[Improving Adversarial Transferability in MLLMs via Dynamic Vision-Language Alignment Attack](http://arxiv.org/abs/2502.19672v1)** | 2025-02-27 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2403.09766</p></details> |
| **[H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2.0 Flash Thinking](http://arxiv.org/abs/2502.12893v2)** | 2025-02-27 | <details><summary>Websi...</summary><p>Website: https://maliciouseducator.org/</p></details> |

