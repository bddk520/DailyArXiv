---
title: Latest 15 Papers - October 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](http://arxiv.org/abs/2510.14005v2)** | 2025-10-17 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[OCR-APT: Reconstructing APT Stories from Audit Logs using Subgraph Anomaly Detection and LLMs](http://arxiv.org/abs/2510.15188v1)** | 2025-10-16 |  |
| **[Active Honeypot Guardrail System: Probing and Confirming Multi-Turn LLM Jailbreaks](http://arxiv.org/abs/2510.15017v1)** | 2025-10-16 | 6pages, 2 figures |
| **[Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs](http://arxiv.org/abs/2510.03567v3)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](http://arxiv.org/abs/2510.14522v1)** | 2025-10-16 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](http://arxiv.org/abs/2510.14381v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[When Style Breaks Safety: Defending LLMs Against Superficial Style Alignment](http://arxiv.org/abs/2506.07452v2)** | 2025-10-16 |  |
| **[Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](http://arxiv.org/abs/2510.14207v1)** | 2025-10-16 | 13 pages, 4 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](http://arxiv.org/abs/2510.14005v2)** | 2025-10-17 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[OCR-APT: Reconstructing APT Stories from Audit Logs using Subgraph Anomaly Detection and LLMs](http://arxiv.org/abs/2510.15188v1)** | 2025-10-16 |  |
| **[Active Honeypot Guardrail System: Probing and Confirming Multi-Turn LLM Jailbreaks](http://arxiv.org/abs/2510.15017v1)** | 2025-10-16 | 6pages, 2 figures |
| **[Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs](http://arxiv.org/abs/2510.03567v3)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](http://arxiv.org/abs/2510.14522v1)** | 2025-10-16 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](http://arxiv.org/abs/2510.14381v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[When Style Breaks Safety: Defending LLMs Against Superficial Style Alignment](http://arxiv.org/abs/2506.07452v2)** | 2025-10-16 |  |
| **[Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](http://arxiv.org/abs/2510.14207v1)** | 2025-10-16 | 13 pages, 4 figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks](http://arxiv.org/abs/2509.20639v2)** | 2025-10-17 |  |
| **[MalCVE: Malware Detection and CVE Association Using Large Language Models](http://arxiv.org/abs/2510.15567v1)** | 2025-10-17 |  |
| **[SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models](http://arxiv.org/abs/2510.15476v1)** | 2025-10-17 |  |
| **[Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](http://arxiv.org/abs/2510.15430v1)** | 2025-10-17 |  |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](http://arxiv.org/abs/2510.15303v1)** | 2025-10-17 | 13 pages, 21 figures |
| **[PoTS: Proof-of-Training-Steps for Backdoor Detection in Large Language Models](http://arxiv.org/abs/2510.15106v1)** | 2025-10-16 | <details><summary>10 pa...</summary><p>10 pages, 6 figures, 1 table. Accepted for presentation at FLLM 2025 (Vienna, Nov 2025)</p></details> |
| **[Sequential Comics for Jailbreaking Multimodal Large Language Models via Structured Visual Storytelling](http://arxiv.org/abs/2510.15068v1)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by IEEE S&P 2026 Cycle 1</p></details> |
| **[SPIRIT: Patching Speech Language Models against Jailbreak Attacks](http://arxiv.org/abs/2505.13541v2)** | 2025-10-16 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks](http://arxiv.org/abs/2509.20639v2)** | 2025-10-17 |  |
| **[MalCVE: Malware Detection and CVE Association Using Large Language Models](http://arxiv.org/abs/2510.15567v1)** | 2025-10-17 |  |
| **[SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models](http://arxiv.org/abs/2510.15476v1)** | 2025-10-17 |  |
| **[Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](http://arxiv.org/abs/2510.15430v1)** | 2025-10-17 |  |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](http://arxiv.org/abs/2510.15303v1)** | 2025-10-17 | 13 pages, 21 figures |
| **[PoTS: Proof-of-Training-Steps for Backdoor Detection in Large Language Models](http://arxiv.org/abs/2510.15106v1)** | 2025-10-16 | <details><summary>10 pa...</summary><p>10 pages, 6 figures, 1 table. Accepted for presentation at FLLM 2025 (Vienna, Nov 2025)</p></details> |
| **[Sequential Comics for Jailbreaking Multimodal Large Language Models via Structured Visual Storytelling](http://arxiv.org/abs/2510.15068v1)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by IEEE S&P 2026 Cycle 1</p></details> |
| **[SPIRIT: Patching Speech Language Models against Jailbreak Attacks](http://arxiv.org/abs/2505.13541v2)** | 2025-10-16 |  |

