---
title: Latest 15 Papers - April 24, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Inducing Vulnerable Code Generation in LLM Coding Assistants](http://arxiv.org/abs/2504.15867v1)** | 2025-04-22 |  |
| **[LAMD: Context-driven Android Malware Detection and Classification with LLMs](http://arxiv.org/abs/2502.13055v2)** | 2025-04-21 | <details><summary>accep...</summary><p>accepted by 2025 46th IEEE Symposium on Security and Privacy Workshops (SPW)</p></details> |
| **[aiXamine: LLM Safety and Security Simplified](http://arxiv.org/abs/2504.14985v1)** | 2025-04-21 |  |
| **[MCGMark: An Encodable and Robust Online Watermark for Tracing LLM-Generated Malicious Code](http://arxiv.org/abs/2408.01354v2)** | 2025-04-21 |  |
| **[Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents](http://arxiv.org/abs/2503.15547v2)** | 2025-04-21 |  |
| **[LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks](http://arxiv.org/abs/2504.14556v1)** | 2025-04-20 | 8 pages, 7 figures, |
| **[Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning](http://arxiv.org/abs/2503.17987v2)** | 2025-04-19 | <details><summary>This ...</summary><p>This paper includes model-generated content that may contain offensive or distressing material</p></details> |
| **[Detecting Malicious Source Code in PyPI Packages with LLMs: Does RAG Come in Handy?](http://arxiv.org/abs/2504.13769v1)** | 2025-04-18 | <details><summary>The p...</summary><p>The paper has been peer-reviewed and accepted for publication to the 29th International Conference on Evaluation and Assessment in Software Engineering (EASE 2025)</p></details> |
| **[AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](http://arxiv.org/abs/2410.09024v3)** | 2025-04-18 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025</p></details> |
| **[DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification](http://arxiv.org/abs/2504.13562v1)** | 2025-04-18 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Inducing Vulnerable Code Generation in LLM Coding Assistants](http://arxiv.org/abs/2504.15867v1)** | 2025-04-22 |  |
| **[LAMD: Context-driven Android Malware Detection and Classification with LLMs](http://arxiv.org/abs/2502.13055v2)** | 2025-04-21 | <details><summary>accep...</summary><p>accepted by 2025 46th IEEE Symposium on Security and Privacy Workshops (SPW)</p></details> |
| **[aiXamine: LLM Safety and Security Simplified](http://arxiv.org/abs/2504.14985v1)** | 2025-04-21 |  |
| **[MCGMark: An Encodable and Robust Online Watermark for Tracing LLM-Generated Malicious Code](http://arxiv.org/abs/2408.01354v2)** | 2025-04-21 |  |
| **[Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents](http://arxiv.org/abs/2503.15547v2)** | 2025-04-21 |  |
| **[LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks](http://arxiv.org/abs/2504.14556v1)** | 2025-04-20 | 8 pages, 7 figures, |
| **[Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning](http://arxiv.org/abs/2503.17987v2)** | 2025-04-19 | <details><summary>This ...</summary><p>This paper includes model-generated content that may contain offensive or distressing material</p></details> |
| **[Detecting Malicious Source Code in PyPI Packages with LLMs: Does RAG Come in Handy?](http://arxiv.org/abs/2504.13769v1)** | 2025-04-18 | <details><summary>The p...</summary><p>The paper has been peer-reviewed and accepted for publication to the 29th International Conference on Evaluation and Assessment in Software Engineering (EASE 2025)</p></details> |
| **[AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](http://arxiv.org/abs/2410.09024v3)** | 2025-04-18 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025</p></details> |
| **[DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification](http://arxiv.org/abs/2504.13562v1)** | 2025-04-18 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking machine learning models for predicting aerofoil performance](http://arxiv.org/abs/2504.15993v1)** | 2025-04-22 | <details><summary>9 pag...</summary><p>9 pages, 10 figures, submitted to EWTEC</p></details> |
| **[Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models](http://arxiv.org/abs/2504.15823v1)** | 2025-04-22 |  |
| **[BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger](http://arxiv.org/abs/2408.09093v3)** | 2025-04-22 |  |
| **[Red Team Diffuser: Exposing Toxic Continuation Vulnerabilities in Vision-Language Models via Reinforcement Learning](http://arxiv.org/abs/2503.06223v2)** | 2025-04-22 |  |
| **[TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data](http://arxiv.org/abs/2504.15674v1)** | 2025-04-22 |  |
| **[Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey](http://arxiv.org/abs/2504.15622v1)** | 2025-04-22 | 20 pages, 3 figures |
| **[Diversity Helps Jailbreak Large Language Models](http://arxiv.org/abs/2411.04223v2)** | 2025-04-22 |  |
| **[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models](http://arxiv.org/abs/2502.20650v2)** | 2025-04-22 |  |
| **[T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models](http://arxiv.org/abs/2504.15512v1)** | 2025-04-22 | 25 pages, 5 figures |
| **[An Undetectable Watermark for Generative Image Models](http://arxiv.org/abs/2410.07369v4)** | 2025-04-21 | ICLR 2025 |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking machine learning models for predicting aerofoil performance](http://arxiv.org/abs/2504.15993v1)** | 2025-04-22 | <details><summary>9 pag...</summary><p>9 pages, 10 figures, submitted to EWTEC</p></details> |
| **[Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models](http://arxiv.org/abs/2504.15823v1)** | 2025-04-22 |  |
| **[BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger](http://arxiv.org/abs/2408.09093v3)** | 2025-04-22 |  |
| **[Red Team Diffuser: Exposing Toxic Continuation Vulnerabilities in Vision-Language Models via Reinforcement Learning](http://arxiv.org/abs/2503.06223v2)** | 2025-04-22 |  |
| **[TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data](http://arxiv.org/abs/2504.15674v1)** | 2025-04-22 |  |
| **[Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey](http://arxiv.org/abs/2504.15622v1)** | 2025-04-22 | 20 pages, 3 figures |
| **[Diversity Helps Jailbreak Large Language Models](http://arxiv.org/abs/2411.04223v2)** | 2025-04-22 |  |
| **[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models](http://arxiv.org/abs/2502.20650v2)** | 2025-04-22 |  |
| **[T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models](http://arxiv.org/abs/2504.15512v1)** | 2025-04-22 | 25 pages, 5 figures |
| **[An Undetectable Watermark for Generative Image Models](http://arxiv.org/abs/2410.07369v4)** | 2025-04-21 | ICLR 2025 |

