---
title: Latest 15 Papers - May 08, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](http://arxiv.org/abs/2503.18991v2)** | 2025-05-06 | <details><summary>The t...</summary><p>The three authors contributed equally to this work</p></details> |
| **[A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](http://arxiv.org/abs/2505.03196v1)** | 2025-05-06 |  |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v1)** | 2025-05-06 |  |
| **[CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](http://arxiv.org/abs/2505.01900v1)** | 2025-05-03 |  |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v1)** | 2025-05-03 |  |
| **[LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](http://arxiv.org/abs/2505.01177v1)** | 2025-05-02 |  |
| **[Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](http://arxiv.org/abs/2504.21036v2)** | 2025-05-01 | accepted by DBSec25 |
| **[Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](http://arxiv.org/abs/2505.01456v1)** | 2025-05-01 | <details><summary>The d...</summary><p>The dataset and code are publicly available at https://github.com/Vaidehi99/UnLOK-VQA</p></details> |
| **[Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems](http://arxiv.org/abs/2405.20774v3)** | 2025-04-30 | <details><summary>Accep...</summary><p>Accepted paper at ICLR 2025, 31 pages, including main paper, references, and appendix</p></details> |
| **[XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](http://arxiv.org/abs/2504.21700v1)** | 2025-04-30 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](http://arxiv.org/abs/2503.18991v2)** | 2025-05-06 | <details><summary>The t...</summary><p>The three authors contributed equally to this work</p></details> |
| **[A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](http://arxiv.org/abs/2505.03196v1)** | 2025-05-06 |  |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v1)** | 2025-05-06 |  |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v5)** | 2025-05-04 | <details><summary>40 pa...</summary><p>40 pages, 38 figures An earlier revision of this paper was submitted to ICML. Since then, it has been updated to include new results on training dynamics (4.7) and base models (4.8)</p></details> |
| **[CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](http://arxiv.org/abs/2505.01900v1)** | 2025-05-03 |  |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v1)** | 2025-05-03 |  |
| **[LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](http://arxiv.org/abs/2505.01177v1)** | 2025-05-02 |  |
| **[Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](http://arxiv.org/abs/2504.21036v2)** | 2025-05-01 | accepted by DBSec25 |
| **[Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](http://arxiv.org/abs/2505.01456v1)** | 2025-05-01 | <details><summary>The d...</summary><p>The dataset and code are publicly available at https://github.com/Vaidehi99/UnLOK-VQA</p></details> |
| **[Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems](http://arxiv.org/abs/2405.20774v3)** | 2025-04-30 | <details><summary>Accep...</summary><p>Accepted paper at ICLR 2025, 31 pages, including main paper, references, and appendix</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Robustness of Deep Learning Models for Inland Water Body Segmentation from SAR Images](http://arxiv.org/abs/2505.01884v2)** | 2025-05-06 | <details><summary>21 pa...</summary><p>21 pages, 15 figures, 2 tables</p></details> |
| **[Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](http://arxiv.org/abs/2505.03519v1)** | 2025-05-06 | <details><summary>Our d...</summary><p>Our dataset and code are available in the Supp</p></details> |
| **[BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](http://arxiv.org/abs/2505.03501v1)** | 2025-05-06 |  |
| **[A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](http://arxiv.org/abs/2505.03490v1)** | 2025-05-06 |  |
| **[Automatic Calibration for Membership Inference Attack on Large Language Models](http://arxiv.org/abs/2505.03392v1)** | 2025-05-06 |  |
| **[Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models](http://arxiv.org/abs/2503.06269v2)** | 2025-05-06 |  |
| **[Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](http://arxiv.org/abs/2505.03147v1)** | 2025-05-06 | <details><summary>5 pag...</summary><p>5 pages, 2 figures 4 tables, accepted for publication at the Web Conference 2025 (WWW'25)</p></details> |
| **[PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](http://arxiv.org/abs/2411.11389v2)** | 2025-05-06 |  |
| **[Large Language Models as Robust Data Generators in Software Analytics: Are We There Yet?](http://arxiv.org/abs/2411.10565v3)** | 2025-05-05 | <details><summary>Accep...</summary><p>Accepted to the AI Model/Data Track of the Evaluation and Assessment in Software Engineering (EASE) 2025 Conference</p></details> |
| **[Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation](http://arxiv.org/abs/2505.02971v1)** | 2025-05-05 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Robustness of Deep Learning Models for Inland Water Body Segmentation from SAR Images](http://arxiv.org/abs/2505.01884v2)** | 2025-05-06 | <details><summary>21 pa...</summary><p>21 pages, 15 figures, 2 tables</p></details> |
| **[Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](http://arxiv.org/abs/2505.03519v1)** | 2025-05-06 | <details><summary>Our d...</summary><p>Our dataset and code are available in the Supp</p></details> |
| **[BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](http://arxiv.org/abs/2505.03501v1)** | 2025-05-06 |  |
| **[A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](http://arxiv.org/abs/2505.03490v1)** | 2025-05-06 |  |
| **[Automatic Calibration for Membership Inference Attack on Large Language Models](http://arxiv.org/abs/2505.03392v1)** | 2025-05-06 |  |
| **[Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models](http://arxiv.org/abs/2503.06269v2)** | 2025-05-06 |  |
| **[Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](http://arxiv.org/abs/2505.03147v1)** | 2025-05-06 | <details><summary>5 pag...</summary><p>5 pages, 2 figures 4 tables, accepted for publication at the Web Conference 2025 (WWW'25)</p></details> |
| **[PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](http://arxiv.org/abs/2411.11389v2)** | 2025-05-06 |  |
| **[Large Language Models as Robust Data Generators in Software Analytics: Are We There Yet?](http://arxiv.org/abs/2411.10565v3)** | 2025-05-05 | <details><summary>Accep...</summary><p>Accepted to the AI Model/Data Track of the Evaluation and Assessment in Software Engineering (EASE) 2025 Conference</p></details> |
| **[Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation](http://arxiv.org/abs/2505.02971v1)** | 2025-05-05 |  |

