---
title: Latest 15 Papers - October 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts](http://arxiv.org/abs/2510.07239v1)** | 2025-10-08 |  |
| **[Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples](http://arxiv.org/abs/2510.07192v1)** | 2025-10-08 |  |
| **[RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning](http://arxiv.org/abs/2510.06994v1)** | 2025-10-08 |  |
| **[Membership Inference Attacks on LLM-based Recommender Systems](http://arxiv.org/abs/2508.18665v3)** | 2025-10-08 | <details><summary>this ...</summary><p>this paper is under review</p></details> |
| **[Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?](http://arxiv.org/abs/2510.06594v1)** | 2025-10-08 |  |
| **[From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond](http://arxiv.org/abs/2510.06530v1)** | 2025-10-08 |  |
| **[LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v2)** | 2025-10-07 |  |
| **[An Embarrassingly Simple Defense Against LLM Abliteration Attacks](http://arxiv.org/abs/2505.19056v2)** | 2025-10-07 | <details><summary>prepr...</summary><p>preprint - under review</p></details> |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[AutoPentester: An LLM Agent-based Framework for Automated Pentesting](http://arxiv.org/abs/2510.05605v1)** | 2025-10-07 | <details><summary>IEEE ...</summary><p>IEEE TrustCom 2025 10 pages</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts](http://arxiv.org/abs/2510.07239v1)** | 2025-10-08 |  |
| **[Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples](http://arxiv.org/abs/2510.07192v1)** | 2025-10-08 |  |
| **[RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning](http://arxiv.org/abs/2510.06994v1)** | 2025-10-08 |  |
| **[Membership Inference Attacks on LLM-based Recommender Systems](http://arxiv.org/abs/2508.18665v3)** | 2025-10-08 | <details><summary>this ...</summary><p>this paper is under review</p></details> |
| **[Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?](http://arxiv.org/abs/2510.06594v1)** | 2025-10-08 |  |
| **[From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond](http://arxiv.org/abs/2510.06530v1)** | 2025-10-08 |  |
| **[LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v2)** | 2025-10-07 |  |
| **[An Embarrassingly Simple Defense Against LLM Abliteration Attacks](http://arxiv.org/abs/2505.19056v2)** | 2025-10-07 | <details><summary>prepr...</summary><p>preprint - under review</p></details> |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[AutoPentester: An LLM Agent-based Framework for Automated Pentesting](http://arxiv.org/abs/2510.05605v1)** | 2025-10-07 | <details><summary>IEEE ...</summary><p>IEEE TrustCom 2025 10 pages</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models](http://arxiv.org/abs/2509.03487v2)** | 2025-10-08 |  |
| **[DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven Training-Free Model Inversion](http://arxiv.org/abs/2504.18015v3)** | 2025-10-08 |  |
| **[Benchmarking Gaslighting Negation Attacks Against Multimodal Large Language Models](http://arxiv.org/abs/2501.19017v4)** | 2025-10-08 | <details><summary>Proje...</summary><p>Project website: https://yxg1005.github.io/GaslightingNegationAttacks/</p></details> |
| **[XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection](http://arxiv.org/abs/2510.06706v1)** | 2025-10-08 | <details><summary>Accep...</summary><p>Accepted to 2025 IEEE International Conference on Advanced Video and Signal-Based Surveillance</p></details> |
| **[Is the Hard-Label Cryptanalytic Model Extraction Really Polynomial?](http://arxiv.org/abs/2510.06692v1)** | 2025-10-08 |  |
| **[Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks](http://arxiv.org/abs/2508.11711v2)** | 2025-10-08 |  |
| **[Towards the Worst-case Robustness of Large Language Models](http://arxiv.org/abs/2501.19040v4)** | 2025-10-08 |  |
| **[SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models](http://arxiv.org/abs/2510.05173v2)** | 2025-10-08 | <details><summary>Accep...</summary><p>Accepted by ACM CCS 2025</p></details> |
| **[Text-to-Image Models Leave Identifiable Signatures: Implications for Leaderboard Security](http://arxiv.org/abs/2510.06525v1)** | 2025-10-07 | <details><summary>Accep...</summary><p>Accepted at Lock-LLM Workshop, NeurIPS 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models](http://arxiv.org/abs/2509.03487v2)** | 2025-10-08 |  |
| **[From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models](http://arxiv.org/abs/2509.03122v2)** | 2025-10-08 | preprint |
| **[DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven Training-Free Model Inversion](http://arxiv.org/abs/2504.18015v3)** | 2025-10-08 |  |
| **[Benchmarking Gaslighting Negation Attacks Against Multimodal Large Language Models](http://arxiv.org/abs/2501.19017v4)** | 2025-10-08 | <details><summary>Proje...</summary><p>Project website: https://yxg1005.github.io/GaslightingNegationAttacks/</p></details> |
| **[XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection](http://arxiv.org/abs/2510.06706v1)** | 2025-10-08 | <details><summary>Accep...</summary><p>Accepted to 2025 IEEE International Conference on Advanced Video and Signal-Based Surveillance</p></details> |
| **[Is the Hard-Label Cryptanalytic Model Extraction Really Polynomial?](http://arxiv.org/abs/2510.06692v1)** | 2025-10-08 |  |
| **[Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks](http://arxiv.org/abs/2508.11711v2)** | 2025-10-08 |  |
| **[Towards the Worst-case Robustness of Large Language Models](http://arxiv.org/abs/2501.19040v4)** | 2025-10-08 |  |
| **[SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models](http://arxiv.org/abs/2510.05173v2)** | 2025-10-08 | <details><summary>Accep...</summary><p>Accepted by ACM CCS 2025</p></details> |
| **[Text-to-Image Models Leave Identifiable Signatures: Implications for Leaderboard Security](http://arxiv.org/abs/2510.06525v1)** | 2025-10-07 | <details><summary>Accep...</summary><p>Accepted at Lock-LLM Workshop, NeurIPS 2025</p></details> |

