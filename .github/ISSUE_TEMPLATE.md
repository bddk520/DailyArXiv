---
title: Latest 15 Papers - August 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v1)** | 2025-08-14 | Preprint |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](http://arxiv.org/abs/2508.10390v1)** | 2025-08-14 |  |
| **[MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs](http://arxiv.org/abs/2506.22557v2)** | 2025-08-13 |  |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v2)** | 2025-08-13 |  |
| **[Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM](http://arxiv.org/abs/2508.05775v2)** | 2025-08-13 |  |
| **[NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](http://arxiv.org/abs/2508.09473v1)** | 2025-08-13 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v4)** | 2025-08-13 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](http://arxiv.org/abs/2508.09442v1)** | 2025-08-13 |  |
| **[One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs](http://arxiv.org/abs/2502.18862v2)** | 2025-08-12 | <details><summary>Publi...</summary><p>Published at COLM 2025. 30 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro and https://github.com/jacobdunefsky/one-shot-steering-misalignment</p></details> |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v1)** | 2025-08-12 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v1)** | 2025-08-14 | Preprint |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](http://arxiv.org/abs/2508.10390v1)** | 2025-08-14 |  |
| **[MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs](http://arxiv.org/abs/2506.22557v2)** | 2025-08-13 |  |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v2)** | 2025-08-13 |  |
| **[Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM](http://arxiv.org/abs/2508.05775v2)** | 2025-08-13 |  |
| **[NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](http://arxiv.org/abs/2508.09473v1)** | 2025-08-13 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v4)** | 2025-08-13 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](http://arxiv.org/abs/2508.09442v1)** | 2025-08-13 |  |
| **[One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs](http://arxiv.org/abs/2502.18862v2)** | 2025-08-12 | <details><summary>Publi...</summary><p>Published at COLM 2025. 30 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro and https://github.com/jacobdunefsky/one-shot-steering-misalignment</p></details> |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v1)** | 2025-08-12 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](http://arxiv.org/abs/2506.07468v2)** | 2025-08-15 |  |
| **[Semantically Guided Adversarial Testing of Vision Models Using Language Models](http://arxiv.org/abs/2508.11341v1)** | 2025-08-15 | <details><summary>12 pa...</summary><p>12 pages, 4 figures, 3 tables. Submitted for peer review</p></details> |
| **[MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](http://arxiv.org/abs/2508.10991v1)** | 2025-08-14 |  |
| **[Leveraging large language models for SQL behavior-based database intrusion detection](http://arxiv.org/abs/2508.05690v2)** | 2025-08-14 |  |
| **[Failures to Surface Harmful Contents in Video Large Language Models](http://arxiv.org/abs/2508.10974v1)** | 2025-08-14 | 11 pages, 8 figures |
| **[An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach](http://arxiv.org/abs/2402.13871v2)** | 2025-08-14 |  |
| **[BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](http://arxiv.org/abs/2508.03221v2)** | 2025-08-14 |  |
| **[A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning](http://arxiv.org/abs/2508.10315v1)** | 2025-08-14 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](http://arxiv.org/abs/2506.07468v2)** | 2025-08-15 |  |
| **[Semantically Guided Adversarial Testing of Vision Models Using Language Models](http://arxiv.org/abs/2508.11341v1)** | 2025-08-15 | <details><summary>12 pa...</summary><p>12 pages, 4 figures, 3 tables. Submitted for peer review</p></details> |
| **[MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](http://arxiv.org/abs/2508.10991v1)** | 2025-08-14 |  |
| **[Leveraging large language models for SQL behavior-based database intrusion detection](http://arxiv.org/abs/2508.05690v2)** | 2025-08-14 |  |
| **[Failures to Surface Harmful Contents in Video Large Language Models](http://arxiv.org/abs/2508.10974v1)** | 2025-08-14 | 11 pages, 8 figures |
| **[An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach](http://arxiv.org/abs/2402.13871v2)** | 2025-08-14 |  |
| **[BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](http://arxiv.org/abs/2508.03221v2)** | 2025-08-14 |  |
| **[A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning](http://arxiv.org/abs/2508.10315v1)** | 2025-08-14 |  |

