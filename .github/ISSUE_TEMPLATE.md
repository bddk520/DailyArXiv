---
title: Latest 15 Papers - October 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs](http://arxiv.org/abs/2510.03567v3)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](http://arxiv.org/abs/2510.14522v1)** | 2025-10-16 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](http://arxiv.org/abs/2510.14381v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[When Style Breaks Safety: Defending LLMs Against Superficial Style Alignment](http://arxiv.org/abs/2506.07452v2)** | 2025-10-16 |  |
| **[Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](http://arxiv.org/abs/2510.14207v1)** | 2025-10-16 | 13 pages, 4 figures |
| **[One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery](http://arxiv.org/abs/2510.14036v1)** | 2025-10-15 |  |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](http://arxiv.org/abs/2510.14005v1)** | 2025-10-15 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks](http://arxiv.org/abs/2504.14556v2)** | 2025-10-15 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs](http://arxiv.org/abs/2510.03567v3)** | 2025-10-16 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](http://arxiv.org/abs/2510.14522v1)** | 2025-10-16 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](http://arxiv.org/abs/2510.14381v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[When Style Breaks Safety: Defending LLMs Against Superficial Style Alignment](http://arxiv.org/abs/2506.07452v2)** | 2025-10-16 |  |
| **[Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](http://arxiv.org/abs/2510.14207v1)** | 2025-10-16 | 13 pages, 4 figures |
| **[One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery](http://arxiv.org/abs/2510.14036v1)** | 2025-10-15 |  |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](http://arxiv.org/abs/2510.14005v1)** | 2025-10-15 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks](http://arxiv.org/abs/2504.14556v2)** | 2025-10-15 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by IEEE S&P 2026 Cycle 1</p></details> |
| **[SPIRIT: Patching Speech Language Models against Jailbreak Attacks](http://arxiv.org/abs/2505.13541v2)** | 2025-10-16 |  |
| **[Lost in the Averages: A New Specific Setup to Evaluate Membership Inference Attacks Against Machine Learning Models](http://arxiv.org/abs/2405.15423v2)** | 2025-10-16 | <details><summary>Data ...</summary><p>Data Privacy Management workshop at ESORICS 2025</p></details> |
| **[Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal](http://arxiv.org/abs/2507.21750v4)** | 2025-10-16 | <details><summary>This ...</summary><p>This paper was accepted with an A-decision to Transactions of the Association for Computational Linguistics. This version is the pre-publication version prior to MIT Press production</p></details> |
| **[Stealthy Dual-Trigger Backdoors: Attacking Prompt Tuning in LM-Empowered Graph Foundation Models](http://arxiv.org/abs/2510.14470v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](http://arxiv.org/abs/2509.14225v2)** | 2025-10-16 | <details><summary>5 pag...</summary><p>5 pages, 2 figures, 1 table</p></details> |
| **[RHINO: Guided Reasoning for Mapping Network Logs to Adversarial Tactics and Techniques with Large Language Models](http://arxiv.org/abs/2510.14233v1)** | 2025-10-16 |  |
| **[An Information Asymmetry Game for Trigger-based DNN Model Watermarking](http://arxiv.org/abs/2510.14218v1)** | 2025-10-16 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v2)** | 2025-10-16 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by IEEE S&P 2026 Cycle 1</p></details> |
| **[SPIRIT: Patching Speech Language Models against Jailbreak Attacks](http://arxiv.org/abs/2505.13541v2)** | 2025-10-16 |  |
| **[Lost in the Averages: A New Specific Setup to Evaluate Membership Inference Attacks Against Machine Learning Models](http://arxiv.org/abs/2405.15423v2)** | 2025-10-16 | <details><summary>Data ...</summary><p>Data Privacy Management workshop at ESORICS 2025</p></details> |
| **[Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal](http://arxiv.org/abs/2507.21750v4)** | 2025-10-16 | <details><summary>This ...</summary><p>This paper was accepted with an A-decision to Transactions of the Association for Computational Linguistics. This version is the pre-publication version prior to MIT Press production</p></details> |
| **[Stealthy Dual-Trigger Backdoors: Attacking Prompt Tuning in LM-Empowered Graph Foundation Models](http://arxiv.org/abs/2510.14470v1)** | 2025-10-16 |  |
| **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](http://arxiv.org/abs/2410.13903v2)** | 2025-10-16 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025 Conference</p></details> |
| **[Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](http://arxiv.org/abs/2509.14225v2)** | 2025-10-16 | <details><summary>5 pag...</summary><p>5 pages, 2 figures, 1 table</p></details> |
| **[RHINO: Guided Reasoning for Mapping Network Logs to Adversarial Tactics and Techniques with Large Language Models](http://arxiv.org/abs/2510.14233v1)** | 2025-10-16 |  |
| **[An Information Asymmetry Game for Trigger-based DNN Model Watermarking](http://arxiv.org/abs/2510.14218v1)** | 2025-10-16 |  |

