---
title: Latest 15 Papers - September 29, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Improving LLM Unlearning Robustness via Random Perturbations](http://arxiv.org/abs/2501.19202v4)** | 2025-09-25 | <details><summary>29 pa...</summary><p>29 pages, 13 figures, 8 tables</p></details> |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v3)** | 2025-09-25 |  |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[RLCracker: Exposing the Vulnerability of LLM Watermarks with Adaptive RL Attacks](http://arxiv.org/abs/2509.20924v1)** | 2025-09-25 |  |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v2)** | 2025-09-25 | Preprint |
| **[Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](http://arxiv.org/abs/2509.20680v1)** | 2025-09-25 | <details><summary>28 pa...</summary><p>28 pages, 32 figures, accepted to the Findings of EMNLP 2025</p></details> |
| **[Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization](http://arxiv.org/abs/2509.20230v1)** | 2025-09-24 |  |
| **[STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation](http://arxiv.org/abs/2509.20190v1)** | 2025-09-24 | <details><summary>18 pa...</summary><p>18 pages, 2 figures, accepted for 23rd escar Europe (Nov 05-06, 2025, Frankfurt, Germany)</p></details> |
| **[CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning](http://arxiv.org/abs/2509.20166v1)** | 2025-09-24 |  |
| **[CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain](http://arxiv.org/abs/2509.19925v1)** | 2025-09-24 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Improving LLM Unlearning Robustness via Random Perturbations](http://arxiv.org/abs/2501.19202v4)** | 2025-09-25 | <details><summary>29 pa...</summary><p>29 pages, 13 figures, 8 tables</p></details> |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v3)** | 2025-09-25 |  |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[RLCracker: Exposing the Vulnerability of LLM Watermarks with Adaptive RL Attacks](http://arxiv.org/abs/2509.20924v1)** | 2025-09-25 |  |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v2)** | 2025-09-25 | Preprint |
| **[Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](http://arxiv.org/abs/2509.20680v1)** | 2025-09-25 | <details><summary>28 pa...</summary><p>28 pages, 32 figures, accepted to the Findings of EMNLP 2025</p></details> |
| **[Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization](http://arxiv.org/abs/2509.20230v1)** | 2025-09-24 |  |
| **[STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation](http://arxiv.org/abs/2509.20190v1)** | 2025-09-24 | <details><summary>18 pa...</summary><p>18 pages, 2 figures, accepted for 23rd escar Europe (Nov 05-06, 2025, Frankfurt, Germany)</p></details> |
| **[CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning](http://arxiv.org/abs/2509.20166v1)** | 2025-09-24 |  |
| **[CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain](http://arxiv.org/abs/2509.19925v1)** | 2025-09-24 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves](http://arxiv.org/abs/2411.00827v6)** | 2025-09-25 |  |
| **[GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](http://arxiv.org/abs/2509.21192v1)** | 2025-09-25 | <details><summary>16 pa...</summary><p>16 pages, 5 figures, 4 tables. Under review as a conference paper at ICLR 2026</p></details> |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](http://arxiv.org/abs/2509.21008v1)** | 2025-09-25 |  |
| **[Poisoning Prompt-Guided Sampling in Video Large Language Models](http://arxiv.org/abs/2509.20851v1)** | 2025-09-25 | 12 pages, 4 figures |
| **[Robust Set Partitioning Strategy for Malicious Information Detection in Large-Scale Internet of Things](http://arxiv.org/abs/2502.11538v3)** | 2025-09-25 | 24 pages, 5 figures |
| **[Exploring the Secondary Risks of Large Language Models](http://arxiv.org/abs/2506.12382v3)** | 2025-09-25 | 18 pages, 5 figures |
| **[A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks](http://arxiv.org/abs/2509.20639v1)** | 2025-09-25 |  |
| **[Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles](http://arxiv.org/abs/2405.19179v2)** | 2025-09-24 | <details><summary>publi...</summary><p>published in IROS 2024</p></details> |
| **[RAG Security and Privacy: Formalizing the Threat Model and Attack Surface](http://arxiv.org/abs/2509.20324v1)** | 2025-09-24 | <details><summary>Accep...</summary><p>Accepted at the 5th ICDM Workshop on September 20, 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves](http://arxiv.org/abs/2411.00827v6)** | 2025-09-25 |  |
| **[GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](http://arxiv.org/abs/2509.21192v1)** | 2025-09-25 | <details><summary>16 pa...</summary><p>16 pages, 5 figures, 4 tables. Under review as a conference paper at ICLR 2026</p></details> |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](http://arxiv.org/abs/2509.21008v1)** | 2025-09-25 |  |
| **[Poisoning Prompt-Guided Sampling in Video Large Language Models](http://arxiv.org/abs/2509.20851v1)** | 2025-09-25 | 12 pages, 4 figures |
| **[Causal Time Series Generation via Diffusion Models](http://arxiv.org/abs/2509.20846v1)** | 2025-09-25 |  |
| **[Robust Set Partitioning Strategy for Malicious Information Detection in Large-Scale Internet of Things](http://arxiv.org/abs/2502.11538v3)** | 2025-09-25 | 24 pages, 5 figures |
| **[Exploring the Secondary Risks of Large Language Models](http://arxiv.org/abs/2506.12382v3)** | 2025-09-25 | 18 pages, 5 figures |
| **[A Framework for Rapidly Developing and Deploying Protection Against Large Language Model Attacks](http://arxiv.org/abs/2509.20639v1)** | 2025-09-25 |  |
| **[Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles](http://arxiv.org/abs/2405.19179v2)** | 2025-09-24 | <details><summary>publi...</summary><p>published in IROS 2024</p></details> |

