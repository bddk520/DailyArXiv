---
title: Latest 15 Papers - February 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](http://arxiv.org/abs/2502.08586v1)** | 2025-02-12 |  |
| **[Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark](http://arxiv.org/abs/2502.08332v1)** | 2025-02-12 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v3)** | 2025-02-12 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization](http://arxiv.org/abs/2405.09113v2)** | 2025-02-12 |  |
| **[Universal Adversarial Attack on Aligned Multimodal LLMs](http://arxiv.org/abs/2502.07987v1)** | 2025-02-11 |  |
| **[AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](http://arxiv.org/abs/2502.06348v2)** | 2025-02-11 |  |
| **[LUNAR: LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v1)** | 2025-02-11 |  |
| **[LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild](http://arxiv.org/abs/2410.13919v2)** | 2025-02-10 |  |
| **[Tamper-Resistant Safeguards for Open-Weight LLMs](http://arxiv.org/abs/2408.00761v4)** | 2025-02-10 | <details><summary>Websi...</summary><p>Website: https://www.tamper-resistant-safeguards.com</p></details> |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](http://arxiv.org/abs/2502.08586v1)** | 2025-02-12 |  |
| **[Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark](http://arxiv.org/abs/2502.08332v1)** | 2025-02-12 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v3)** | 2025-02-12 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization](http://arxiv.org/abs/2405.09113v2)** | 2025-02-12 |  |
| **[Universal Adversarial Attack on Aligned Multimodal LLMs](http://arxiv.org/abs/2502.07987v1)** | 2025-02-11 |  |
| **[AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](http://arxiv.org/abs/2502.06348v2)** | 2025-02-11 |  |
| **[LUNAR: LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v1)** | 2025-02-11 |  |
| **[LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild](http://arxiv.org/abs/2410.13919v2)** | 2025-02-10 |  |
| **[Tamper-Resistant Safeguards for Open-Weight LLMs](http://arxiv.org/abs/2408.00761v4)** | 2025-02-10 | <details><summary>Websi...</summary><p>Website: https://www.tamper-resistant-safeguards.com</p></details> |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models](http://arxiv.org/abs/2408.02416v2)** | 2025-02-12 | <details><summary>Sourc...</summary><p>Source Code: https://github.com/liangzid/PromptExtractionEval</p></details> |
| **[Compromising Honesty and Harmlessness in Language Models via Deception Attacks](http://arxiv.org/abs/2502.08301v1)** | 2025-02-12 |  |
| **[The Nonlinear Filter Model of Stream Cipher Redivivus](http://arxiv.org/abs/2502.01110v4)** | 2025-02-12 |  |
| **[In-Context Experience Replay Facilitates Safety Red-Teaming of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.16769v2)** | 2025-02-12 |  |
| **[Safety at Scale: A Comprehensive Survey of Large Model Safety](http://arxiv.org/abs/2502.05206v2)** | 2025-02-12 | <details><summary>47 pa...</summary><p>47 pages, 3 figures, 11 tables GitHub: https://github.com/xingjunm/Awesome-Large-Model-Safety</p></details> |
| **[BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks](http://arxiv.org/abs/2410.20971v2)** | 2025-02-12 |  |
| **[Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](http://arxiv.org/abs/2502.06832v2)** | 2025-02-12 | <details><summary>10 pa...</summary><p>10 pages, 3 figures, submitted to ICML 2025 (under review)</p></details> |
| **[SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models](http://arxiv.org/abs/2502.07644v2)** | 2025-02-12 | <details><summary>16 pa...</summary><p>16 pages. arXiv admin note: text overlap with arXiv:2404.04306</p></details> |
| **[MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models](http://arxiv.org/abs/2502.08079v1)** | 2025-02-12 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models](http://arxiv.org/abs/2408.02416v2)** | 2025-02-12 | <details><summary>Sourc...</summary><p>Source Code: https://github.com/liangzid/PromptExtractionEval</p></details> |
| **[Compromising Honesty and Harmlessness in Language Models via Deception Attacks](http://arxiv.org/abs/2502.08301v1)** | 2025-02-12 |  |
| **[The Nonlinear Filter Model of Stream Cipher Redivivus](http://arxiv.org/abs/2502.01110v4)** | 2025-02-12 |  |
| **[In-Context Experience Replay Facilitates Safety Red-Teaming of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.16769v2)** | 2025-02-12 |  |
| **[Safety at Scale: A Comprehensive Survey of Large Model Safety](http://arxiv.org/abs/2502.05206v2)** | 2025-02-12 | <details><summary>47 pa...</summary><p>47 pages, 3 figures, 11 tables GitHub: https://github.com/xingjunm/Awesome-Large-Model-Safety</p></details> |
| **[BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks](http://arxiv.org/abs/2410.20971v2)** | 2025-02-12 |  |
| **[Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](http://arxiv.org/abs/2502.06832v2)** | 2025-02-12 | <details><summary>10 pa...</summary><p>10 pages, 3 figures, submitted to ICML 2025 (under review)</p></details> |
| **[SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models](http://arxiv.org/abs/2502.07644v2)** | 2025-02-12 | <details><summary>16 pa...</summary><p>16 pages. arXiv admin note: text overlap with arXiv:2404.04306</p></details> |
| **[MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models](http://arxiv.org/abs/2502.08079v1)** | 2025-02-12 |  |

