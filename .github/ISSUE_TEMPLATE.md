---
title: Latest 15 Papers - May 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v1)** | 2025-05-07 | 7 Pages, 6 Figures |
| **[ACE: A Security Architecture for LLM-Integrated App Systems](http://arxiv.org/abs/2504.20984v2)** | 2025-05-07 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; clarify relation to indirect prompt injection attacks</p></details> |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v2)** | 2025-05-07 | <details><summary>Accep...</summary><p>Accepted by IEEE Communications Magazine</p></details> |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v1)** | 2025-05-07 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2405.01886</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v6)** | 2025-05-12 | <details><summary>40 pa...</summary><p>40 pages, 38 figures An earlier revision of this paper was accepted at ICML 2025. Since then, it has been updated to include new results on training dynamics (4.7) and base models (4.8)</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v1)** | 2025-05-07 | 7 Pages, 6 Figures |
| **[ACE: A Security Architecture for LLM-Integrated App Systems](http://arxiv.org/abs/2504.20984v2)** | 2025-05-07 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; clarify relation to indirect prompt injection attacks</p></details> |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v2)** | 2025-05-07 | <details><summary>Accep...</summary><p>Accepted by IEEE Communications Magazine</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v1)** | 2025-05-12 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v3)** | 2025-05-12 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v5)** | 2025-05-12 |  |
| **[Modeling False Data Injection Attacks in Integrated Electricity-Gas Systems](http://arxiv.org/abs/2312.00781v2)** | 2025-05-12 | 13 pages |
| **[One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](http://arxiv.org/abs/2505.07167v1)** | 2025-05-12 |  |
| **[Unleashing the potential of prompt engineering for large language models](http://arxiv.org/abs/2310.14735v6)** | 2025-05-11 | <details><summary>v6 - ...</summary><p>v6 - Metadata updated (title, journal ref, DOI). PDF identical to v5 (original submission). Please cite the peer-reviewed Version of Record in "Patterns" (DOI: 10.1016/j.patter.2025.101260)</p></details> |
| **[Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges](http://arxiv.org/abs/2504.21415v2)** | 2025-05-11 | 13pages, 10 figures |
| **[Diversity Helps Jailbreak Large Language Models](http://arxiv.org/abs/2411.04223v3)** | 2025-05-11 |  |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v1)** | 2025-05-10 | <details><summary>Submi...</summary><p>Submitted to USENIX Security '25 Cycle 2 in Wednesday, January 22, 2025. Under Shepherding</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v1)** | 2025-05-12 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v3)** | 2025-05-12 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v5)** | 2025-05-12 |  |
| **[Modeling False Data Injection Attacks in Integrated Electricity-Gas Systems](http://arxiv.org/abs/2312.00781v2)** | 2025-05-12 | 13 pages |
| **[One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](http://arxiv.org/abs/2505.07167v1)** | 2025-05-12 |  |
| **[Unleashing the potential of prompt engineering for large language models](http://arxiv.org/abs/2310.14735v6)** | 2025-05-11 | <details><summary>v6 - ...</summary><p>v6 - Metadata updated (title, journal ref, DOI). PDF identical to v5 (original submission). Please cite the peer-reviewed Version of Record in "Patterns" (DOI: 10.1016/j.patter.2025.101260)</p></details> |
| **[Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges](http://arxiv.org/abs/2504.21415v2)** | 2025-05-11 | 13pages, 10 figures |
| **[Diversity Helps Jailbreak Large Language Models](http://arxiv.org/abs/2411.04223v3)** | 2025-05-11 |  |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v1)** | 2025-05-10 | <details><summary>Submi...</summary><p>Submitted to USENIX Security '25 Cycle 2 in Wednesday, January 22, 2025. Under Shepherding</p></details> |

