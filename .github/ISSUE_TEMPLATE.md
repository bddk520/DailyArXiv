---
title: Latest 15 Papers - August 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v2)** | 2025-08-18 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |
| **[RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](http://arxiv.org/abs/2508.13152v1)** | 2025-08-18 | <details><summary>Accep...</summary><p>Accepted to TACL 2025. This version is a pre-MIT Press publication version</p></details> |
| **[Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis](http://arxiv.org/abs/2508.13240v1)** | 2025-08-18 |  |
| **[Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions](http://arxiv.org/abs/2508.13214v1)** | 2025-08-16 |  |
| **[Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection](http://arxiv.org/abs/2411.01077v5)** | 2025-08-16 |  |
| **[Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous](http://arxiv.org/abs/2508.12175v1)** | 2025-08-16 | <details><summary>https...</summary><p>https://sites.google.com/view/invitation-is-all-you-need/home</p></details> |
| **[Can LLMs Handle WebShell Detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework](http://arxiv.org/abs/2504.13811v2)** | 2025-08-16 | <details><summary>Publi...</summary><p>Published as a conference paper at COLM 2025</p></details> |
| **[Mitigating Jailbreaks with Intent-Aware LLMs](http://arxiv.org/abs/2508.12072v1)** | 2025-08-16 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v2)** | 2025-08-18 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |
| **[RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](http://arxiv.org/abs/2508.13152v1)** | 2025-08-18 | <details><summary>Accep...</summary><p>Accepted to TACL 2025. This version is a pre-MIT Press publication version</p></details> |
| **[Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis](http://arxiv.org/abs/2508.13240v1)** | 2025-08-18 |  |
| **[Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions](http://arxiv.org/abs/2508.13214v1)** | 2025-08-16 |  |
| **[Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection](http://arxiv.org/abs/2411.01077v5)** | 2025-08-16 |  |
| **[Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous](http://arxiv.org/abs/2508.12175v1)** | 2025-08-16 | <details><summary>https...</summary><p>https://sites.google.com/view/invitation-is-all-you-need/home</p></details> |
| **[Can LLMs Handle WebShell Detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework](http://arxiv.org/abs/2504.13811v2)** | 2025-08-16 | <details><summary>Publi...</summary><p>Published as a conference paper at COLM 2025</p></details> |
| **[Mitigating Jailbreaks with Intent-Aware LLMs](http://arxiv.org/abs/2508.12072v1)** | 2025-08-16 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedUP: Efficient Pruning-based Federated Unlearning for Model Poisoning Attacks](http://arxiv.org/abs/2508.13853v1)** | 2025-08-19 | <details><summary>15 pa...</summary><p>15 pages, 5 figures, 7 tables</p></details> |
| **[Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance](http://arxiv.org/abs/2508.13739v1)** | 2025-08-19 |  |
| **[The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](http://arxiv.org/abs/2508.13030v1)** | 2025-08-18 | <details><summary>21 pa...</summary><p>21 pages, 6 figures,Proceedings of the IEEE International Conference on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto, Canada, July 8-11, 2025</p></details> |
| **[Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](http://arxiv.org/abs/2508.12920v1)** | 2025-08-18 |  |
| **[Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models](http://arxiv.org/abs/2412.05934v3)** | 2025-08-18 | ICCV 2025 |
| **[Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position](http://arxiv.org/abs/2508.12398v1)** | 2025-08-17 |  |
| **[ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](http://arxiv.org/abs/2508.12384v1)** | 2025-08-17 |  |
| **[MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols](http://arxiv.org/abs/2508.13220v1)** | 2025-08-17 | <details><summary>This ...</summary><p>This is a technical report from Lingnan University, Hong Kong</p></details> |
| **[SHoM: A Mental-Synthesis Trust Management Model for Mitigating Botnet-Driven DDoS Attacks in the Internet of Things](http://arxiv.org/abs/2507.21178v3)** | 2025-08-16 | <details><summary>22 Pa...</summary><p>22 Pages, 15 figure, 9 tables</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedUP: Efficient Pruning-based Federated Unlearning for Model Poisoning Attacks](http://arxiv.org/abs/2508.13853v1)** | 2025-08-19 | <details><summary>15 pa...</summary><p>15 pages, 5 figures, 7 tables</p></details> |
| **[Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance](http://arxiv.org/abs/2508.13739v1)** | 2025-08-19 |  |
| **[The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](http://arxiv.org/abs/2508.13030v1)** | 2025-08-18 | <details><summary>21 pa...</summary><p>21 pages, 6 figures,Proceedings of the IEEE International Conference on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto, Canada, July 8-11, 2025</p></details> |
| **[Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](http://arxiv.org/abs/2508.12920v1)** | 2025-08-18 |  |
| **[Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models](http://arxiv.org/abs/2412.05934v3)** | 2025-08-18 | ICCV 2025 |
| **[Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position](http://arxiv.org/abs/2508.12398v1)** | 2025-08-17 |  |
| **[ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](http://arxiv.org/abs/2508.12384v1)** | 2025-08-17 |  |
| **[MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols](http://arxiv.org/abs/2508.13220v1)** | 2025-08-17 | <details><summary>This ...</summary><p>This is a technical report from Lingnan University, Hong Kong</p></details> |
| **[SHoM: A Mental-Synthesis Trust Management Model for Mitigating Botnet-Driven DDoS Attacks in the Internet of Things](http://arxiv.org/abs/2507.21178v3)** | 2025-08-16 | <details><summary>22 Pa...</summary><p>22 Pages, 15 figure, 9 tables</p></details> |

