---
title: Latest 15 Papers - August 08, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |
| **[AttnTrace: Attention-based Context Traceback for Long-Context LLMs](http://arxiv.org/abs/2508.03793v1)** | 2025-08-05 | <details><summary>The c...</summary><p>The code is available at https://github.com/Wang-Yanting/AttnTrace. The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace</p></details> |
| **[M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs](http://arxiv.org/abs/2503.04856v3)** | 2025-08-05 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Main Track). Camera-ready version</p></details> |
| **[Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](http://arxiv.org/abs/2508.03125v1)** | 2025-08-05 |  |
| **[VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](http://arxiv.org/abs/2508.03097v1)** | 2025-08-05 | <details><summary>12 pa...</summary><p>12 pages, 10 figures, published in KDD2025</p></details> |
| **[Defend LLMs Through Self-Consciousness](http://arxiv.org/abs/2508.02961v1)** | 2025-08-04 | <details><summary>Prese...</summary><p>Presented at KDD Workshop on Ethical Artificial Intelligence: Methods and Applications (EAI) 2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |
| **[AttnTrace: Attention-based Context Traceback for Long-Context LLMs](http://arxiv.org/abs/2508.03793v1)** | 2025-08-05 | <details><summary>The c...</summary><p>The code is available at https://github.com/Wang-Yanting/AttnTrace. The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace</p></details> |
| **[M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs](http://arxiv.org/abs/2503.04856v3)** | 2025-08-05 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Main Track). Camera-ready version</p></details> |
| **[Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](http://arxiv.org/abs/2508.03125v1)** | 2025-08-05 |  |
| **[VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](http://arxiv.org/abs/2508.03097v1)** | 2025-08-05 | <details><summary>12 pa...</summary><p>12 pages, 10 figures, published in KDD2025</p></details> |
| **[Defend LLMs Through Self-Consciousness](http://arxiv.org/abs/2508.02961v1)** | 2025-08-04 | <details><summary>Prese...</summary><p>Presented at KDD Workshop on Ethical Artificial Intelligence: Methods and Applications (EAI) 2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prompt Obfuscation for Large Language Models](http://arxiv.org/abs/2409.11026v4)** | 2025-08-06 |  |
| **[A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models](http://arxiv.org/abs/2508.04276v1)** | 2025-08-06 |  |
| **[ReasoningGuard: Safeguarding Large Reasoning Models with Inference-time Safety Aha Moments](http://arxiv.org/abs/2508.04204v1)** | 2025-08-06 |  |
| **[Eliciting and Analyzing Emergent Misalignment in State-of-the-Art Large Language Models](http://arxiv.org/abs/2508.04196v1)** | 2025-08-06 |  |
| **[Random Erasing vs. Model Inversion: A Promising Defense or a False Hope?](http://arxiv.org/abs/2409.01062v3)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted in Transactions on Machine Learning Research (TMLR). First two authors contributed equally</p></details> |
| **[Model Inversion Attacks on Vision-Language Models: Do They Leak What They Learn?](http://arxiv.org/abs/2508.04097v1)** | 2025-08-06 | Under review |
| **[Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application](http://arxiv.org/abs/2503.06989v3)** | 2025-08-06 |  |
| **[CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](http://arxiv.org/abs/2508.02997v2)** | 2025-08-06 |  |
| **[Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code](http://arxiv.org/abs/2508.03949v1)** | 2025-08-05 |  |
| **[Understanding In-Context Learning of Linear Models in Transformers Through an Adversarial Lens](http://arxiv.org/abs/2411.05189v2)** | 2025-08-05 | <details><summary>Trans...</summary><p>Transactions on Machine Learning Research (TMLR) 2025, with Featured Certification</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prompt Obfuscation for Large Language Models](http://arxiv.org/abs/2409.11026v4)** | 2025-08-06 |  |
| **[A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models](http://arxiv.org/abs/2508.04276v1)** | 2025-08-06 |  |
| **[ReasoningGuard: Safeguarding Large Reasoning Models with Inference-time Safety Aha Moments](http://arxiv.org/abs/2508.04204v1)** | 2025-08-06 |  |
| **[Eliciting and Analyzing Emergent Misalignment in State-of-the-Art Large Language Models](http://arxiv.org/abs/2508.04196v1)** | 2025-08-06 |  |
| **[Random Erasing vs. Model Inversion: A Promising Defense or a False Hope?](http://arxiv.org/abs/2409.01062v3)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted in Transactions on Machine Learning Research (TMLR). First two authors contributed equally</p></details> |
| **[Model Inversion Attacks on Vision-Language Models: Do They Leak What They Learn?](http://arxiv.org/abs/2508.04097v1)** | 2025-08-06 | Under review |
| **[Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application](http://arxiv.org/abs/2503.06989v3)** | 2025-08-06 |  |
| **[CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](http://arxiv.org/abs/2508.02997v2)** | 2025-08-06 |  |
| **[Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code](http://arxiv.org/abs/2508.03949v1)** | 2025-08-05 |  |
| **[Understanding In-Context Learning of Linear Models in Transformers Through an Adversarial Lens](http://arxiv.org/abs/2411.05189v2)** | 2025-08-05 | <details><summary>Trans...</summary><p>Transactions on Machine Learning Research (TMLR) 2025, with Featured Certification</p></details> |

