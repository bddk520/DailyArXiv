---
title: Latest 15 Papers - December 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Async Control: Stress-testing Asynchronous Control Measures for LLM Agents](https://arxiv.org/abs/2512.13526v1)** | 2025-12-15 |  |
| **[When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449v2)** | 2025-12-15 |  |
| **[ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321v3)** | 2025-12-15 | <details><summary>To ap...</summary><p>To appear in NDSS 2026. For slides, see https://people.duke.edu/~zg70/code/PromptInjection.pdf</p></details> |
| **[CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs](https://arxiv.org/abs/2512.12914v1)** | 2025-12-15 | <details><summary>Accep...</summary><p>Accepted at the 18th Cybersecurity Experimentation and Test Workshop (CSET), in conjunction with ACSAC 2025</p></details> |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260v2)** | 2025-12-14 | <details><summary>The p...</summary><p>The paper is published in ICT Express (Elsevier)</p></details> |
| **[LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878v4)** | 2025-12-14 |  |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v3)** | 2025-12-13 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[BreakFun: Jailbreaking LLMs via Schema Exploitation](https://arxiv.org/abs/2510.17904v2)** | 2025-12-13 |  |
| **[Taint-Based Code Slicing for LLMs-based Malicious NPM Package Detection](https://arxiv.org/abs/2512.12313v1)** | 2025-12-13 | <details><summary>17 pa...</summary><p>17 pages, 4 figures, 9 tables</p></details> |
| **[Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting](https://arxiv.org/abs/2512.12154v1)** | 2025-12-13 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Async Control: Stress-testing Asynchronous Control Measures for LLM Agents](https://arxiv.org/abs/2512.13526v1)** | 2025-12-15 |  |
| **[When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449v2)** | 2025-12-15 |  |
| **[ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321v3)** | 2025-12-15 | <details><summary>To ap...</summary><p>To appear in NDSS 2026. For slides, see https://people.duke.edu/~zg70/code/PromptInjection.pdf</p></details> |
| **[CTIGuardian: A Few-Shot Framework for Mitigating Privacy Leakage in Fine-Tuned LLMs](https://arxiv.org/abs/2512.12914v1)** | 2025-12-15 | <details><summary>Accep...</summary><p>Accepted at the 18th Cybersecurity Experimentation and Test Workshop (CSET), in conjunction with ACSAC 2025</p></details> |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260v2)** | 2025-12-14 | <details><summary>The p...</summary><p>The paper is published in ICT Express (Elsevier)</p></details> |
| **[LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878v4)** | 2025-12-14 |  |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v3)** | 2025-12-13 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[BreakFun: Jailbreaking LLMs via Schema Exploitation](https://arxiv.org/abs/2510.17904v2)** | 2025-12-13 |  |
| **[Taint-Based Code Slicing for LLMs-based Malicious NPM Package Detection](https://arxiv.org/abs/2512.12313v1)** | 2025-12-13 | <details><summary>17 pa...</summary><p>17 pages, 4 figures, 9 tables</p></details> |
| **[Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting](https://arxiv.org/abs/2512.12154v1)** | 2025-12-13 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models](https://arxiv.org/abs/2512.13352v1)** | 2025-12-15 | <details><summary>Accep...</summary><p>Accepted to IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2026</p></details> |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](https://arxiv.org/abs/2501.02968v5)** | 2025-12-15 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2509.22082v2)** | 2025-12-15 |  |
| **[SA$^{2}$GFM: Enhancing Robust Graph Foundation Models with Structure-Aware Semantic Augmentation](https://arxiv.org/abs/2512.07857v2)** | 2025-12-15 |  |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](https://arxiv.org/abs/2505.24592v3)** | 2025-12-14 | <details><summary>In Pr...</summary><p>In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) 2026, Singapore</p></details> |
| **[Phishing Email Detection Using Large Language Models](https://arxiv.org/abs/2512.10104v2)** | 2025-12-14 | 7 pages |
| **[Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks](https://arxiv.org/abs/2512.10637v2)** | 2025-12-13 | <details><summary>7 pag...</summary><p>7 pages,3 figures, 2 Table. Neha and T. Bhatia "Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks" (2025) 103-107</p></details> |
| **[Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://arxiv.org/abs/2512.12069v1)** | 2025-12-12 | 40 pages, 13 figures |
| **[Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously](https://arxiv.org/abs/2512.11783v1)** | 2025-12-12 | 13 pages, 5 Figures |
| **[Defense That Attacks: How Robust Models Become Better Attackers](https://arxiv.org/abs/2512.02830v3)** | 2025-12-12 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models](https://arxiv.org/abs/2512.13352v1)** | 2025-12-15 | <details><summary>Accep...</summary><p>Accepted to IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2026</p></details> |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](https://arxiv.org/abs/2501.02968v5)** | 2025-12-15 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2509.22082v2)** | 2025-12-15 |  |
| **[SA$^{2}$GFM: Enhancing Robust Graph Foundation Models with Structure-Aware Semantic Augmentation](https://arxiv.org/abs/2512.07857v2)** | 2025-12-15 |  |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](https://arxiv.org/abs/2505.24592v3)** | 2025-12-14 | <details><summary>In Pr...</summary><p>In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) 2026, Singapore</p></details> |
| **[Phishing Email Detection Using Large Language Models](https://arxiv.org/abs/2512.10104v2)** | 2025-12-14 | 7 pages |
| **[Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks](https://arxiv.org/abs/2512.10637v2)** | 2025-12-13 | <details><summary>7 pag...</summary><p>7 pages,3 figures, 2 Table. Neha and T. Bhatia "Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks" (2025) 103-107</p></details> |
| **[Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://arxiv.org/abs/2512.12069v1)** | 2025-12-12 | 40 pages, 13 figures |
| **[Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously](https://arxiv.org/abs/2512.11783v1)** | 2025-12-12 | 13 pages, 5 Figures |
| **[Defense That Attacks: How Robust Models Become Better Attackers](https://arxiv.org/abs/2512.02830v3)** | 2025-12-12 |  |

