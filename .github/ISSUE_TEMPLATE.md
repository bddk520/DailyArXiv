---
title: Latest 15 Papers - January 06, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems](https://arxiv.org/abs/2601.00566v1)** | 2026-01-02 | 8 figures, 8 tables |
| **[From Description to Score: Can LLMs Quantify Vulnerabilities?](https://arxiv.org/abs/2512.06781v2)** | 2026-01-01 | 10 pages |
| **[Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments](https://arxiv.org/abs/2511.13788v2)** | 2026-01-01 |  |
| **[Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240v1)** | 2026-01-01 | 16 pages |
| **[Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak](https://arxiv.org/abs/2601.00213v1)** | 2026-01-01 |  |
| **[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065v1)** | 2025-12-31 |  |
| **[Effective and Efficient Jailbreaks of Black-Box LLMs with Cross-Behavior Attacks](https://arxiv.org/abs/2503.08990v2)** | 2025-12-31 | <details><summary>Code ...</summary><p>Code is at https://github.com/gohil-vasudev/JCB</p></details> |
| **[Illusions of Relevance: Arbitrary Content Injection Attacks Deceive Retrievers, Rerankers, and LLM Judges](https://arxiv.org/abs/2501.18536v2)** | 2025-12-30 | AACL Findings 2025 |
| **[Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?](https://arxiv.org/abs/2512.24044v1)** | 2025-12-30 | <details><summary>26 pa...</summary><p>26 pages,11 tables, 7 figures</p></details> |
| **[RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress](https://arxiv.org/abs/2512.23995v1)** | 2025-12-30 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems](https://arxiv.org/abs/2601.00566v1)** | 2026-01-02 | 8 figures, 8 tables |
| **[From Description to Score: Can LLMs Quantify Vulnerabilities?](https://arxiv.org/abs/2512.06781v2)** | 2026-01-01 | 10 pages |
| **[Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments](https://arxiv.org/abs/2511.13788v2)** | 2026-01-01 |  |
| **[Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240v1)** | 2026-01-01 | 16 pages |
| **[Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak](https://arxiv.org/abs/2601.00213v1)** | 2026-01-01 |  |
| **[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065v1)** | 2025-12-31 |  |
| **[Effective and Efficient Jailbreaks of Black-Box LLMs with Cross-Behavior Attacks](https://arxiv.org/abs/2503.08990v2)** | 2025-12-31 | <details><summary>Code ...</summary><p>Code is at https://github.com/gohil-vasudev/JCB</p></details> |
| **[Illusions of Relevance: Arbitrary Content Injection Attacks Deceive Retrievers, Rerankers, and LLM Judges](https://arxiv.org/abs/2501.18536v2)** | 2025-12-30 | AACL Findings 2025 |
| **[Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?](https://arxiv.org/abs/2512.24044v1)** | 2025-12-30 | <details><summary>26 pa...</summary><p>26 pages,11 tables, 7 figures</p></details> |
| **[RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress](https://arxiv.org/abs/2512.23995v1)** | 2025-12-30 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v2)** | 2026-01-02 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version)</p></details> |
| **[Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454v1)** | 2026-01-01 |  |
| **[FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models](https://arxiv.org/abs/2505.15683v4)** | 2026-01-01 |  |
| **[AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving](https://arxiv.org/abs/2412.15206v2)** | 2026-01-01 | <details><summary>Publi...</summary><p>Published at TMLR 2025</p></details> |
| **[One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org/abs/2505.07167v3)** | 2026-01-01 |  |
| **[Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042v1)** | 2025-12-31 |  |
| **[APT-CGLP: Advanced Persistent Threat Hunting via Contrastive Graph-Language Pre-Training](https://arxiv.org/abs/2511.20290v2)** | 2025-12-31 | <details><summary>Accep...</summary><p>Accepted by SIGKDD 2026 Research Track</p></details> |
| **[Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service](https://arxiv.org/abs/2512.24415v1)** | 2025-12-30 |  |
| **[SourceBroken: A large-scale analysis on the (un)reliability of SourceRank in the PyPI ecosystem](https://arxiv.org/abs/2512.24400v1)** | 2025-12-30 | <details><summary>Accpt...</summary><p>Accpted for the 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26), March 23--27, 2026, Thessaloniki, Greece</p></details> |
| **[Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms](https://arxiv.org/abs/2512.20391v3)** | 2025-12-30 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v2)** | 2026-01-02 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version)</p></details> |
| **[Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454v1)** | 2026-01-01 |  |
| **[FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models](https://arxiv.org/abs/2505.15683v4)** | 2026-01-01 |  |
| **[AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving](https://arxiv.org/abs/2412.15206v2)** | 2026-01-01 | <details><summary>Publi...</summary><p>Published at TMLR 2025</p></details> |
| **[One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org/abs/2505.07167v3)** | 2026-01-01 |  |
| **[Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042v1)** | 2025-12-31 |  |
| **[APT-CGLP: Advanced Persistent Threat Hunting via Contrastive Graph-Language Pre-Training](https://arxiv.org/abs/2511.20290v2)** | 2025-12-31 | <details><summary>Accep...</summary><p>Accepted by SIGKDD 2026 Research Track</p></details> |
| **[Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service](https://arxiv.org/abs/2512.24415v1)** | 2025-12-30 |  |
| **[SourceBroken: A large-scale analysis on the (un)reliability of SourceRank in the PyPI ecosystem](https://arxiv.org/abs/2512.24400v1)** | 2025-12-30 | <details><summary>Accpt...</summary><p>Accpted for the 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26), March 23--27, 2026, Thessaloniki, Greece</p></details> |
| **[Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms](https://arxiv.org/abs/2512.20391v3)** | 2025-12-30 |  |

