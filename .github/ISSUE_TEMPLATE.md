---
title: Latest 15 Papers - May 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](http://arxiv.org/abs/2505.15738v1)** | 2025-05-21 |  |
| **[A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](http://arxiv.org/abs/2505.15683v1)** | 2025-05-21 |  |
| **[Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](http://arxiv.org/abs/2505.15656v1)** | 2025-05-21 | 19 pages |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |
| **[Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack](http://arxiv.org/abs/2505.15323v1)** | 2025-05-21 | <details><summary>13 pa...</summary><p>13 pages, 5 figures, 7 tables</p></details> |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v3)** | 2025-05-21 | <details><summary>New v...</summary><p>New version of the paper</p></details> |
| **[AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents](http://arxiv.org/abs/2505.05849v2)** | 2025-05-21 |  |
| **[MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](http://arxiv.org/abs/2504.15241v2)** | 2025-05-20 | Preprint |
| **[Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders](http://arxiv.org/abs/2505.14536v1)** | 2025-05-20 | <details><summary>Prepr...</summary><p>Preprint: 19 pages, 7 figures, 1 table</p></details> |
| **[Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs](http://arxiv.org/abs/2505.14368v1)** | 2025-05-20 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, EMNLP 2025 under review</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](http://arxiv.org/abs/2505.15738v1)** | 2025-05-21 |  |
| **[A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](http://arxiv.org/abs/2505.15683v1)** | 2025-05-21 |  |
| **[Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](http://arxiv.org/abs/2505.15656v1)** | 2025-05-21 | 19 pages |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |
| **[Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack](http://arxiv.org/abs/2505.15323v1)** | 2025-05-21 | <details><summary>13 pa...</summary><p>13 pages, 5 figures, 7 tables</p></details> |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v3)** | 2025-05-21 | <details><summary>New v...</summary><p>New version of the paper</p></details> |
| **[AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents](http://arxiv.org/abs/2505.05849v2)** | 2025-05-21 |  |
| **[MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](http://arxiv.org/abs/2504.15241v2)** | 2025-05-20 | Preprint |
| **[Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders](http://arxiv.org/abs/2505.14536v1)** | 2025-05-20 | <details><summary>Prepr...</summary><p>Preprint: 19 pages, 7 figures, 1 table</p></details> |
| **[Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs](http://arxiv.org/abs/2505.14368v1)** | 2025-05-20 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, EMNLP 2025 under review</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering](http://arxiv.org/abs/2505.15805v1)** | 2025-05-21 |  |
| **[Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models](http://arxiv.org/abs/2412.17034v2)** | 2025-05-21 | 17 pages, 9 figures |
| **[SQL Injection Jailbreak: A Structural Disaster of Large Language Models](http://arxiv.org/abs/2411.01565v6)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted by findings of ACL 2025</p></details> |
| **[SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings](http://arxiv.org/abs/2502.12562v2)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted in ACL 2025 Main Track</p></details> |
| **[Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](http://arxiv.org/abs/2505.15406v1)** | 2025-05-21 | <details><summary>We re...</summary><p>We release AJailBench, including both static and optimized adversarial data, to facilitate future research: https://github.com/mbzuai-nlp/AudioJailbreak</p></details> |
| **[RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](http://arxiv.org/abs/2505.15386v1)** | 2025-05-21 |  |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |
| **[My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping](http://arxiv.org/abs/2505.15336v1)** | 2025-05-21 |  |
| **[Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models](http://arxiv.org/abs/2505.15332v1)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted at IEEE International Conference on Automatic Face and Gesture Recognition (FG 2025)</p></details> |
| **[Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models](http://arxiv.org/abs/2505.15130v1)** | 2025-05-21 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering](http://arxiv.org/abs/2505.15805v1)** | 2025-05-21 |  |
| **[Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models](http://arxiv.org/abs/2412.17034v2)** | 2025-05-21 | 17 pages, 9 figures |
| **[SQL Injection Jailbreak: A Structural Disaster of Large Language Models](http://arxiv.org/abs/2411.01565v6)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted by findings of ACL 2025</p></details> |
| **[SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings](http://arxiv.org/abs/2502.12562v2)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted in ACL 2025 Main Track</p></details> |
| **[Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](http://arxiv.org/abs/2505.15406v1)** | 2025-05-21 | <details><summary>We re...</summary><p>We release AJailBench, including both static and optimized adversarial data, to facilitate future research: https://github.com/mbzuai-nlp/AudioJailbreak</p></details> |
| **[RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](http://arxiv.org/abs/2505.15386v1)** | 2025-05-21 |  |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |
| **[My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping](http://arxiv.org/abs/2505.15336v1)** | 2025-05-21 |  |
| **[Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models](http://arxiv.org/abs/2505.15332v1)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted at IEEE International Conference on Automatic Face and Gesture Recognition (FG 2025)</p></details> |
| **[Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models](http://arxiv.org/abs/2505.15130v1)** | 2025-05-21 |  |

