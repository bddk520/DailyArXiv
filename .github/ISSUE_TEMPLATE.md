---
title: Latest 15 Papers - February 25, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Interpreting and Steering LLMs with Mutual Information-based Explanations on Sparse Autoencoders](http://arxiv.org/abs/2502.15576v1)** | 2025-02-21 | <details><summary>Pre-p...</summary><p>Pre-print. 20 pages, 5 figures</p></details> |
| **[Construction and Evaluation of LLM-based agents for Semi-Autonomous penetration testing](http://arxiv.org/abs/2502.15506v1)** | 2025-02-21 | <details><summary>7 pag...</summary><p>7 pages, 4 tables and 1 figure</p></details> |
| **[Adversarial Prompt Evaluation: Systematic Benchmarking of Guardrails Against Prompt Input Attacks on LLMs](http://arxiv.org/abs/2502.15427v1)** | 2025-02-21 | <details><summary>NeurI...</summary><p>NeurIPS 2024, Safe Generative AI Workshop</p></details> |
| **[Red-Teaming LLM Multi-Agent Systems via Communication Attacks](http://arxiv.org/abs/2502.14847v1)** | 2025-02-20 |  |
| **[Fundamental Limitations in Defending LLM Finetuning APIs](http://arxiv.org/abs/2502.14828v1)** | 2025-02-20 |  |
| **[PEARL: Towards Permutation-Resilient LLMs](http://arxiv.org/abs/2502.14628v1)** | 2025-02-20 | ICLR 2025 |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v2)** | 2025-02-20 |  |
| **[Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning](http://arxiv.org/abs/2502.14215v1)** | 2025-02-20 |  |
| **[Multi-Faceted Studies on Data Poisoning can Advance LLM Development](http://arxiv.org/abs/2502.14182v1)** | 2025-02-20 |  |
| **[Theoretically Grounded Framework for LLM Watermarking: A Distribution-Adaptive Approach](http://arxiv.org/abs/2410.02890v4)** | 2025-02-19 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Interpreting and Steering LLMs with Mutual Information-based Explanations on Sparse Autoencoders](http://arxiv.org/abs/2502.15576v1)** | 2025-02-21 | <details><summary>Pre-p...</summary><p>Pre-print. 20 pages, 5 figures</p></details> |
| **[Construction and Evaluation of LLM-based agents for Semi-Autonomous penetration testing](http://arxiv.org/abs/2502.15506v1)** | 2025-02-21 | <details><summary>7 pag...</summary><p>7 pages, 4 tables and 1 figure</p></details> |
| **[Adversarial Prompt Evaluation: Systematic Benchmarking of Guardrails Against Prompt Input Attacks on LLMs](http://arxiv.org/abs/2502.15427v1)** | 2025-02-21 | <details><summary>NeurI...</summary><p>NeurIPS 2024, Safe Generative AI Workshop</p></details> |
| **[Red-Teaming LLM Multi-Agent Systems via Communication Attacks](http://arxiv.org/abs/2502.14847v1)** | 2025-02-20 |  |
| **[Fundamental Limitations in Defending LLM Finetuning APIs](http://arxiv.org/abs/2502.14828v1)** | 2025-02-20 |  |
| **[PEARL: Towards Permutation-Resilient LLMs](http://arxiv.org/abs/2502.14628v1)** | 2025-02-20 | ICLR 2025 |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v2)** | 2025-02-20 |  |
| **[Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning](http://arxiv.org/abs/2502.14215v1)** | 2025-02-20 |  |
| **[Multi-Faceted Studies on Data Poisoning can Advance LLM Development](http://arxiv.org/abs/2502.14182v1)** | 2025-02-20 |  |
| **[Theoretically Grounded Framework for LLM Watermarking: A Distribution-Adaptive Approach](http://arxiv.org/abs/2410.02890v4)** | 2025-02-19 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention](http://arxiv.org/abs/2502.15594v1)** | 2025-02-21 |  |
| **[Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses](http://arxiv.org/abs/2502.15567v1)** | 2025-02-21 |  |
| **[Single-pass Detection of Jailbreaking Input in Large Language Models](http://arxiv.org/abs/2502.15435v1)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accepted in TMLR 2025</p></details> |
| **[R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge](http://arxiv.org/abs/2411.18220v3)** | 2025-02-21 |  |
| **[Backdoor Attacks against No-Reference Image Quality Assessment Models via a Scalable Trigger](http://arxiv.org/abs/2412.07277v3)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accept by AAAI 2025 (Also fix the typo mistakes in line 9 of the Algorithm 2 in the AAAI camera-ready version)</p></details> |
| **[Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective](http://arxiv.org/abs/2401.06824v5)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accepted by COLING 2025</p></details> |
| **[HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States](http://arxiv.org/abs/2502.14744v2)** | 2025-02-21 |  |
| **[SMTFL: Secure Model Training to Untrusted Participants in Federated Learning](http://arxiv.org/abs/2502.02038v2)** | 2025-02-21 |  |
| **[MACPruning: Dynamic Operation Pruning to Mitigate Side-Channel DNN Model Extraction](http://arxiv.org/abs/2502.15020v1)** | 2025-02-20 | <details><summary>This ...</summary><p>This paper is accepted by HOST 2025</p></details> |
| **[EigenShield: Causal Subspace Filtering via Random Matrix Theory for Adversarially Robust Vision-Language Models](http://arxiv.org/abs/2502.14976v1)** | 2025-02-20 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention](http://arxiv.org/abs/2502.15594v1)** | 2025-02-21 |  |
| **[Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses](http://arxiv.org/abs/2502.15567v1)** | 2025-02-21 |  |
| **[Single-pass Detection of Jailbreaking Input in Large Language Models](http://arxiv.org/abs/2502.15435v1)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accepted in TMLR 2025</p></details> |
| **[R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge](http://arxiv.org/abs/2411.18220v3)** | 2025-02-21 |  |
| **[Backdoor Attacks against No-Reference Image Quality Assessment Models via a Scalable Trigger](http://arxiv.org/abs/2412.07277v3)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accept by AAAI 2025 (Also fix the typo mistakes in line 9 of the Algorithm 2 in the AAAI camera-ready version)</p></details> |
| **[Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective](http://arxiv.org/abs/2401.06824v5)** | 2025-02-21 | <details><summary>Accep...</summary><p>Accepted by COLING 2025</p></details> |
| **[HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States](http://arxiv.org/abs/2502.14744v2)** | 2025-02-21 |  |
| **[SMTFL: Secure Model Training to Untrusted Participants in Federated Learning](http://arxiv.org/abs/2502.02038v2)** | 2025-02-21 |  |
| **[MACPruning: Dynamic Operation Pruning to Mitigate Side-Channel DNN Model Extraction](http://arxiv.org/abs/2502.15020v1)** | 2025-02-20 | <details><summary>This ...</summary><p>This paper is accepted by HOST 2025</p></details> |
| **[EigenShield: Causal Subspace Filtering via Random Matrix Theory for Adversarially Robust Vision-Language Models](http://arxiv.org/abs/2502.14976v1)** | 2025-02-20 |  |

