---
title: Latest 15 Papers - May 29, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](http://arxiv.org/abs/2505.20824v1)** | 2025-05-27 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v4)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[Capability-Based Scaling Laws for LLM Red-Teaming](http://arxiv.org/abs/2505.20162v1)** | 2025-05-26 |  |
| **[PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks](http://arxiv.org/abs/2505.13862v3)** | 2025-05-26 |  |
| **[Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings](http://arxiv.org/abs/2412.13879v4)** | 2025-05-26 | <details><summary>22 pa...</summary><p>22 pages, 8 figures, 11 tables</p></details> |
| **[JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs](http://arxiv.org/abs/2402.05668v3)** | 2025-05-26 | <details><summary>Corre...</summary><p>Correct typos and update new experiment results. Accepted in ACL 2025. 25 pages, 12 figures</p></details> |
| **[Firewalls to Secure Dynamic LLM Agentic Networks](http://arxiv.org/abs/2502.01822v5)** | 2025-05-26 |  |
| **[What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs](http://arxiv.org/abs/2505.19773v1)** | 2025-05-26 | Accepted by ACL 2025 |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v2)** | 2025-05-26 |  |
| **[Robo-Troj: Attacking LLM-based Task Planners](http://arxiv.org/abs/2504.17070v2)** | 2025-05-26 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](http://arxiv.org/abs/2505.20824v1)** | 2025-05-27 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v4)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[Capability-Based Scaling Laws for LLM Red-Teaming](http://arxiv.org/abs/2505.20162v1)** | 2025-05-26 |  |
| **[PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks](http://arxiv.org/abs/2505.13862v3)** | 2025-05-26 |  |
| **[Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings](http://arxiv.org/abs/2412.13879v4)** | 2025-05-26 | <details><summary>22 pa...</summary><p>22 pages, 8 figures, 11 tables</p></details> |
| **[JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs](http://arxiv.org/abs/2402.05668v3)** | 2025-05-26 | <details><summary>Corre...</summary><p>Correct typos and update new experiment results. Accepted in ACL 2025. 25 pages, 12 figures</p></details> |
| **[Firewalls to Secure Dynamic LLM Agentic Networks](http://arxiv.org/abs/2502.01822v5)** | 2025-05-26 |  |
| **[What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs](http://arxiv.org/abs/2505.19773v1)** | 2025-05-26 | Accepted by ACL 2025 |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v2)** | 2025-05-26 |  |
| **[Robo-Troj: Attacking LLM-based Task Planners](http://arxiv.org/abs/2504.17070v2)** | 2025-05-26 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Are Concepts Erased From Diffusion Models?](http://arxiv.org/abs/2505.17013v3)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project Page: https://nyu-dice-lab.github.io/when-are-concepts-erased/</p></details> |
| **[Securing Federated Learning against Backdoor Threats with Foundation Model Integration](http://arxiv.org/abs/2410.17573v3)** | 2025-05-27 | <details><summary>This ...</summary><p>This paper has been accepted to IEEE IRI 2025</p></details> |
| **[Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](http://arxiv.org/abs/2502.06832v3)** | 2025-05-27 | <details><summary>15 pa...</summary><p>15 pages, 7 figures, accepted by ICML 2025</p></details> |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](http://arxiv.org/abs/2505.16670v2)** | 2025-05-27 |  |
| **[Tradeoffs Between Alignment and Helpfulness in Language Models with Steering Methods](http://arxiv.org/abs/2401.16332v5)** | 2025-05-27 |  |
| **[Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models](http://arxiv.org/abs/2505.20955v1)** | 2025-05-27 |  |
| **[IRCopilot: Automated Incident Response with Large Language Models](http://arxiv.org/abs/2505.20945v1)** | 2025-05-27 |  |
| **[TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](http://arxiv.org/abs/2505.20118v2)** | 2025-05-27 | 9 pages, 5 figures |
| **[Improved Representation Steering for Language Models](http://arxiv.org/abs/2505.20809v1)** | 2025-05-27 | <details><summary>46 pa...</summary><p>46 pages, 23 figures, preprint</p></details> |
| **[Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks](http://arxiv.org/abs/2505.12786v2)** | 2025-05-27 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Are Concepts Erased From Diffusion Models?](http://arxiv.org/abs/2505.17013v3)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project Page: https://nyu-dice-lab.github.io/when-are-concepts-erased/</p></details> |
| **[Securing Federated Learning against Backdoor Threats with Foundation Model Integration](http://arxiv.org/abs/2410.17573v3)** | 2025-05-27 | <details><summary>This ...</summary><p>This paper has been accepted to IEEE IRI 2025</p></details> |
| **[Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach](http://arxiv.org/abs/2502.06832v3)** | 2025-05-27 | <details><summary>15 pa...</summary><p>15 pages, 7 figures, accepted by ICML 2025</p></details> |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](http://arxiv.org/abs/2505.16670v2)** | 2025-05-27 |  |
| **[Tradeoffs Between Alignment and Helpfulness in Language Models with Steering Methods](http://arxiv.org/abs/2401.16332v5)** | 2025-05-27 |  |
| **[Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models](http://arxiv.org/abs/2505.20955v1)** | 2025-05-27 |  |
| **[IRCopilot: Automated Incident Response with Large Language Models](http://arxiv.org/abs/2505.20945v1)** | 2025-05-27 |  |
| **[TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](http://arxiv.org/abs/2505.20118v2)** | 2025-05-27 | 9 pages, 5 figures |
| **[Improved Representation Steering for Language Models](http://arxiv.org/abs/2505.20809v1)** | 2025-05-27 | <details><summary>46 pa...</summary><p>46 pages, 23 figures, preprint</p></details> |
| **[Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks](http://arxiv.org/abs/2505.12786v2)** | 2025-05-27 |  |

