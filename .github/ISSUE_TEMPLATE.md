---
title: Latest 15 Papers - July 22, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v4)** | 2025-07-18 | <details><summary>Final...</summary><p>Final Version and Paper Accepted at IEEE ITSC 2025</p></details> |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v2)** | 2025-07-17 |  |
| **[Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](http://arxiv.org/abs/2507.13474v1)** | 2025-07-17 |  |
| **[Detecting LLM-generated Code with Subtle Modification by Adversarial Training](http://arxiv.org/abs/2507.13123v1)** | 2025-07-17 |  |
| **[LLMs Encode Harmfulness and Refusal Separately](http://arxiv.org/abs/2507.11878v1)** | 2025-07-16 |  |
| **[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](http://arxiv.org/abs/2505.23847v3)** | 2025-07-15 |  |
| **[A Generative Approach to LLM Harmfulness Detection with Special Red Flag Tokens](http://arxiv.org/abs/2502.16366v3)** | 2025-07-15 | 14 pages, 6 figures |
| **[Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs](http://arxiv.org/abs/2507.11112v1)** | 2025-07-15 |  |
| **[The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](http://arxiv.org/abs/2507.11097v1)** | 2025-07-15 | <details><summary>21 pa...</summary><p>21 pages, 9 figures, work in progress</p></details> |
| **[From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection](http://arxiv.org/abs/2507.10873v1)** | 2025-07-15 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v4)** | 2025-07-18 | <details><summary>Final...</summary><p>Final Version and Paper Accepted at IEEE ITSC 2025</p></details> |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v2)** | 2025-07-17 |  |
| **[Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](http://arxiv.org/abs/2507.13474v1)** | 2025-07-17 |  |
| **[Detecting LLM-generated Code with Subtle Modification by Adversarial Training](http://arxiv.org/abs/2507.13123v1)** | 2025-07-17 |  |
| **[LLMs Encode Harmfulness and Refusal Separately](http://arxiv.org/abs/2507.11878v1)** | 2025-07-16 |  |
| **[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](http://arxiv.org/abs/2505.23847v3)** | 2025-07-15 |  |
| **[A Generative Approach to LLM Harmfulness Detection with Special Red Flag Tokens](http://arxiv.org/abs/2502.16366v3)** | 2025-07-15 | 14 pages, 6 figures |
| **[Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs](http://arxiv.org/abs/2507.11112v1)** | 2025-07-15 |  |
| **[The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](http://arxiv.org/abs/2507.11097v1)** | 2025-07-15 | <details><summary>21 pa...</summary><p>21 pages, 9 figures, work in progress</p></details> |
| **[From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection](http://arxiv.org/abs/2507.10873v1)** | 2025-07-15 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VLA-Mark: A cross modal watermark for large vision-language alignment model](http://arxiv.org/abs/2507.14067v1)** | 2025-07-18 |  |
| **[The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems](http://arxiv.org/abs/2507.14007v1)** | 2025-07-18 |  |
| **[GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](http://arxiv.org/abs/2507.13598v1)** | 2025-07-18 | <details><summary>Warni...</summary><p>Warning: This paper contains NSFW content. Reader discretion is advised</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v1)** | 2025-07-17 | <details><summary>Worki...</summary><p>Working in progress. 22 pages (8+ for main); 25 figures; 1 table</p></details> |
| **[Formalizing Attack Scenario Description: A Proposed Model](http://arxiv.org/abs/2507.13076v1)** | 2025-07-17 |  |
| **[JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](http://arxiv.org/abs/2504.03770v3)** | 2025-07-16 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v2)** | 2025-07-16 |  |
| **[InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](http://arxiv.org/abs/2507.12060v1)** | 2025-07-16 | Accepted by MM'25 |
| **[Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](http://arxiv.org/abs/2507.11630v1)** | 2025-07-15 |  |
| **[MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing](http://arxiv.org/abs/2507.11092v1)** | 2025-07-15 | 27 pages |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VLA-Mark: A cross modal watermark for large vision-language alignment model](http://arxiv.org/abs/2507.14067v1)** | 2025-07-18 |  |
| **[The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems](http://arxiv.org/abs/2507.14007v1)** | 2025-07-18 |  |
| **[GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](http://arxiv.org/abs/2507.13598v1)** | 2025-07-18 | <details><summary>Warni...</summary><p>Warning: This paper contains NSFW content. Reader discretion is advised</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v1)** | 2025-07-17 | <details><summary>Worki...</summary><p>Working in progress. 22 pages (8+ for main); 25 figures; 1 table</p></details> |
| **[Formalizing Attack Scenario Description: A Proposed Model](http://arxiv.org/abs/2507.13076v1)** | 2025-07-17 |  |
| **[JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model](http://arxiv.org/abs/2504.03770v3)** | 2025-07-16 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v2)** | 2025-07-16 |  |
| **[InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](http://arxiv.org/abs/2507.12060v1)** | 2025-07-16 | Accepted by MM'25 |
| **[Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](http://arxiv.org/abs/2507.11630v1)** | 2025-07-15 |  |
| **[MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing](http://arxiv.org/abs/2507.11092v1)** | 2025-07-15 | 27 pages |

