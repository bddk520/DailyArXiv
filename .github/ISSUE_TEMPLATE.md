---
title: Latest 15 Papers - July 07, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](http://arxiv.org/abs/2507.02735v1)** | 2025-07-03 |  |
| **[Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents](http://arxiv.org/abs/2507.02699v1)** | 2025-07-03 |  |
| **[MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](http://arxiv.org/abs/2507.02057v1)** | 2025-07-02 |  |
| **[Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](http://arxiv.org/abs/2507.01752v1)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](http://arxiv.org/abs/2507.01513v1)** | 2025-07-02 |  |
| **[Don't Say No: Jailbreaking LLM by Suppressing Refusal](http://arxiv.org/abs/2404.16369v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v4)** | 2025-07-01 |  |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](http://arxiv.org/abs/2507.02735v1)** | 2025-07-03 |  |
| **[Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents](http://arxiv.org/abs/2507.02699v1)** | 2025-07-03 |  |
| **[MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation](http://arxiv.org/abs/2507.02057v1)** | 2025-07-02 |  |
| **[Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](http://arxiv.org/abs/2507.01752v1)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](http://arxiv.org/abs/2507.01513v1)** | 2025-07-02 |  |
| **[Don't Say No: Jailbreaking LLM by Suppressing Refusal](http://arxiv.org/abs/2404.16369v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v4)** | 2025-07-01 |  |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](http://arxiv.org/abs/2507.02799v1)** | 2025-07-03 |  |
| **[StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models](http://arxiv.org/abs/2502.11853v2)** | 2025-07-03 |  |
| **[Evaluating Language Models For Threat Detection in IoT Security Logs](http://arxiv.org/abs/2507.02390v1)** | 2025-07-03 |  |
| **[UniNet: A Unified Multi-granular Traffic Modeling Framework for Network Security](http://arxiv.org/abs/2503.04174v2)** | 2025-07-03 | <details><summary>16 pa...</summary><p>16 pages,6 figures, 12 tables; accepted for publication in IEEE Transactions on Cognitive Communications and Networking, 2025</p></details> |
| **[Threat Modeling for AI: The Case for an Asset-Centric Approach](http://arxiv.org/abs/2505.06315v2)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[Backdooring Bias (B^2) into Stable Diffusion Models](http://arxiv.org/abs/2406.15213v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted to USENIX Security '25</p></details> |
| **[CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs](http://arxiv.org/abs/2507.00817v1)** | 2025-07-01 |  |
| **[Impact of Fine-Tuning Methods on Memorization in Large Language Models](http://arxiv.org/abs/2507.00258v1)** | 2025-06-30 |  |
| **[Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)](http://arxiv.org/abs/2311.10248v3)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2025. This is the full version</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models](http://arxiv.org/abs/2507.02799v1)** | 2025-07-03 |  |
| **[StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models](http://arxiv.org/abs/2502.11853v2)** | 2025-07-03 |  |
| **[Evaluating Language Models For Threat Detection in IoT Security Logs](http://arxiv.org/abs/2507.02390v1)** | 2025-07-03 |  |
| **[UniNet: A Unified Multi-granular Traffic Modeling Framework for Network Security](http://arxiv.org/abs/2503.04174v2)** | 2025-07-03 | <details><summary>16 pa...</summary><p>16 pages,6 figures, 12 tables; accepted for publication in IEEE Transactions on Cognitive Communications and Networking, 2025</p></details> |
| **[Threat Modeling for AI: The Case for an Asset-Centric Approach](http://arxiv.org/abs/2505.06315v2)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[Backdooring Bias (B^2) into Stable Diffusion Models](http://arxiv.org/abs/2406.15213v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted to USENIX Security '25</p></details> |
| **[CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs](http://arxiv.org/abs/2507.00817v1)** | 2025-07-01 |  |
| **[Impact of Fine-Tuning Methods on Memorization in Large Language Models](http://arxiv.org/abs/2507.00258v1)** | 2025-06-30 |  |
| **[Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)](http://arxiv.org/abs/2311.10248v3)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2025. This is the full version</p></details> |

