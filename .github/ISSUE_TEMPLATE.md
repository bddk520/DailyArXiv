---
title: Latest 15 Papers - August 27, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Confidential Prompting: Privacy-preserving LLM Inference on Cloud](http://arxiv.org/abs/2409.19134v4)** | 2025-08-25 |  |
| **[PhantomLint: Principled Detection of Hidden LLM Prompts in Structured Documents](http://arxiv.org/abs/2508.17884v1)** | 2025-08-25 |  |
| **[Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models](http://arxiv.org/abs/2508.17674v1)** | 2025-08-25 | 7 pages, 2 figures |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](http://arxiv.org/abs/2508.17361v1)** | 2025-08-24 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v3)** | 2025-08-24 |  |
| **[Optimization-based Prompt Injection Attack to LLM-as-a-Judge](http://arxiv.org/abs/2403.17710v5)** | 2025-08-24 | <details><summary>To ap...</summary><p>To appear in the Proceedings of The ACM Conference on Computer and Communications Security (CCS), 2024</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v3)** | 2025-08-24 |  |
| **[Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents](http://arxiv.org/abs/2508.17155v1)** | 2025-08-23 | Pre-print |
| **[Mitigating Jailbreaks with Intent-Aware LLMs](http://arxiv.org/abs/2508.12072v2)** | 2025-08-23 |  |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v1)** | 2025-08-22 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Confidential Prompting: Privacy-preserving LLM Inference on Cloud](http://arxiv.org/abs/2409.19134v4)** | 2025-08-25 |  |
| **[PhantomLint: Principled Detection of Hidden LLM Prompts in Structured Documents](http://arxiv.org/abs/2508.17884v1)** | 2025-08-25 |  |
| **[Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models](http://arxiv.org/abs/2508.17674v1)** | 2025-08-25 | 7 pages, 2 figures |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](http://arxiv.org/abs/2508.17361v1)** | 2025-08-24 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v3)** | 2025-08-24 |  |
| **[Optimization-based Prompt Injection Attack to LLM-as-a-Judge](http://arxiv.org/abs/2403.17710v5)** | 2025-08-24 | <details><summary>To ap...</summary><p>To appear in the Proceedings of The ACM Conference on Computer and Communications Security (CCS), 2024</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v3)** | 2025-08-24 |  |
| **[Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents](http://arxiv.org/abs/2508.17155v1)** | 2025-08-23 | Pre-print |
| **[Mitigating Jailbreaks with Intent-Aware LLMs](http://arxiv.org/abs/2508.12072v2)** | 2025-08-23 |  |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v1)** | 2025-08-22 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning](http://arxiv.org/abs/2501.03119v3)** | 2025-08-25 |  |
| **[Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](http://arxiv.org/abs/2502.05945v3)** | 2025-08-25 | <details><summary>Publi...</summary><p>Published at Transaction of Machine Learning Research 08/2025, Large Language Models (LLMs), Interference-time activation shifting, Steerability, Explainability, AI alignment, Interpretability</p></details> |
| **[Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models](http://arxiv.org/abs/2508.17674v1)** | 2025-08-25 | 7 pages, 2 figures |
| **[TombRaider: Entering the Vault of History to Jailbreak Large Language Models](http://arxiv.org/abs/2501.18628v2)** | 2025-08-25 | <details><summary>Main ...</summary><p>Main Conference of EMNLP</p></details> |
| **[Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](http://arxiv.org/abs/2507.13357v2)** | 2025-08-25 | <details><summary>Publi...</summary><p>Published at ACL 2025 SRW, 9 pages, 3 figures</p></details> |
| **[Unified attacks to large language model watermarks: spoofing and scrubbing in unauthorized knowledge distillation](http://arxiv.org/abs/2504.17480v4)** | 2025-08-25 |  |
| **[Defending against Jailbreak through Early Exit Generation of Large Language Models](http://arxiv.org/abs/2408.11308v2)** | 2025-08-25 | ICONIP 2025 |
| **[Exploring the Vulnerability of the Content Moderation Guardrail in Large Language Models via Intent Manipulation](http://arxiv.org/abs/2505.18556v2)** | 2025-08-25 | <details><summary>Accep...</summary><p>Accepted for EMNLP'25 Findings. TL;DR: We propose a new two-stage intent-based prompt-refinement framework, IntentPrompt, that aims to explore the vulnerability of LLMs' content moderation guardrails by refining prompts into benign-looking declarative forms via intent manipulation for red-teaming purposes</p></details> |
| **[sudoLLM: On Multi-role Alignment of Language Models](http://arxiv.org/abs/2505.14607v2)** | 2025-08-24 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 (findings)</p></details> |
| **[Bridging Models to Defend: A Population-Based Strategy for Robust Adversarial Defense](http://arxiv.org/abs/2303.10225v2)** | 2025-08-24 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning](http://arxiv.org/abs/2501.03119v3)** | 2025-08-25 |  |
| **[Fingerprint Vector: Enabling Scalable and Efficient Model Fingerprint Transfer via Vector Addition](http://arxiv.org/abs/2409.08846v2)** | 2025-08-25 |  |
| **[Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](http://arxiv.org/abs/2502.05945v3)** | 2025-08-25 | <details><summary>Publi...</summary><p>Published at Transaction of Machine Learning Research 08/2025, Large Language Models (LLMs), Interference-time activation shifting, Steerability, Explainability, AI alignment, Interpretability</p></details> |
| **[Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models](http://arxiv.org/abs/2508.17674v1)** | 2025-08-25 | 7 pages, 2 figures |
| **[TombRaider: Entering the Vault of History to Jailbreak Large Language Models](http://arxiv.org/abs/2501.18628v2)** | 2025-08-25 | <details><summary>Main ...</summary><p>Main Conference of EMNLP</p></details> |
| **[Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](http://arxiv.org/abs/2507.13357v2)** | 2025-08-25 | <details><summary>Publi...</summary><p>Published at ACL 2025 SRW, 9 pages, 3 figures</p></details> |
| **[Unified attacks to large language model watermarks: spoofing and scrubbing in unauthorized knowledge distillation](http://arxiv.org/abs/2504.17480v4)** | 2025-08-25 |  |
| **[Defending against Jailbreak through Early Exit Generation of Large Language Models](http://arxiv.org/abs/2408.11308v2)** | 2025-08-25 | ICONIP 2025 |
| **[Exploring the Vulnerability of the Content Moderation Guardrail in Large Language Models via Intent Manipulation](http://arxiv.org/abs/2505.18556v2)** | 2025-08-25 | <details><summary>Accep...</summary><p>Accepted for EMNLP'25 Findings. TL;DR: We propose a new two-stage intent-based prompt-refinement framework, IntentPrompt, that aims to explore the vulnerability of LLMs' content moderation guardrails by refining prompts into benign-looking declarative forms via intent manipulation for red-teaming purposes</p></details> |
| **[sudoLLM: On Multi-role Alignment of Language Models](http://arxiv.org/abs/2505.14607v2)** | 2025-08-24 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 (findings)</p></details> |

