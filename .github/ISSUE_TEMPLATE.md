---
title: Latest 15 Papers - February 13, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](http://arxiv.org/abs/2502.06348v2)** | 2025-02-11 |  |
| **[LUNAR: LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v1)** | 2025-02-11 |  |
| **[LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild](http://arxiv.org/abs/2410.13919v2)** | 2025-02-10 |  |
| **[Tamper-Resistant Safeguards for Open-Weight LLMs](http://arxiv.org/abs/2408.00761v4)** | 2025-02-10 | <details><summary>Websi...</summary><p>Website: https://www.tamper-resistant-safeguards.com</p></details> |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |
| **[LIAR: Leveraging Inference Time Alignment (Best-of-N) to Jailbreak LLMs in Seconds](http://arxiv.org/abs/2412.05232v2)** | 2025-02-10 |  |
| **[Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models](http://arxiv.org/abs/2501.18280v2)** | 2025-02-10 |  |
| **[Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs](http://arxiv.org/abs/2403.04801v3)** | 2025-02-09 |  |
| **[Arabic Dataset for LLM Safeguard Evaluation](http://arxiv.org/abs/2410.17040v2)** | 2025-02-09 | <details><summary>Accep...</summary><p>Accepted at NAACL 2025 Main Conference</p></details> |
| **[Obfuscated Activations Bypass LLM Latent-Space Defenses](http://arxiv.org/abs/2412.09565v2)** | 2025-02-08 | <details><summary>Proje...</summary><p>Project page: https://obfuscated-activations.github.io/ Code: https://github.com/LukeBailey181/obfuscated-activations</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation](http://arxiv.org/abs/2502.06348v2)** | 2025-02-11 |  |
| **[LUNAR: LLM Unlearning via Neural Activation Redirection](http://arxiv.org/abs/2502.07218v1)** | 2025-02-11 |  |
| **[LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild](http://arxiv.org/abs/2410.13919v2)** | 2025-02-10 |  |
| **[Tamper-Resistant Safeguards for Open-Weight LLMs](http://arxiv.org/abs/2408.00761v4)** | 2025-02-10 | <details><summary>Websi...</summary><p>Website: https://www.tamper-resistant-safeguards.com</p></details> |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |
| **[LIAR: Leveraging Inference Time Alignment (Best-of-N) to Jailbreak LLMs in Seconds](http://arxiv.org/abs/2412.05232v2)** | 2025-02-10 |  |
| **[Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models](http://arxiv.org/abs/2501.18280v2)** | 2025-02-10 |  |
| **[Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs](http://arxiv.org/abs/2403.04801v3)** | 2025-02-09 |  |
| **[Arabic Dataset for LLM Safeguard Evaluation](http://arxiv.org/abs/2410.17040v2)** | 2025-02-09 | <details><summary>Accep...</summary><p>Accepted at NAACL 2025 Main Conference</p></details> |
| **[Obfuscated Activations Bypass LLM Latent-Space Defenses](http://arxiv.org/abs/2412.09565v2)** | 2025-02-08 | <details><summary>Proje...</summary><p>Project page: https://obfuscated-activations.github.io/ Code: https://github.com/LukeBailey181/obfuscated-activations</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Auditing Prompt Caching in Language Model APIs](http://arxiv.org/abs/2502.07776v1)** | 2025-02-11 | 20 pages, 7 figures |
| **[SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models](http://arxiv.org/abs/2502.07644v1)** | 2025-02-11 | <details><summary>16 pa...</summary><p>16 pages. arXiv admin note: text overlap with arXiv:2404.04306</p></details> |
| **[JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation](http://arxiv.org/abs/2502.07557v1)** | 2025-02-11 | <details><summary>To Ap...</summary><p>To Appear in the 34rd USENIX Security Symposium, August 13-15, 2025</p></details> |
| **[CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models](http://arxiv.org/abs/2502.07225v1)** | 2025-02-11 |  |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |
| **[Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions](http://arxiv.org/abs/2408.05212v2)** | 2025-02-10 | <details><summary>Publi...</summary><p>Published in Transactions on Machine Learning Research (TMLR) https://openreview.net/forum?id=Ss9MTTN7OL</p></details> |
| **[Membership Inference Risks in Quantized Models: A Theoretical and Empirical Study](http://arxiv.org/abs/2502.06567v1)** | 2025-02-10 |  |
| **[Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models](http://arxiv.org/abs/2501.18280v2)** | 2025-02-10 |  |
| **[An Efficient Security Model for Industrial Internet of Things (IIoT) System Based on Machine Learning Principles](http://arxiv.org/abs/2502.06502v1)** | 2025-02-10 |  |
| **[Detecting Backdoor Samples in Contrastive Language Image Pretraining](http://arxiv.org/abs/2502.01385v2)** | 2025-02-10 | ICLR2025 |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Auditing Prompt Caching in Language Model APIs](http://arxiv.org/abs/2502.07776v1)** | 2025-02-11 | 20 pages, 7 figures |
| **[Causal Additive Models with Unobserved Causal Paths and Backdoor Paths](http://arxiv.org/abs/2502.07646v1)** | 2025-02-11 | 14 pages |
| **[SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models](http://arxiv.org/abs/2502.07644v1)** | 2025-02-11 | <details><summary>16 pa...</summary><p>16 pages. arXiv admin note: text overlap with arXiv:2404.04306</p></details> |
| **[JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation](http://arxiv.org/abs/2502.07557v1)** | 2025-02-11 | <details><summary>To Ap...</summary><p>To Appear in the 34rd USENIX Security Symposium, August 13-15, 2025</p></details> |
| **[CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models](http://arxiv.org/abs/2502.07225v1)** | 2025-02-11 |  |
| **[Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks](http://arxiv.org/abs/2501.18727v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop on Privacy-Preserving Artificial Intelligence</p></details> |
| **[Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions](http://arxiv.org/abs/2408.05212v2)** | 2025-02-10 | <details><summary>Publi...</summary><p>Published in Transactions on Machine Learning Research (TMLR) https://openreview.net/forum?id=Ss9MTTN7OL</p></details> |
| **[Membership Inference Risks in Quantized Models: A Theoretical and Empirical Study](http://arxiv.org/abs/2502.06567v1)** | 2025-02-10 |  |
| **[Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models](http://arxiv.org/abs/2501.18280v2)** | 2025-02-10 |  |
| **[An Efficient Security Model for Industrial Internet of Things (IIoT) System Based on Machine Learning Principles](http://arxiv.org/abs/2502.06502v1)** | 2025-02-10 |  |

