---
title: Latest 15 Papers - April 08, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Les Dissonances: Cross-Tool Harvesting and Polluting in Multi-Tool Empowered LLM Agents](http://arxiv.org/abs/2504.03111v1)** | 2025-04-04 |  |
| **[PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs](http://arxiv.org/abs/2409.14729v2)** | 2025-04-03 |  |
| **[Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation](http://arxiv.org/abs/2504.02458v1)** | 2025-04-03 |  |
| **[Learning to Lie: Reinforcement Learning Attacks Damage Human-AI Teams and Teams of LLMs](http://arxiv.org/abs/2503.21983v2)** | 2025-04-02 | <details><summary>17 pa...</summary><p>17 pages, 9 figures, accepted to ICLR 2025 Workshop on Human-AI Coevolution</p></details> |
| **[Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses](http://arxiv.org/abs/2504.02080v1)** | 2025-04-02 |  |
| **[An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer](http://arxiv.org/abs/2408.11313v2)** | 2025-04-02 | <details><summary>Be ac...</summary><p>Be accepeted as NAACL2025 Findings</p></details> |
| **[Multilingual and Multi-Accent Jailbreaking of Audio LLMs](http://arxiv.org/abs/2504.01094v1)** | 2025-04-01 | <details><summary>21 pa...</summary><p>21 pages, 6 figures, 15 tables</p></details> |
| **[Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments](http://arxiv.org/abs/2504.00341v1)** | 2025-04-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in the IEEE 2025 International Conference on Communications (ICC2025)</p></details> |
| **[$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](http://arxiv.org/abs/2504.00218v1)** | 2025-03-31 |  |
| **[Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms](http://arxiv.org/abs/2503.24191v1)** | 2025-03-31 | <details><summary>15 pa...</summary><p>15 pages, 13 figures, 4 tables Work In Progress</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Les Dissonances: Cross-Tool Harvesting and Polluting in Multi-Tool Empowered LLM Agents](http://arxiv.org/abs/2504.03111v1)** | 2025-04-04 |  |
| **[PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs](http://arxiv.org/abs/2409.14729v2)** | 2025-04-03 |  |
| **[Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation](http://arxiv.org/abs/2504.02458v1)** | 2025-04-03 |  |
| **[Learning to Lie: Reinforcement Learning Attacks Damage Human-AI Teams and Teams of LLMs](http://arxiv.org/abs/2503.21983v2)** | 2025-04-02 | <details><summary>17 pa...</summary><p>17 pages, 9 figures, accepted to ICLR 2025 Workshop on Human-AI Coevolution</p></details> |
| **[Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses](http://arxiv.org/abs/2504.02080v1)** | 2025-04-02 |  |
| **[An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer](http://arxiv.org/abs/2408.11313v2)** | 2025-04-02 | <details><summary>Be ac...</summary><p>Be accepeted as NAACL2025 Findings</p></details> |
| **[Multilingual and Multi-Accent Jailbreaking of Audio LLMs](http://arxiv.org/abs/2504.01094v1)** | 2025-04-01 | <details><summary>21 pa...</summary><p>21 pages, 6 figures, 15 tables</p></details> |
| **[Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments](http://arxiv.org/abs/2504.00341v1)** | 2025-04-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in the IEEE 2025 International Conference on Communications (ICC2025)</p></details> |
| **[$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](http://arxiv.org/abs/2504.00218v1)** | 2025-03-31 |  |
| **[Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms](http://arxiv.org/abs/2503.24191v1)** | 2025-03-31 | <details><summary>15 pa...</summary><p>15 pages, 13 figures, 4 tables Work In Progress</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ToxicSQL: Migrating SQL Injection Threats into Text-to-SQL Models via Backdoor Attack](http://arxiv.org/abs/2503.05445v2)** | 2025-04-03 |  |
| **[Theoretical Insights in Model Inversion Robustness and Conditional Entropy Maximization for Collaborative Inference Systems](http://arxiv.org/abs/2503.00383v2)** | 2025-04-03 | accepted by CVPR2025 |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v1)** | 2025-04-03 |  |
| **[Defending Large Language Models Against Attacks With Residual Stream Activation Analysis](http://arxiv.org/abs/2406.03230v5)** | 2025-04-02 | <details><summary>Inclu...</summary><p>Included in Proceedings of the Conference on Applied Machine Learning in Information Security (CAMLIS 2024), Arlington, Virginia, USA, October 24-25, 2024</p></details> |
| **[On Model Protection in Federated Learning against Eavesdropping Attacks](http://arxiv.org/abs/2504.02114v1)** | 2025-04-02 |  |
| **[Implicit Bias Injection Attacks against Text-to-Image Diffusion Models](http://arxiv.org/abs/2504.01819v1)** | 2025-04-02 | Accept to CVPR 2025 |
| **[AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization](http://arxiv.org/abs/2504.01735v1)** | 2025-04-02 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v1)** | 2025-04-02 |  |
| **[PiCo: Jailbreaking Multimodal Large Language Models via $\textbf{Pi}$ctorial $\textbf{Co}$de Contextualization](http://arxiv.org/abs/2504.01444v1)** | 2025-04-02 |  |
| **[STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models](http://arxiv.org/abs/2408.16807v2)** | 2025-04-02 | <details><summary>Accep...</summary><p>Accepted to CVPR-2025. Code: https://github.com/koushiksrivats/robust-concept-erasing</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ToxicSQL: Migrating SQL Injection Threats into Text-to-SQL Models via Backdoor Attack](http://arxiv.org/abs/2503.05445v2)** | 2025-04-03 |  |
| **[Theoretical Insights in Model Inversion Robustness and Conditional Entropy Maximization for Collaborative Inference Systems](http://arxiv.org/abs/2503.00383v2)** | 2025-04-03 | accepted by CVPR2025 |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v1)** | 2025-04-03 |  |
| **[Defending Large Language Models Against Attacks With Residual Stream Activation Analysis](http://arxiv.org/abs/2406.03230v5)** | 2025-04-02 | <details><summary>Inclu...</summary><p>Included in Proceedings of the Conference on Applied Machine Learning in Information Security (CAMLIS 2024), Arlington, Virginia, USA, October 24-25, 2024</p></details> |
| **[On Model Protection in Federated Learning against Eavesdropping Attacks](http://arxiv.org/abs/2504.02114v1)** | 2025-04-02 |  |
| **[Implicit Bias Injection Attacks against Text-to-Image Diffusion Models](http://arxiv.org/abs/2504.01819v1)** | 2025-04-02 | Accept to CVPR 2025 |
| **[AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization](http://arxiv.org/abs/2504.01735v1)** | 2025-04-02 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v1)** | 2025-04-02 |  |
| **[PiCo: Jailbreaking Multimodal Large Language Models via $\textbf{Pi}$ctorial $\textbf{Co}$de Contextualization](http://arxiv.org/abs/2504.01444v1)** | 2025-04-02 |  |
| **[STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models](http://arxiv.org/abs/2408.16807v2)** | 2025-04-02 | <details><summary>Accep...</summary><p>Accepted to CVPR-2025. Code: https://github.com/koushiksrivats/robust-concept-erasing</p></details> |

