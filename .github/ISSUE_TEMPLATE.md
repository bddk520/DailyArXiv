---
title: Latest 15 Papers - August 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |
| **[AttnTrace: Attention-based Context Traceback for Long-Context LLMs](http://arxiv.org/abs/2508.03793v1)** | 2025-08-05 | <details><summary>The c...</summary><p>The code is available at https://github.com/Wang-Yanting/AttnTrace. The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace</p></details> |
| **[M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs](http://arxiv.org/abs/2503.04856v3)** | 2025-08-05 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Main Track). Camera-ready version</p></details> |
| **[Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](http://arxiv.org/abs/2508.03125v1)** | 2025-08-05 |  |
| **[VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](http://arxiv.org/abs/2508.03097v1)** | 2025-08-05 | <details><summary>12 pa...</summary><p>12 pages, 10 figures, published in KDD2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |
| **[AttnTrace: Attention-based Context Traceback for Long-Context LLMs](http://arxiv.org/abs/2508.03793v1)** | 2025-08-05 | <details><summary>The c...</summary><p>The code is available at https://github.com/Wang-Yanting/AttnTrace. The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace</p></details> |
| **[M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs](http://arxiv.org/abs/2503.04856v3)** | 2025-08-05 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Main Track). Camera-ready version</p></details> |
| **[Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](http://arxiv.org/abs/2508.03125v1)** | 2025-08-05 |  |
| **[VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs](http://arxiv.org/abs/2508.03097v1)** | 2025-08-05 | <details><summary>12 pa...</summary><p>12 pages, 10 figures, published in KDD2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](http://arxiv.org/abs/2508.00649v2)** | 2025-08-07 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[JULI: Jailbreak Large Language Models by Self-Introspection](http://arxiv.org/abs/2505.11790v3)** | 2025-08-07 |  |
| **[From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](http://arxiv.org/abs/2508.05409v1)** | 2025-08-07 | 19 Pages, 24 Figures |
| **[Towards Reliable Audio Deepfake Attribution and Model Recognition: A Multi-Level Autoencoder-Based Framework](http://arxiv.org/abs/2508.02521v2)** | 2025-08-07 |  |
| **[PhysPatch: A Physically Realizable and Transferable Adversarial Patch Attack for Multimodal Large Language Models-based Autonomous Driving Systems](http://arxiv.org/abs/2508.05167v1)** | 2025-08-07 |  |
| **[IRCopilot: Automated Incident Response with Large Language Models](http://arxiv.org/abs/2505.20945v2)** | 2025-08-07 |  |
| **[JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](http://arxiv.org/abs/2508.05087v1)** | 2025-08-07 | <details><summary>10 pa...</summary><p>10 pages, 3 tables, 2 figures, to appear in the Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)</p></details> |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[Prompt Obfuscation for Large Language Models](http://arxiv.org/abs/2409.11026v4)** | 2025-08-06 |  |
| **[A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models](http://arxiv.org/abs/2508.04276v1)** | 2025-08-06 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](http://arxiv.org/abs/2508.00649v2)** | 2025-08-07 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[JULI: Jailbreak Large Language Models by Self-Introspection](http://arxiv.org/abs/2505.11790v3)** | 2025-08-07 |  |
| **[From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](http://arxiv.org/abs/2508.05409v1)** | 2025-08-07 | 19 Pages, 24 Figures |
| **[Towards Reliable Audio Deepfake Attribution and Model Recognition: A Multi-Level Autoencoder-Based Framework](http://arxiv.org/abs/2508.02521v2)** | 2025-08-07 |  |
| **[PhysPatch: A Physically Realizable and Transferable Adversarial Patch Attack for Multimodal Large Language Models-based Autonomous Driving Systems](http://arxiv.org/abs/2508.05167v1)** | 2025-08-07 |  |
| **[IRCopilot: Automated Incident Response with Large Language Models](http://arxiv.org/abs/2505.20945v2)** | 2025-08-07 |  |
| **[JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](http://arxiv.org/abs/2508.05087v1)** | 2025-08-07 | <details><summary>10 pa...</summary><p>10 pages, 3 tables, 2 figures, to appear in the Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)</p></details> |
| **[Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](http://arxiv.org/abs/2508.04999v1)** | 2025-08-07 |  |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[Prompt Obfuscation for Large Language Models](http://arxiv.org/abs/2409.11026v4)** | 2025-08-06 |  |

