---
title: Latest 15 Papers - October 09, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[An Embarrassingly Simple Defense Against LLM Abliteration Attacks](http://arxiv.org/abs/2505.19056v2)** | 2025-10-07 | <details><summary>prepr...</summary><p>preprint - under review</p></details> |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[AutoPentester: An LLM Agent-based Framework for Automated Pentesting](http://arxiv.org/abs/2510.05605v1)** | 2025-10-07 | <details><summary>IEEE ...</summary><p>IEEE TrustCom 2025 10 pages</p></details> |
| **[A Middle Path for On-Premises LLM Deployment: Preserving Privacy Without Sacrificing Model Confidentiality](http://arxiv.org/abs/2410.11182v3)** | 2025-10-07 | <details><summary>8 pag...</summary><p>8 pages for main content of the paper</p></details> |
| **[(Token-Level) \textbf{InfoRMIA}: Stronger Membership Inference and Memorization Assessment for LLMs](http://arxiv.org/abs/2510.05582v1)** | 2025-10-07 |  |
| **[Proactive defense against LLM Jailbreak](http://arxiv.org/abs/2510.05052v1)** | 2025-10-06 |  |
| **[SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](http://arxiv.org/abs/2510.04891v1)** | 2025-10-06 |  |
| **[RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection](http://arxiv.org/abs/2510.04885v1)** | 2025-10-06 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v3)** | 2025-10-06 |  |
| **[P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs](http://arxiv.org/abs/2510.04503v1)** | 2025-10-06 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[An Embarrassingly Simple Defense Against LLM Abliteration Attacks](http://arxiv.org/abs/2505.19056v2)** | 2025-10-07 | <details><summary>prepr...</summary><p>preprint - under review</p></details> |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[AutoPentester: An LLM Agent-based Framework for Automated Pentesting](http://arxiv.org/abs/2510.05605v1)** | 2025-10-07 | <details><summary>IEEE ...</summary><p>IEEE TrustCom 2025 10 pages</p></details> |
| **[A Middle Path for On-Premises LLM Deployment: Preserving Privacy Without Sacrificing Model Confidentiality](http://arxiv.org/abs/2410.11182v3)** | 2025-10-07 | <details><summary>8 pag...</summary><p>8 pages for main content of the paper</p></details> |
| **[(Token-Level) \textbf{InfoRMIA}: Stronger Membership Inference and Memorization Assessment for LLMs](http://arxiv.org/abs/2510.05582v1)** | 2025-10-07 |  |
| **[Proactive defense against LLM Jailbreak](http://arxiv.org/abs/2510.05052v1)** | 2025-10-06 |  |
| **[SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](http://arxiv.org/abs/2510.04891v1)** | 2025-10-06 |  |
| **[RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection](http://arxiv.org/abs/2510.04885v1)** | 2025-10-06 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v3)** | 2025-10-06 |  |
| **[P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs](http://arxiv.org/abs/2510.04503v1)** | 2025-10-06 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Timed Obstruction Logic for Dynamic Game Models](http://arxiv.org/abs/2510.06045v1)** | 2025-10-07 |  |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v6)** | 2025-10-07 | <details><summary>Accep...</summary><p>Accepted for publication in JMLR</p></details> |
| **[DP-SNP-TIHMM: Differentially Private, Time-Inhomogeneous Hidden Markov Models for Synthesizing Genome-Wide Association Datasets](http://arxiv.org/abs/2510.05777v1)** | 2025-10-07 |  |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](http://arxiv.org/abs/2510.05699v1)** | 2025-10-07 | <details><summary>Code ...</summary><p>Code is available at: https://github.com/mengtong0110/Tokenizer-MIA</p></details> |
| **[Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions](http://arxiv.org/abs/2503.23278v3)** | 2025-10-07 |  |
| **[A Middle Path for On-Premises LLM Deployment: Preserving Privacy Without Sacrificing Model Confidentiality](http://arxiv.org/abs/2410.11182v3)** | 2025-10-07 | <details><summary>8 pag...</summary><p>8 pages for main content of the paper</p></details> |
| **[Adversarial Reinforcement Learning for Large Language Model Agent Safety](http://arxiv.org/abs/2510.05442v1)** | 2025-10-06 |  |
| **[DP-Adam-AC: Privacy-preserving Fine-Tuning of Localizable Language Models Using Adam Optimization with Adaptive Clipping](http://arxiv.org/abs/2510.05288v1)** | 2025-10-06 |  |
| **[Rethinking Exact Unlearning under Exposure: Extracting Forgotten Data under Exact Unlearning in Large Language Model](http://arxiv.org/abs/2505.24379v2)** | 2025-10-06 | <details><summary>Accep...</summary><p>Accepted by Neurips 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Timed Obstruction Logic for Dynamic Game Models](http://arxiv.org/abs/2510.06045v1)** | 2025-10-07 |  |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v6)** | 2025-10-07 | <details><summary>Accep...</summary><p>Accepted for publication in JMLR</p></details> |
| **[DP-SNP-TIHMM: Differentially Private, Time-Inhomogeneous Hidden Markov Models for Synthesizing Genome-Wide Association Datasets](http://arxiv.org/abs/2510.05777v1)** | 2025-10-07 |  |
| **[Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1)** | 2025-10-07 |  |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](http://arxiv.org/abs/2510.05699v1)** | 2025-10-07 | <details><summary>Code ...</summary><p>Code is available at: https://github.com/mengtong0110/Tokenizer-MIA</p></details> |
| **[Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions](http://arxiv.org/abs/2503.23278v3)** | 2025-10-07 |  |
| **[A Middle Path for On-Premises LLM Deployment: Preserving Privacy Without Sacrificing Model Confidentiality](http://arxiv.org/abs/2410.11182v3)** | 2025-10-07 | <details><summary>8 pag...</summary><p>8 pages for main content of the paper</p></details> |
| **[Adversarial Reinforcement Learning for Large Language Model Agent Safety](http://arxiv.org/abs/2510.05442v1)** | 2025-10-06 |  |
| **[DP-Adam-AC: Privacy-preserving Fine-Tuning of Localizable Language Models Using Adam Optimization with Adaptive Clipping](http://arxiv.org/abs/2510.05288v1)** | 2025-10-06 |  |
| **[Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning](http://arxiv.org/abs/2412.10924v6)** | 2025-10-06 |  |

