---
title: Latest 15 Papers - July 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Financial Trust and Compliance, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint](http://arxiv.org/abs/2506.12088v2)** | 2025-07-26 |  |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v3)** | 2025-07-25 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v4)** | 2025-07-24 | Accepted to TMLR |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v2)** | 2025-07-24 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Financial Trust and Compliance, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint](http://arxiv.org/abs/2506.12088v2)** | 2025-07-26 |  |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v3)** | 2025-07-25 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v4)** | 2025-07-24 | Accepted to TMLR |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v2)** | 2025-07-24 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Memorization in Fine-Tuned Large Language Models](http://arxiv.org/abs/2507.21009v1)** | 2025-07-28 |  |
| **[A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems](http://arxiv.org/abs/2506.00831v2)** | 2025-07-28 |  |
| **[Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models](http://arxiv.org/abs/2507.20704v1)** | 2025-07-28 | <details><summary>9 pag...</summary><p>9 pages, 9 figures. Jake Thomas served as Editor for this manuscript</p></details> |
| **[InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](http://arxiv.org/abs/2507.12060v2)** | 2025-07-28 | Accepted by MM'25 |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](http://arxiv.org/abs/2505.16789v2)** | 2025-07-28 |  |
| **[Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](http://arxiv.org/abs/2507.20526v1)** | 2025-07-28 |  |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v3)** | 2025-07-28 | <details><summary>This ...</summary><p>This version includes updated results and expanded discussion</p></details> |
| **[MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?](http://arxiv.org/abs/2507.19598v1)** | 2025-07-25 | <details><summary>Winne...</summary><p>Winner Defender Team at Amazon Nova AI Challenge 2025</p></details> |
| **[Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](http://arxiv.org/abs/2507.19227v1)** | 2025-07-25 |  |
| **[PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models](http://arxiv.org/abs/2507.19185v1)** | 2025-07-25 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Memorization in Fine-Tuned Large Language Models](http://arxiv.org/abs/2507.21009v1)** | 2025-07-28 |  |
| **[A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems](http://arxiv.org/abs/2506.00831v2)** | 2025-07-28 |  |
| **[Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models](http://arxiv.org/abs/2507.20704v1)** | 2025-07-28 | <details><summary>9 pag...</summary><p>9 pages, 9 figures. Jake Thomas served as Editor for this manuscript</p></details> |
| **[Hot-Swap MarkBoard: An Efficient Black-box Watermarking Approach for Large-scale Model Distribution](http://arxiv.org/abs/2507.20650v1)** | 2025-07-28 |  |
| **[InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](http://arxiv.org/abs/2507.12060v2)** | 2025-07-28 | Accepted by MM'25 |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](http://arxiv.org/abs/2505.16789v2)** | 2025-07-28 |  |
| **[Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](http://arxiv.org/abs/2507.20526v1)** | 2025-07-28 |  |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v3)** | 2025-07-28 | <details><summary>This ...</summary><p>This version includes updated results and expanded discussion</p></details> |
| **[MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?](http://arxiv.org/abs/2507.19598v1)** | 2025-07-25 | <details><summary>Winne...</summary><p>Winner Defender Team at Amazon Nova AI Challenge 2025</p></details> |
| **[Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](http://arxiv.org/abs/2507.19227v1)** | 2025-07-25 |  |

