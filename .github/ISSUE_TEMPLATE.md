---
title: Latest 15 Papers - June 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v3)** | 2025-05-30 |  |
| **[SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors](http://arxiv.org/abs/2505.24458v1)** | 2025-05-30 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v4)** | 2025-05-30 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |
| **[LLM Agents Should Employ Security Principles](http://arxiv.org/abs/2505.24019v1)** | 2025-05-29 |  |
| **[SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](http://arxiv.org/abs/2505.23559v1)** | 2025-05-29 |  |
| **[Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context](http://arxiv.org/abs/2412.16359v3)** | 2025-05-29 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.14644</p></details> |
| **[Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](http://arxiv.org/abs/2505.22943v1)** | 2025-05-28 | <details><summary>ACL 2...</summary><p>ACL 2025 Main. Code is released at https://vision.snu.ac.kr/projects/mac</p></details> |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v1)** | 2025-05-28 |  |
| **[Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](http://arxiv.org/abs/2505.22852v1)** | 2025-05-28 |  |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v2)** | 2025-05-28 | <details><summary>Follo...</summary><p>Follow-up work from arXiv:2405.01886</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v3)** | 2025-05-30 |  |
| **[SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors](http://arxiv.org/abs/2505.24458v1)** | 2025-05-30 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v4)** | 2025-05-30 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |
| **[LLM Agents Should Employ Security Principles](http://arxiv.org/abs/2505.24019v1)** | 2025-05-29 |  |
| **[SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](http://arxiv.org/abs/2505.23559v1)** | 2025-05-29 |  |
| **[Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context](http://arxiv.org/abs/2412.16359v3)** | 2025-05-29 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.14644</p></details> |
| **[Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](http://arxiv.org/abs/2505.22943v1)** | 2025-05-28 | <details><summary>ACL 2...</summary><p>ACL 2025 Main. Code is released at https://vision.snu.ac.kr/projects/mac</p></details> |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v1)** | 2025-05-28 |  |
| **[Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](http://arxiv.org/abs/2505.22852v1)** | 2025-05-28 |  |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v2)** | 2025-05-28 | <details><summary>Follo...</summary><p>Follow-up work from arXiv:2405.01886</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cascading Adversarial Bias from Injection to Distillation in Language Models](http://arxiv.org/abs/2505.24842v1)** | 2025-05-30 |  |
| **[LoBAM: LoRA-Based Backdoor Attack on Model Merging](http://arxiv.org/abs/2411.16746v4)** | 2025-05-30 |  |
| **[TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis](http://arxiv.org/abs/2505.24672v1)** | 2025-05-30 |  |
| **[Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization](http://arxiv.org/abs/2505.24621v1)** | 2025-05-30 | Preprint |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](http://arxiv.org/abs/2505.24592v1)** | 2025-05-30 |  |
| **[CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control](http://arxiv.org/abs/2505.24536v1)** | 2025-05-30 |  |
| **[Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors](http://arxiv.org/abs/2505.24523v1)** | 2025-05-30 | <details><summary>Accep...</summary><p>Accepted at Findings of ACL 2025</p></details> |
| **[An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks](http://arxiv.org/abs/2410.16222v2)** | 2025-05-30 |  |
| **[Learning Safety Constraints for Large Language Models](http://arxiv.org/abs/2505.24445v1)** | 2025-05-30 | <details><summary>ICML ...</summary><p>ICML 2025 (Spotlight)</p></details> |
| **[Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models](http://arxiv.org/abs/2505.24379v1)** | 2025-05-30 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cascading Adversarial Bias from Injection to Distillation in Language Models](http://arxiv.org/abs/2505.24842v1)** | 2025-05-30 |  |
| **[LoBAM: LoRA-Based Backdoor Attack on Model Merging](http://arxiv.org/abs/2411.16746v4)** | 2025-05-30 |  |
| **[TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis](http://arxiv.org/abs/2505.24672v1)** | 2025-05-30 |  |
| **[Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization](http://arxiv.org/abs/2505.24621v1)** | 2025-05-30 | Preprint |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](http://arxiv.org/abs/2505.24592v1)** | 2025-05-30 |  |
| **[CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control](http://arxiv.org/abs/2505.24536v1)** | 2025-05-30 |  |
| **[Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors](http://arxiv.org/abs/2505.24523v1)** | 2025-05-30 | <details><summary>Accep...</summary><p>Accepted at Findings of ACL 2025</p></details> |
| **[An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks](http://arxiv.org/abs/2410.16222v2)** | 2025-05-30 |  |
| **[Learning Safety Constraints for Large Language Models](http://arxiv.org/abs/2505.24445v1)** | 2025-05-30 | <details><summary>ICML ...</summary><p>ICML 2025 (Spotlight)</p></details> |
| **[Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models](http://arxiv.org/abs/2505.24379v1)** | 2025-05-30 |  |

