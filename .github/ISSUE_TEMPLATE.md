---
title: Latest 15 Papers - October 31, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery](http://arxiv.org/abs/2510.25472v1)** | 2025-10-29 |  |
| **[MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](http://arxiv.org/abs/2505.16947v2)** | 2025-10-28 | <details><summary>Publi...</summary><p>Published at 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</p></details> |
| **[Fast-MIA: Efficient and Scalable Membership Inference for LLMs](http://arxiv.org/abs/2510.23074v1)** | 2025-10-27 |  |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v1)** | 2025-10-27 |  |
| **[Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628v1)** | 2025-10-26 | <details><summary>11 pa...</summary><p>11 pages, 5 figures. Preprint version under review in the area of Artificial Intelligence (cs.AI)</p></details> |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](http://arxiv.org/abs/2510.22620v1)** | 2025-10-26 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](http://arxiv.org/abs/2510.19462v2)** | 2025-10-25 |  |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](http://arxiv.org/abs/2503.03704v3)** | 2025-10-24 |  |
| **[Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](http://arxiv.org/abs/2510.21983v1)** | 2025-10-24 |  |
| **[$δ$-STEAL: LLM Stealing Attack with Local Differential Privacy](http://arxiv.org/abs/2510.21946v1)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted at ACML 2025 (PMLR W&CP). Code: https://github.com/kirudang/LDP_Stealing_Attack</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[NetEcho: From Real-World Streaming Side-Channels to Full LLM Conversation Recovery](http://arxiv.org/abs/2510.25472v1)** | 2025-10-29 |  |
| **[MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](http://arxiv.org/abs/2505.16947v2)** | 2025-10-28 | <details><summary>Publi...</summary><p>Published at 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</p></details> |
| **[Fast-MIA: Efficient and Scalable Membership Inference for LLMs](http://arxiv.org/abs/2510.23074v1)** | 2025-10-27 |  |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v1)** | 2025-10-27 |  |
| **[Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628v1)** | 2025-10-26 | <details><summary>11 pa...</summary><p>11 pages, 5 figures. Preprint version under review in the area of Artificial Intelligence (cs.AI)</p></details> |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](http://arxiv.org/abs/2510.22620v1)** | 2025-10-26 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](http://arxiv.org/abs/2510.19462v2)** | 2025-10-25 |  |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](http://arxiv.org/abs/2503.03704v3)** | 2025-10-24 |  |
| **[Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](http://arxiv.org/abs/2510.21983v1)** | 2025-10-24 |  |
| **[$δ$-STEAL: LLM Stealing Attack with Local Differential Privacy](http://arxiv.org/abs/2510.21946v1)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted at ACML 2025 (PMLR W&CP). Code: https://github.com/kirudang/LDP_Stealing_Attack</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Model Inversion Attacks Meet Cryptographic Fuzzy Extractors](http://arxiv.org/abs/2510.25687v1)** | 2025-10-29 |  |
| **[When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](http://arxiv.org/abs/2510.21285v2)** | 2025-10-29 | <details><summary>First...</summary><p>First two authors contributed equally. The main text is 10 pages, with an appendix of 19 pages. The paper contains 18 figures and 16 tables</p></details> |
| **[Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](http://arxiv.org/abs/2510.25179v1)** | 2025-10-29 |  |
| **[OpenGuardrails: A Configurable, Unified, and Scalable Guardrails Platform for Large Language Models](http://arxiv.org/abs/2510.19169v2)** | 2025-10-29 |  |
| **[A Unified Bilevel Model for Adversarial Learning and A Case Study](http://arxiv.org/abs/2510.25121v1)** | 2025-10-29 |  |
| **[FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models](http://arxiv.org/abs/2510.24985v1)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted By ICCD 2025</p></details> |
| **[Modeling Object Attention in Mobile AR for Intrinsic Cognitive Security](http://arxiv.org/abs/2510.24004v1)** | 2025-10-28 | <details><summary>Confe...</summary><p>Conference Paper, 5 pages. Published at the 2025 ACM the International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc)</p></details> |
| **[Maximal Load Shedding Verification for Neural Network Models of AC Line Switching](http://arxiv.org/abs/2510.23806v1)** | 2025-10-27 |  |
| **[Attention! Your Vision Language Model Could Be Maliciously Manipulated](http://arxiv.org/abs/2505.19911v2)** | 2025-10-27 | NeurIPS 2025 |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v3)** | 2025-10-27 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Model Inversion Attacks Meet Cryptographic Fuzzy Extractors](http://arxiv.org/abs/2510.25687v1)** | 2025-10-29 |  |
| **[When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](http://arxiv.org/abs/2510.21285v2)** | 2025-10-29 | <details><summary>First...</summary><p>First two authors contributed equally. The main text is 10 pages, with an appendix of 19 pages. The paper contains 18 figures and 16 tables</p></details> |
| **[Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](http://arxiv.org/abs/2510.25179v1)** | 2025-10-29 |  |
| **[OpenGuardrails: A Configurable, Unified, and Scalable Guardrails Platform for Large Language Models](http://arxiv.org/abs/2510.19169v2)** | 2025-10-29 |  |
| **[A Unified Bilevel Model for Adversarial Learning and A Case Study](http://arxiv.org/abs/2510.25121v1)** | 2025-10-29 |  |
| **[FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models](http://arxiv.org/abs/2510.24985v1)** | 2025-10-28 | <details><summary>Accep...</summary><p>Accepted By ICCD 2025</p></details> |
| **[Modeling Object Attention in Mobile AR for Intrinsic Cognitive Security](http://arxiv.org/abs/2510.24004v1)** | 2025-10-28 | <details><summary>Confe...</summary><p>Conference Paper, 5 pages. Published at the 2025 ACM the International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc)</p></details> |
| **[Maximal Load Shedding Verification for Neural Network Models of AC Line Switching](http://arxiv.org/abs/2510.23806v1)** | 2025-10-27 |  |
| **[Attention! Your Vision Language Model Could Be Maliciously Manipulated](http://arxiv.org/abs/2505.19911v2)** | 2025-10-27 | NeurIPS 2025 |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v3)** | 2025-10-27 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |

