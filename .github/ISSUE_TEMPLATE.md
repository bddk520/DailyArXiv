---
title: Latest 15 Papers - April 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GraphAttack: Exploiting Representational Blindspots in LLM Safety Mechanisms](http://arxiv.org/abs/2504.13052v1)** | 2025-04-17 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v2)** | 2025-04-17 | <details><summary>Proje...</summary><p>Project Page: https://ai.zjuicsr.cn/firewall</p></details> |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |
| **[Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation](http://arxiv.org/abs/2504.12108v1)** | 2025-04-16 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v3)** | 2025-04-16 |  |
| **[Progent: Programmable Privilege Control for LLM Agents](http://arxiv.org/abs/2504.11703v1)** | 2025-04-16 |  |
| **[Making Acoustic Side-Channel Attacks on Noisy Keyboards Viable with LLM-Assisted Spectrograms' "Typo" Correction](http://arxiv.org/abs/2504.11622v1)** | 2025-04-15 | <details><summary>Lengt...</summary><p>Length: 13 pages Figures: 5 figures Tables: 7 tables Keywords: Acoustic side-channel attacks, machine learning, Visual Transformers, Large Language Models (LLMs), security Conference: Accepted at the 19th USENIX WOOT Conference on Offensive Technologies (WOOT '25). Licensing: This paper is submitted under the CC BY Creative Commons Attribution license. arXiv admin note: text overlap with arXiv:2502.09782</p></details> |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GraphAttack: Exploiting Representational Blindspots in LLM Safety Mechanisms](http://arxiv.org/abs/2504.13052v1)** | 2025-04-17 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v2)** | 2025-04-17 | <details><summary>Proje...</summary><p>Project Page: https://ai.zjuicsr.cn/firewall</p></details> |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |
| **[Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation](http://arxiv.org/abs/2504.12108v1)** | 2025-04-16 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v3)** | 2025-04-16 |  |
| **[Progent: Programmable Privilege Control for LLM Agents](http://arxiv.org/abs/2504.11703v1)** | 2025-04-16 |  |
| **[Making Acoustic Side-Channel Attacks on Noisy Keyboards Viable with LLM-Assisted Spectrograms' "Typo" Correction](http://arxiv.org/abs/2504.11622v1)** | 2025-04-15 | <details><summary>Lengt...</summary><p>Length: 13 pages Figures: 5 figures Tables: 7 tables Keywords: Acoustic side-channel attacks, machine learning, Visual Transformers, Large Language Models (LLMs), security Conference: Accepted at the 19th USENIX WOOT Conference on Offensive Technologies (WOOT '25). Licensing: This paper is submitted under the CC BY Creative Commons Attribution license. arXiv admin note: text overlap with arXiv:2502.09782</p></details> |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v2)** | 2025-04-17 |  |
| **[From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models](http://arxiv.org/abs/2407.16928v3)** | 2025-04-17 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v2)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[Human Aligned Compression for Robust Models](http://arxiv.org/abs/2504.12255v1)** | 2025-04-16 | <details><summary>Prese...</summary><p>Presented at the Workshop AdvML at CVPR 2025</p></details> |
| **[RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning](http://arxiv.org/abs/2502.08989v2)** | 2025-04-16 | 16 pages, 10 Figures |
| **[Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets](http://arxiv.org/abs/2504.11990v1)** | 2025-04-16 | <details><summary>To ap...</summary><p>To appear at IEEE Symposium on Security and Privacy 2025, 20 pages</p></details> |
| **[SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models](http://arxiv.org/abs/2504.11923v1)** | 2025-04-16 |  |
| **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility](http://arxiv.org/abs/2504.11774v1)** | 2025-04-16 |  |
| **[Propaganda via AI? A Study on Semantic Backdoors in Large Language Models](http://arxiv.org/abs/2504.12344v1)** | 2025-04-15 | 18 pages, 1 figure |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v2)** | 2025-04-17 |  |
| **[From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models](http://arxiv.org/abs/2407.16928v3)** | 2025-04-17 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v2)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[Human Aligned Compression for Robust Models](http://arxiv.org/abs/2504.12255v1)** | 2025-04-16 | <details><summary>Prese...</summary><p>Presented at the Workshop AdvML at CVPR 2025</p></details> |
| **[RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning](http://arxiv.org/abs/2502.08989v2)** | 2025-04-16 | 16 pages, 10 Figures |
| **[Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets](http://arxiv.org/abs/2504.11990v1)** | 2025-04-16 | <details><summary>To ap...</summary><p>To appear at IEEE Symposium on Security and Privacy 2025, 20 pages</p></details> |
| **[SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models](http://arxiv.org/abs/2504.11923v1)** | 2025-04-16 |  |
| **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility](http://arxiv.org/abs/2504.11774v1)** | 2025-04-16 |  |
| **[Propaganda via AI? A Study on Semantic Backdoors in Large Language Models](http://arxiv.org/abs/2504.12344v1)** | 2025-04-15 | 18 pages, 1 figure |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |

