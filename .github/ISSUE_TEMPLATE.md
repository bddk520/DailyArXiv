---
title: Latest 15 Papers - September 09, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](http://arxiv.org/abs/2509.04615v1)** | 2025-09-04 |  |
| **[KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](http://arxiv.org/abs/2509.04191v1)** | 2025-09-04 |  |
| **[Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](http://arxiv.org/abs/2508.20038v3)** | 2025-09-04 | EMNLP 2025 findings |
| **[PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity](http://arxiv.org/abs/2509.03117v1)** | 2025-09-03 |  |
| **[Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](http://arxiv.org/abs/2509.02163v1)** | 2025-09-02 |  |
| **[ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation](http://arxiv.org/abs/2507.14201v2)** | 2025-09-01 | Add code link |
| **[Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](http://arxiv.org/abs/2509.01631v1)** | 2025-09-01 | 10 pages, 6 figures |
| **[Strata-Sword: A Hierarchical Safety Evaluation towards LLMs based on Reasoning Complexity of Jailbreak Instructions](http://arxiv.org/abs/2509.01444v1)** | 2025-09-01 |  |
| **[Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](http://arxiv.org/abs/2509.01211v1)** | 2025-09-01 |  |
| **[Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation](http://arxiv.org/abs/2509.00973v1)** | 2025-08-31 | <details><summary>8 pag...</summary><p>8 pages. Accepted for publication in the proceedings of 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2025)</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](http://arxiv.org/abs/2509.04615v1)** | 2025-09-04 |  |
| **[KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](http://arxiv.org/abs/2509.04191v1)** | 2025-09-04 |  |
| **[Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](http://arxiv.org/abs/2508.20038v3)** | 2025-09-04 | EMNLP 2025 findings |
| **[PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity](http://arxiv.org/abs/2509.03117v1)** | 2025-09-03 |  |
| **[Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](http://arxiv.org/abs/2509.02163v1)** | 2025-09-02 |  |
| **[ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation](http://arxiv.org/abs/2507.14201v2)** | 2025-09-01 | Add code link |
| **[Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](http://arxiv.org/abs/2509.01631v1)** | 2025-09-01 | 10 pages, 6 figures |
| **[Strata-Sword: A Hierarchical Safety Evaluation towards LLMs based on Reasoning Complexity of Jailbreak Instructions](http://arxiv.org/abs/2509.01444v1)** | 2025-09-01 |  |
| **[Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](http://arxiv.org/abs/2509.01211v1)** | 2025-09-01 |  |
| **[Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation](http://arxiv.org/abs/2509.00973v1)** | 2025-08-31 | <details><summary>8 pag...</summary><p>8 pages. Accepted for publication in the proceedings of 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2025)</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Training a Perceptual Model for Evaluating Auditory Similarity in Music Adversarial Attack](http://arxiv.org/abs/2509.04985v1)** | 2025-09-05 |  |
| **[RINSER: Accurate API Prediction Using Masked Language Models](http://arxiv.org/abs/2509.04887v1)** | 2025-09-05 | 16 pages, 8 figures |
| **[Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning](http://arxiv.org/abs/2408.09600v3)** | 2025-09-05 | <details><summary>Rejec...</summary><p>Rejected by AAAI25-AIA. Accepted by ICML25. Authors are thankful to the anonymous reviewers from both AAAI25-AIA and ICML25</p></details> |
| **[Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](http://arxiv.org/abs/2509.04615v1)** | 2025-09-04 |  |
| **[Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing](http://arxiv.org/abs/2412.13341v2)** | 2025-09-04 | <details><summary>Publi...</summary><p>Published at ICLR 2025</p></details> |
| **[DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](http://arxiv.org/abs/2509.04597v1)** | 2025-09-04 |  |
| **[Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions](http://arxiv.org/abs/2509.04549v1)** | 2025-09-04 | 13 pages |
| **[Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models](http://arxiv.org/abs/2509.04245v1)** | 2025-09-04 |  |
| **[An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](http://arxiv.org/abs/2509.04214v1)** | 2025-09-04 |  |
| **[NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](http://arxiv.org/abs/2509.03985v1)** | 2025-09-04 | 12 pages, 9 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Training a Perceptual Model for Evaluating Auditory Similarity in Music Adversarial Attack](http://arxiv.org/abs/2509.04985v1)** | 2025-09-05 |  |
| **[RINSER: Accurate API Prediction Using Masked Language Models](http://arxiv.org/abs/2509.04887v1)** | 2025-09-05 | 16 pages, 8 figures |
| **[Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning](http://arxiv.org/abs/2408.09600v3)** | 2025-09-05 | <details><summary>Rejec...</summary><p>Rejected by AAAI25-AIA. Accepted by ICML25. Authors are thankful to the anonymous reviewers from both AAAI25-AIA and ICML25</p></details> |
| **[Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](http://arxiv.org/abs/2509.04615v1)** | 2025-09-04 |  |
| **[Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing](http://arxiv.org/abs/2412.13341v2)** | 2025-09-04 | <details><summary>Publi...</summary><p>Published at ICLR 2025</p></details> |
| **[DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](http://arxiv.org/abs/2509.04597v1)** | 2025-09-04 |  |
| **[Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions](http://arxiv.org/abs/2509.04549v1)** | 2025-09-04 | 13 pages |
| **[Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models](http://arxiv.org/abs/2509.04245v1)** | 2025-09-04 |  |
| **[An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](http://arxiv.org/abs/2509.04214v1)** | 2025-09-04 |  |
| **[NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](http://arxiv.org/abs/2509.03985v1)** | 2025-09-04 | 12 pages, 9 figures |

