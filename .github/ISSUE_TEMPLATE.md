---
title: Latest 15 Papers - December 22, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](https://arxiv.org/abs/2508.17361v2)** | 2025-12-18 |  |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489v3)** | 2025-12-18 | <details><summary>Publi...</summary><p>Published in NeurIPS 2025</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v3)** | 2025-12-17 | <details><summary>Updat...</summary><p>Updated with new baselines and experimental results</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v4)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[Quantifying Return on Security Controls in LLM Systems](https://arxiv.org/abs/2512.15081v1)** | 2025-12-17 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, 3 tables</p></details> |
| **[MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846v1)** | 2025-12-16 |  |
| **[Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space](https://arxiv.org/abs/2512.14448v1)** | 2025-12-16 |  |
| **[PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design](https://arxiv.org/abs/2512.14233v1)** | 2025-12-16 | 13 pages, 6 figures |
| **[ExpShield: Safeguarding Web Text from Unauthorized Crawling and LLM Exploitation](https://arxiv.org/abs/2412.21123v3)** | 2025-12-16 | 18 pages |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](https://arxiv.org/abs/2510.14522v3)** | 2025-12-16 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](https://arxiv.org/abs/2508.17361v2)** | 2025-12-18 |  |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489v3)** | 2025-12-18 | <details><summary>Publi...</summary><p>Published in NeurIPS 2025</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v3)** | 2025-12-17 | <details><summary>Updat...</summary><p>Updated with new baselines and experimental results</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v4)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[Quantifying Return on Security Controls in LLM Systems](https://arxiv.org/abs/2512.15081v1)** | 2025-12-17 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, 3 tables</p></details> |
| **[MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846v1)** | 2025-12-16 |  |
| **[Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space](https://arxiv.org/abs/2512.14448v1)** | 2025-12-16 |  |
| **[PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design](https://arxiv.org/abs/2512.14233v1)** | 2025-12-16 | 13 pages, 6 figures |
| **[ExpShield: Safeguarding Web Text from Unauthorized Crawling and LLM Exploitation](https://arxiv.org/abs/2412.21123v3)** | 2025-12-16 | 18 pages |
| **[Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](https://arxiv.org/abs/2510.14522v3)** | 2025-12-16 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v3)** | 2025-12-18 |  |
| **[MoAPT: Mixture of Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2505.17509v2)** | 2025-12-18 |  |
| **[In-Context Probing for Membership Inference in Fine-Tuned Language Models](https://arxiv.org/abs/2512.16292v1)** | 2025-12-18 |  |
| **[DualGuard: Dual-stream Large Language Model Watermarking Defense against Paraphrase and Spoofing Attack](https://arxiv.org/abs/2512.16182v1)** | 2025-12-18 |  |
| **[Time will Tell: Large-scale De-anonymization of Hidden I2P Services via Live Behavior Alignment (Extended Version)](https://arxiv.org/abs/2512.15510v1)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted to appear at the Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Unveiling the Attribute Misbinding Threat in Identity-Preserving Models](https://arxiv.org/abs/2512.15818v1)** | 2025-12-17 |  |
| **[MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163v1)** | 2025-12-17 | <details><summary>Our b...</summary><p>Our benchmark is available at https://github.com/xjzzzzzzzz/MCPSafety</p></details> |
| **[Benchmarking Gaslighting Negation Attacks Against Reasoning Models](https://arxiv.org/abs/2506.09677v2)** | 2025-12-16 |  |
| **[Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks](https://arxiv.org/abs/2512.14860v1)** | 2025-12-16 |  |
| **[PerProb: Indirectly Evaluating Memorization in Large Language Models](https://arxiv.org/abs/2512.14600v1)** | 2025-12-16 | <details><summary>Accep...</summary><p>Accepted at APSEC 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v3)** | 2025-12-18 |  |
| **[MoAPT: Mixture of Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2505.17509v2)** | 2025-12-18 |  |
| **[In-Context Probing for Membership Inference in Fine-Tuned Language Models](https://arxiv.org/abs/2512.16292v1)** | 2025-12-18 |  |
| **[DualGuard: Dual-stream Large Language Model Watermarking Defense against Paraphrase and Spoofing Attack](https://arxiv.org/abs/2512.16182v1)** | 2025-12-18 |  |
| **[Time will Tell: Large-scale De-anonymization of Hidden I2P Services via Live Behavior Alignment (Extended Version)](https://arxiv.org/abs/2512.15510v1)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted to appear at the Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Unveiling the Attribute Misbinding Threat in Identity-Preserving Models](https://arxiv.org/abs/2512.15818v1)** | 2025-12-17 |  |
| **[MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163v1)** | 2025-12-17 | <details><summary>Our b...</summary><p>Our benchmark is available at https://github.com/xjzzzzzzzz/MCPSafety</p></details> |
| **[Benchmarking Gaslighting Negation Attacks Against Reasoning Models](https://arxiv.org/abs/2506.09677v2)** | 2025-12-16 |  |
| **[Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks](https://arxiv.org/abs/2512.14860v1)** | 2025-12-16 |  |
| **[PerProb: Indirectly Evaluating Memorization in Large Language Models](https://arxiv.org/abs/2512.14600v1)** | 2025-12-16 | <details><summary>Accep...</summary><p>Accepted at APSEC 2025</p></details> |

