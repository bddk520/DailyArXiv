---
title: Latest 15 Papers - February 02, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682v1)** | 2026-01-29 | 20 Pages |
| **[ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533v1)** | 2026-01-29 | 58 pages |
| **[LLM Watermark Evasion via Bias Inversion](https://arxiv.org/abs/2509.23019v4)** | 2026-01-29 |  |
| **[RerouteGuard: Understanding and Mitigating Adversarial Risks for LLM Routing](https://arxiv.org/abs/2601.21380v1)** | 2026-01-29 | 15 pages, 13 figures |
| **[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065v2)** | 2026-01-29 |  |
| **[DUET: Distilled LLM Unlearning from an Efficiently Contextualized Teacher](https://arxiv.org/abs/2601.21283v1)** | 2026-01-29 |  |
| **[Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs](https://arxiv.org/abs/2601.21233v1)** | 2026-01-29 | <details><summary>24 pa...</summary><p>24 pages, 6 figures, 17 tables</p></details> |
| **[When Ads Become Profiles: Uncovering the Invisible Risk of Web Advertising at Scale with LLMs](https://arxiv.org/abs/2509.18874v3)** | 2026-01-29 | <details><summary>The A...</summary><p>The ACM Web Conference 2026</p></details> |
| **[Adaptive and Robust Cost-Aware Proof of Quality for Decentralized LLM Inference Networks](https://arxiv.org/abs/2601.21189v1)** | 2026-01-29 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](https://arxiv.org/abs/2504.06160v4)** | 2026-01-29 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682v1)** | 2026-01-29 | 20 Pages |
| **[ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533v1)** | 2026-01-29 | 58 pages |
| **[LLM Watermark Evasion via Bias Inversion](https://arxiv.org/abs/2509.23019v4)** | 2026-01-29 |  |
| **[RerouteGuard: Understanding and Mitigating Adversarial Risks for LLM Routing](https://arxiv.org/abs/2601.21380v1)** | 2026-01-29 | 15 pages, 13 figures |
| **[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065v2)** | 2026-01-29 |  |
| **[DUET: Distilled LLM Unlearning from an Efficiently Contextualized Teacher](https://arxiv.org/abs/2601.21283v1)** | 2026-01-29 |  |
| **[Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs](https://arxiv.org/abs/2601.21233v1)** | 2026-01-29 | <details><summary>24 pa...</summary><p>24 pages, 6 figures, 17 tables</p></details> |
| **[When Ads Become Profiles: Uncovering the Invisible Risk of Web Advertising at Scale with LLMs](https://arxiv.org/abs/2509.18874v3)** | 2026-01-29 | <details><summary>The A...</summary><p>The ACM Web Conference 2026</p></details> |
| **[Adaptive and Robust Cost-Aware Proof of Quality for Decentralized LLM Inference Networks](https://arxiv.org/abs/2601.21189v1)** | 2026-01-29 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](https://arxiv.org/abs/2504.06160v4)** | 2026-01-29 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Beyond the Finite Variant Property: Extending Symbolic Diffie-Hellman Group Models (Extended Version)](https://arxiv.org/abs/2601.21910v1)** | 2026-01-29 | <details><summary>Exten...</summary><p>Extended version of conference paper</p></details> |
| **[WADBERT: Dual-channel Web Attack Detection Based on BERT Models](https://arxiv.org/abs/2601.21893v1)** | 2026-01-29 |  |
| **[Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies](https://arxiv.org/abs/2601.21771v1)** | 2026-01-29 |  |
| **[SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546v2)** | 2026-01-29 |  |
| **[Noise as a Probe: Membership Inference Attacks on Diffusion Models Leveraging Initial Noise](https://arxiv.org/abs/2601.21628v1)** | 2026-01-29 |  |
| **[Enhancing Membership Inference Attacks on Diffusion Models from a Frequency-Domain Perspective](https://arxiv.org/abs/2505.20955v3)** | 2026-01-29 |  |
| **[On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression](https://arxiv.org/abs/2601.21531v1)** | 2026-01-29 | <details><summary>Under...</summary><p>Under Review, 20 pages</p></details> |
| **[LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220v1)** | 2026-01-29 | <details><summary>Accep...</summary><p>Accepted in main technical track AAAI 2026</p></details> |
| **[Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2510.08592v2)** | 2026-01-29 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Beyond the Finite Variant Property: Extending Symbolic Diffie-Hellman Group Models (Extended Version)](https://arxiv.org/abs/2601.21910v1)** | 2026-01-29 | <details><summary>Exten...</summary><p>Extended version of conference paper</p></details> |
| **[WADBERT: Dual-channel Web Attack Detection Based on BERT Models](https://arxiv.org/abs/2601.21893v1)** | 2026-01-29 |  |
| **[Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies](https://arxiv.org/abs/2601.21771v1)** | 2026-01-29 |  |
| **[SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546v2)** | 2026-01-29 |  |
| **[Noise as a Probe: Membership Inference Attacks on Diffusion Models Leveraging Initial Noise](https://arxiv.org/abs/2601.21628v1)** | 2026-01-29 |  |
| **[Enhancing Membership Inference Attacks on Diffusion Models from a Frequency-Domain Perspective](https://arxiv.org/abs/2505.20955v3)** | 2026-01-29 |  |
| **[On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression](https://arxiv.org/abs/2601.21531v1)** | 2026-01-29 | <details><summary>Under...</summary><p>Under Review, 20 pages</p></details> |
| **[LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220v1)** | 2026-01-29 | <details><summary>Accep...</summary><p>Accepted in main technical track AAAI 2026</p></details> |
| **[Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2510.08592v2)** | 2026-01-29 |  |

