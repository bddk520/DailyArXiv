---
title: Latest 15 Papers - February 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedEAT: A Robustness Optimization Framework for Federated LLMs](http://arxiv.org/abs/2502.11863v1)** | 2025-02-17 |  |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v1)** | 2025-02-17 |  |
| **[Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?](http://arxiv.org/abs/2502.11598v1)** | 2025-02-17 | <details><summary>22 pa...</summary><p>22 pages, 12 figures, 13 tables</p></details> |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v4)** | 2025-02-17 |  |
| **[Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy](http://arxiv.org/abs/2502.11533v1)** | 2025-02-17 |  |
| **[DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning](http://arxiv.org/abs/2502.11521v1)** | 2025-02-17 |  |
| **[Dagger Behind Smile: Fool LLMs with a Happy Ending Story](http://arxiv.org/abs/2501.13115v2)** | 2025-02-17 |  |
| **[Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System](http://arxiv.org/abs/2502.11358v1)** | 2025-02-17 | 15 pages, 11 figures |
| **[G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems](http://arxiv.org/abs/2502.11127v1)** | 2025-02-16 |  |
| **[When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations](http://arxiv.org/abs/2411.12701v3)** | 2025-02-16 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedEAT: A Robustness Optimization Framework for Federated LLMs](http://arxiv.org/abs/2502.11863v1)** | 2025-02-17 |  |
| **[BaxBench: Can LLMs Generate Correct and Secure Backends?](http://arxiv.org/abs/2502.11844v1)** | 2025-02-17 |  |
| **[Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?](http://arxiv.org/abs/2502.11598v1)** | 2025-02-17 | <details><summary>22 pa...</summary><p>22 pages, 12 figures, 13 tables</p></details> |
| **[LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models](http://arxiv.org/abs/2407.16205v4)** | 2025-02-17 |  |
| **[Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy](http://arxiv.org/abs/2502.11533v1)** | 2025-02-17 |  |
| **[DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning](http://arxiv.org/abs/2502.11521v1)** | 2025-02-17 |  |
| **[Dagger Behind Smile: Fool LLMs with a Happy Ending Story](http://arxiv.org/abs/2501.13115v2)** | 2025-02-17 |  |
| **[Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System](http://arxiv.org/abs/2502.11358v1)** | 2025-02-17 | 15 pages, 11 figures |
| **[G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems](http://arxiv.org/abs/2502.11127v1)** | 2025-02-16 |  |
| **[When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations](http://arxiv.org/abs/2411.12701v3)** | 2025-02-16 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models](http://arxiv.org/abs/2502.09782v2)** | 2025-02-17 | <details><summary>We wi...</summary><p>We will reflect comments from the reviewers and re-submit</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models](http://arxiv.org/abs/2502.09782v2)** | 2025-02-17 | <details><summary>We wi...</summary><p>We will reflect comments from the reviewers and re-submit</p></details> |
| **[Enhanced Anomaly Detection in IoMT Networks using Ensemble AI Models on the CICIoMT2024 Dataset](http://arxiv.org/abs/2502.11854v1)** | 2025-02-17 |  |
| **[StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models](http://arxiv.org/abs/2502.11853v1)** | 2025-02-17 |  |
| **[Impactful Bit-Flip Search on Full-precision Models](http://arxiv.org/abs/2411.08133v3)** | 2025-02-17 |  |
| **[BackdoorDM: A Comprehensive Benchmark for Backdoor Learning in Diffusion Model](http://arxiv.org/abs/2502.11798v1)** | 2025-02-17 |  |
| **[Adversarially Robust CLIP Models Can Induce Better (Robust) Perceptual Metrics](http://arxiv.org/abs/2502.11725v1)** | 2025-02-17 | <details><summary>This ...</summary><p>This work has been accepted for publication in the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore</p></details> |
| **[Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models](http://arxiv.org/abs/2412.11041v2)** | 2025-02-17 | <details><summary>16 pa...</summary><p>16 pages, 14 figures,</p></details> |
| **[DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](http://arxiv.org/abs/2502.11647v1)** | 2025-02-17 |  |
| **[Membership Inference Attacks for Face Images Against Fine-Tuned Latent Diffusion Models](http://arxiv.org/abs/2502.11619v1)** | 2025-02-17 | <details><summary>In Pr...</summary><p>In Proceedings of the 20th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP 2025) - Volume 2: VISAPP, pages 439-446</p></details> |
| **[A Unified Modeling Framework for Automated Penetration Testing](http://arxiv.org/abs/2502.11588v1)** | 2025-02-17 |  |

