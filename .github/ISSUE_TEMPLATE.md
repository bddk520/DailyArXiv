---
title: Latest 15 Papers - June 13, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v2)** | 2025-06-11 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v2)** | 2025-06-11 |  |
| **[LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge](http://arxiv.org/abs/2506.09443v1)** | 2025-06-11 |  |
| **[Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](http://arxiv.org/abs/2406.15481v3)** | 2025-06-11 | <details><summary>To ap...</summary><p>To appear in ACL 2025</p></details> |
| **[AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](http://arxiv.org/abs/2506.08885v2)** | 2025-06-11 |  |
| **[Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis](http://arxiv.org/abs/2506.08561v2)** | 2025-06-11 |  |
| **[On the Ethics of Using LLMs for Offensive Security](http://arxiv.org/abs/2506.08693v1)** | 2025-06-10 |  |
| **[R.R.: Unveiling LLM Training Privacy through Recollection and Ranking](http://arxiv.org/abs/2502.12658v2)** | 2025-06-09 | <details><summary>13 pa...</summary><p>13 pages, 9 figures; typos corrected</p></details> |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v4)** | 2025-06-09 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](http://arxiv.org/abs/2412.15289v4)** | 2025-06-09 | <details><summary>To ap...</summary><p>To appear at Findings of ACL 2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v2)** | 2025-06-11 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v2)** | 2025-06-11 |  |
| **[LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge](http://arxiv.org/abs/2506.09443v1)** | 2025-06-11 |  |
| **[Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](http://arxiv.org/abs/2406.15481v3)** | 2025-06-11 | <details><summary>To ap...</summary><p>To appear in ACL 2025</p></details> |
| **[AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](http://arxiv.org/abs/2506.08885v2)** | 2025-06-11 |  |
| **[Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis](http://arxiv.org/abs/2506.08561v2)** | 2025-06-11 |  |
| **[On the Ethics of Using LLMs for Offensive Security](http://arxiv.org/abs/2506.08693v1)** | 2025-06-10 |  |
| **[R.R.: Unveiling LLM Training Privacy through Recollection and Ranking](http://arxiv.org/abs/2502.12658v2)** | 2025-06-09 | <details><summary>13 pa...</summary><p>13 pages, 9 figures; typos corrected</p></details> |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v4)** | 2025-06-09 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](http://arxiv.org/abs/2412.15289v4)** | 2025-06-09 | <details><summary>To ap...</summary><p>To appear at Findings of ACL 2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v1)** | 2025-06-11 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v1)** | 2025-06-11 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model](http://arxiv.org/abs/2506.04704v2)** | 2025-06-11 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |
| **[CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization](http://arxiv.org/abs/2411.12768v2)** | 2025-06-11 | <details><summary>Accep...</summary><p>Accepted at ICML 2025, 20 pages</p></details> |
| **[Evasion Attacks Against Bayesian Predictive Models](http://arxiv.org/abs/2506.09640v1)** | 2025-06-11 | <details><summary>Accep...</summary><p>Accepted as an oral presentation at UAI'25</p></details> |
| **[Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals in Large Language Models](http://arxiv.org/abs/2409.00598v2)** | 2025-06-11 |  |
| **[FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts](http://arxiv.org/abs/2502.21059v2)** | 2025-06-10 | 13 pages, 7 figures |
| **[PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips](http://arxiv.org/abs/2412.07192v2)** | 2025-06-10 | Pre-print |
| **[ASIDE: Architectural Separation of Instructions and Data in Language Models](http://arxiv.org/abs/2503.10566v3)** | 2025-06-10 | <details><summary>Preli...</summary><p>Preliminary version accepted to ICLR 2025 Workshop on Building Trust in Language Models and Applications</p></details> |
| **[SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech Classification Models](http://arxiv.org/abs/2506.08346v1)** | 2025-06-10 | <details><summary>Accep...</summary><p>Accepted by IJCNN 2025</p></details> |
| **[A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks](http://arxiv.org/abs/2506.08227v1)** | 2025-06-09 |  |

