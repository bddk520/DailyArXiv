---
title: Latest 15 Papers - May 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |
| **[ACE: A Security Architecture for LLM-Integrated App Systems](http://arxiv.org/abs/2504.20984v2)** | 2025-05-07 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; clarify relation to indirect prompt injection attacks</p></details> |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v2)** | 2025-05-07 | <details><summary>Accep...</summary><p>Accepted by IEEE Communications Magazine</p></details> |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v1)** | 2025-05-07 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2405.01886</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |
| **[Concept-Level Explainability for Auditing & Steering LLM Responses](http://arxiv.org/abs/2505.07610v1)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, Submission to Neurips 2025</p></details> |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v6)** | 2025-05-12 | <details><summary>40 pa...</summary><p>40 pages, 38 figures An earlier revision of this paper was accepted at ICML 2025. Since then, it has been updated to include new results on training dynamics (4.7) and base models (4.8)</p></details> |
| **[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)** | 2025-05-11 | <details><summary>This ...</summary><p>This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025</p></details> |
| **[Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface](http://arxiv.org/abs/2501.09798v2)** | 2025-05-10 |  |
| **[Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions](http://arxiv.org/abs/2410.18966v3)** | 2025-05-09 | <details><summary>This ...</summary><p>This paper is accepted by NAACL 2025 findings. Link to the paper presentation: https://youtu.be/IhaxwbZOcaU</p></details> |
| **[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted for presentation at IEEE International Conference on LLM-Aided Design (ICLAD), 2025</p></details> |
| **[Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems](http://arxiv.org/abs/2505.05196v1)** | 2025-05-08 |  |
| **[ACE: A Security Architecture for LLM-Integrated App Systems](http://arxiv.org/abs/2504.20984v2)** | 2025-05-07 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; clarify relation to indirect prompt injection attacks</p></details> |
| **[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v2)** | 2025-05-07 | <details><summary>Accep...</summary><p>Accepted by IEEE Communications Magazine</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](http://arxiv.org/abs/2504.15026v2)** | 2025-05-13 | 18 pages, 8 figures |
| **[Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem](http://arxiv.org/abs/2403.03593v2)** | 2025-05-13 | 18 pages |
| **[GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models](http://arxiv.org/abs/2501.10985v2)** | 2025-05-13 |  |
| **[LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](http://arxiv.org/abs/2505.08204v1)** | 2025-05-13 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2501.02968v3)** | 2025-05-13 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](http://arxiv.org/abs/2505.08148v1)** | 2025-05-13 |  |
| **[LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](http://arxiv.org/abs/2505.05619v2)** | 2025-05-12 | <details><summary>14 pa...</summary><p>14 pages, 18 figures, and 4 tables</p></details> |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v1)** | 2025-05-12 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v3)** | 2025-05-12 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v5)** | 2025-05-12 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](http://arxiv.org/abs/2504.15026v2)** | 2025-05-13 | 18 pages, 8 figures |
| **[Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem](http://arxiv.org/abs/2403.03593v2)** | 2025-05-13 | 18 pages |
| **[GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models](http://arxiv.org/abs/2501.10985v2)** | 2025-05-13 |  |
| **[LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](http://arxiv.org/abs/2505.08204v1)** | 2025-05-13 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2501.02968v3)** | 2025-05-13 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](http://arxiv.org/abs/2505.08148v1)** | 2025-05-13 |  |
| **[LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](http://arxiv.org/abs/2505.05619v2)** | 2025-05-12 | <details><summary>14 pa...</summary><p>14 pages, 18 figures, and 4 tables</p></details> |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v1)** | 2025-05-12 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v3)** | 2025-05-12 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Fundamental Limits of Membership Inference Attacks on Machine Learning Models](http://arxiv.org/abs/2310.13786v5)** | 2025-05-12 |  |

