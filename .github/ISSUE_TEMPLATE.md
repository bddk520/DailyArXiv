---
title: Latest 15 Papers - December 29, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents](https://arxiv.org/abs/2512.21250v1)** | 2025-12-24 |  |
| **[Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking](https://arxiv.org/abs/2512.21236v1)** | 2025-12-24 | Accepted to FSE 2026 |
| **[GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs](https://arxiv.org/abs/2512.21008v1)** | 2025-12-24 | <details><summary>Accep...</summary><p>Accepted by USENIX Security'26</p></details> |
| **[AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs](https://arxiv.org/abs/2512.20986v1)** | 2025-12-24 |  |
| **[Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses](https://arxiv.org/abs/2504.02080v2)** | 2025-12-24 |  |
| **[Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography](https://arxiv.org/abs/2512.20168v1)** | 2025-12-23 | <details><summary>This ...</summary><p>This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026</p></details> |
| **[AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications](https://arxiv.org/abs/2512.20164v1)** | 2025-12-23 |  |
| **[SoK: Are Watermarks in LLMs Ready for Deployment?](https://arxiv.org/abs/2506.05594v3)** | 2025-12-23 |  |
| **[Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231v2)** | 2025-12-22 | 19 pages, 7 figures |
| **[Bleeding Pathways: Vanishing Discriminability in LLM Hidden States Fuels Jailbreak Attacks](https://arxiv.org/abs/2503.11185v2)** | 2025-12-22 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents](https://arxiv.org/abs/2512.21250v1)** | 2025-12-24 |  |
| **[Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking](https://arxiv.org/abs/2512.21236v1)** | 2025-12-24 | Accepted to FSE 2026 |
| **[GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs](https://arxiv.org/abs/2512.21008v1)** | 2025-12-24 | <details><summary>Accep...</summary><p>Accepted by USENIX Security'26</p></details> |
| **[AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs](https://arxiv.org/abs/2512.20986v1)** | 2025-12-24 |  |
| **[Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses](https://arxiv.org/abs/2504.02080v2)** | 2025-12-24 |  |
| **[Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography](https://arxiv.org/abs/2512.20168v1)** | 2025-12-23 | <details><summary>This ...</summary><p>This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026</p></details> |
| **[AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications](https://arxiv.org/abs/2512.20164v1)** | 2025-12-23 |  |
| **[SoK: Are Watermarks in LLMs Ready for Deployment?](https://arxiv.org/abs/2506.05594v3)** | 2025-12-23 |  |
| **[Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231v2)** | 2025-12-22 | 19 pages, 7 figures |
| **[Bleeding Pathways: Vanishing Discriminability in LLM Hidden States Fuels Jailbreak Attacks](https://arxiv.org/abs/2503.11185v2)** | 2025-12-22 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Steering Vision-Language Pre-trained Models for Incremental Face Presentation Attack Detection](https://arxiv.org/abs/2512.19022v2)** | 2025-12-24 |  |
| **[AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2507.01020v2)** | 2025-12-23 | <details><summary>We en...</summary><p>We encountered issues with the paper being hosted under my personal account, so we republished it under a different account associated with a university email, which makes updates and management easier. As a result, this version is a duplicate of arXiv:2511.02376</p></details> |
| **[Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2505.02824v2)** | 2025-12-23 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Information Forensics and Security</p></details> |
| **[Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms](https://arxiv.org/abs/2512.20391v1)** | 2025-12-23 |  |
| **[Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models](https://arxiv.org/abs/2508.01741v2)** | 2025-12-23 |  |
| **[AI-based Traffic Modeling for Network Security and Privacy: Challenges Ahead](https://arxiv.org/abs/2503.22161v4)** | 2025-12-23 | <details><summary>Accep...</summary><p>Accepted at the AAAI 2026 Workshop on Artificial Intelligence for Cyber Security (AICS)</p></details> |
| **[One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models](https://arxiv.org/abs/2406.05491v4)** | 2025-12-22 | <details><summary>Accep...</summary><p>Accepted by ICCV-2025</p></details> |
| **[SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.19317v1)** | 2025-12-22 |  |
| **[Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models](https://arxiv.org/abs/2512.19297v1)** | 2025-12-22 | NDSS 2026 |
| **[Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation](https://arxiv.org/abs/2512.19215v1)** | 2025-12-22 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Steering Vision-Language Pre-trained Models for Incremental Face Presentation Attack Detection](https://arxiv.org/abs/2512.19022v2)** | 2025-12-24 |  |
| **[AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2507.01020v2)** | 2025-12-23 | <details><summary>We en...</summary><p>We encountered issues with the paper being hosted under my personal account, so we republished it under a different account associated with a university email, which makes updates and management easier. As a result, this version is a duplicate of arXiv:2511.02376</p></details> |
| **[Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2505.02824v2)** | 2025-12-23 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Information Forensics and Security</p></details> |
| **[Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms](https://arxiv.org/abs/2512.20391v1)** | 2025-12-23 |  |
| **[Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models](https://arxiv.org/abs/2508.01741v2)** | 2025-12-23 |  |
| **[AI-based Traffic Modeling for Network Security and Privacy: Challenges Ahead](https://arxiv.org/abs/2503.22161v4)** | 2025-12-23 | <details><summary>Accep...</summary><p>Accepted at the AAAI 2026 Workshop on Artificial Intelligence for Cyber Security (AICS)</p></details> |
| **[One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models](https://arxiv.org/abs/2406.05491v4)** | 2025-12-22 | <details><summary>Accep...</summary><p>Accepted by ICCV-2025</p></details> |
| **[SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.19317v1)** | 2025-12-22 |  |
| **[Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models](https://arxiv.org/abs/2512.19297v1)** | 2025-12-22 | NDSS 2026 |
| **[Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation](https://arxiv.org/abs/2512.19215v1)** | 2025-12-22 |  |

