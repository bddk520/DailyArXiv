---
title: Latest 15 Papers - February 09, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions](http://arxiv.org/abs/2502.04322v1)** | 2025-02-06 |  |
| **[Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks](http://arxiv.org/abs/2502.04227v1)** | 2025-02-06 |  |
| **["Short-length" Adversarial Training Helps LLMs Defend "Long-length" Jailbreak Attacks: Theoretical and Empirical Evidence](http://arxiv.org/abs/2502.04204v1)** | 2025-02-06 |  |
| **[OverThink: Slowdown Attacks on Reasoning LLMs](http://arxiv.org/abs/2502.02542v2)** | 2025-02-05 |  |
| **[SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner](http://arxiv.org/abs/2406.05498v3)** | 2025-02-05 | <details><summary>Accep...</summary><p>Accepted by USENIX Security Symposium 2025. Please cite the conference version of this paper, i.e., "Xunguang Wang, Daoyuan Wu, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Shuai Wang, Yingjiu Li, Yang Liu, Ning Liu, and Juergen Rahmel. SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner. In Proc. USENIX Security, 2025."</p></details> |
| **[Lost in Overlap: Exploring Logit-based Watermark Collision in LLMs](http://arxiv.org/abs/2403.10020v3)** | 2025-02-05 | <details><summary>Long ...</summary><p>Long Paper, 9 pages, accepted at NAACL 2025 Findings</p></details> |
| **[Certifying LLM Safety against Adversarial Prompting](http://arxiv.org/abs/2309.02705v4)** | 2025-02-04 | <details><summary>Accep...</summary><p>Accepted at COLM 2024: https://openreview.net/forum?id=9Ik05cycLq</p></details> |
| **[The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs](http://arxiv.org/abs/2501.18626v3)** | 2025-02-04 |  |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v3)** | 2025-02-04 |  |
| **[SHIELD: APT Detection and Intelligent Explanation Using LLM](http://arxiv.org/abs/2502.02342v1)** | 2025-02-04 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions](http://arxiv.org/abs/2502.04322v1)** | 2025-02-06 |  |
| **[Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks](http://arxiv.org/abs/2502.04227v1)** | 2025-02-06 |  |
| **["Short-length" Adversarial Training Helps LLMs Defend "Long-length" Jailbreak Attacks: Theoretical and Empirical Evidence](http://arxiv.org/abs/2502.04204v1)** | 2025-02-06 |  |
| **[OverThink: Slowdown Attacks on Reasoning LLMs](http://arxiv.org/abs/2502.02542v2)** | 2025-02-05 |  |
| **[SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner](http://arxiv.org/abs/2406.05498v3)** | 2025-02-05 | <details><summary>Accep...</summary><p>Accepted by USENIX Security Symposium 2025. Please cite the conference version of this paper, i.e., "Xunguang Wang, Daoyuan Wu, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Shuai Wang, Yingjiu Li, Yang Liu, Ning Liu, and Juergen Rahmel. SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner. In Proc. USENIX Security, 2025."</p></details> |
| **[Lost in Overlap: Exploring Logit-based Watermark Collision in LLMs](http://arxiv.org/abs/2403.10020v3)** | 2025-02-05 | <details><summary>Long ...</summary><p>Long Paper, 9 pages, accepted at NAACL 2025 Findings</p></details> |
| **[Certifying LLM Safety against Adversarial Prompting](http://arxiv.org/abs/2309.02705v4)** | 2025-02-04 | <details><summary>Accep...</summary><p>Accepted at COLM 2024: https://openreview.net/forum?id=9Ik05cycLq</p></details> |
| **[The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs](http://arxiv.org/abs/2501.18626v3)** | 2025-02-04 |  |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v3)** | 2025-02-04 |  |
| **[SHIELD: APT Detection and Intelligent Explanation Using LLM](http://arxiv.org/abs/2502.02342v1)** | 2025-02-04 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v1)** | 2025-02-06 |  |
| **[DiffZOO: A Purely Query-Based Black-Box Attack for Red-teaming Text-to-Image Generative Model via Zeroth Order Optimization](http://arxiv.org/abs/2408.11071v2)** | 2025-02-06 |  |
| **[On Effects of Steering Latent Representation for Large Language Model Unlearning](http://arxiv.org/abs/2408.06223v3)** | 2025-02-06 | <details><summary>Accep...</summary><p>Accepted at AAAI-25 Main Technical Track</p></details> |
| **[DocMIA: Document-Level Membership Inference Attacks against DocVQA Models](http://arxiv.org/abs/2502.03692v1)** | 2025-02-06 | ICLR 2025 |
| **[GLOV: Guided Large Language Models as Implicit Optimizers for Vision Language Models](http://arxiv.org/abs/2410.06154v5)** | 2025-02-05 | <details><summary>Code:...</summary><p>Code: https://github.com/jmiemirza/GLOV</p></details> |
| **[ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](http://arxiv.org/abs/2403.02910v3)** | 2025-02-05 |  |
| **[Gotham Dataset 2025: A Reproducible Large-Scale IoT Network Dataset for Intrusion Detection and Security Research](http://arxiv.org/abs/2502.03134v1)** | 2025-02-05 | <details><summary>16 pa...</summary><p>16 pages, 7 figures, 4 tables. Submitted at the Data in Brief journal</p></details> |
| **[ACTISM: Threat-informed Dynamic Security Modelling for Automotive Systems](http://arxiv.org/abs/2412.00416v3)** | 2025-02-05 | <details><summary>Prepr...</summary><p>Preprint under submission</p></details> |
| **[Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing](http://arxiv.org/abs/2502.03086v1)** | 2025-02-05 | <details><summary>accap...</summary><p>accapted at IEEE International Conference on Next Generation Information System Engineering</p></details> |
| **[Watermark Smoothing Attacks against Language Models](http://arxiv.org/abs/2407.14206v2)** | 2025-02-05 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v1)** | 2025-02-06 |  |
| **[DiffZOO: A Purely Query-Based Black-Box Attack for Red-teaming Text-to-Image Generative Model via Zeroth Order Optimization](http://arxiv.org/abs/2408.11071v2)** | 2025-02-06 |  |
| **[On Effects of Steering Latent Representation for Large Language Model Unlearning](http://arxiv.org/abs/2408.06223v3)** | 2025-02-06 | <details><summary>Accep...</summary><p>Accepted at AAAI-25 Main Technical Track</p></details> |
| **[DocMIA: Document-Level Membership Inference Attacks against DocVQA Models](http://arxiv.org/abs/2502.03692v1)** | 2025-02-06 | ICLR 2025 |
| **[GLOV: Guided Large Language Models as Implicit Optimizers for Vision Language Models](http://arxiv.org/abs/2410.06154v5)** | 2025-02-05 | <details><summary>Code:...</summary><p>Code: https://github.com/jmiemirza/GLOV</p></details> |
| **[ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](http://arxiv.org/abs/2403.02910v3)** | 2025-02-05 |  |
| **[Gotham Dataset 2025: A Reproducible Large-Scale IoT Network Dataset for Intrusion Detection and Security Research](http://arxiv.org/abs/2502.03134v1)** | 2025-02-05 | <details><summary>16 pa...</summary><p>16 pages, 7 figures, 4 tables. Submitted at the Data in Brief journal</p></details> |
| **[ACTISM: Threat-informed Dynamic Security Modelling for Automotive Systems](http://arxiv.org/abs/2412.00416v3)** | 2025-02-05 | <details><summary>Prepr...</summary><p>Preprint under submission</p></details> |
| **[Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing](http://arxiv.org/abs/2502.03086v1)** | 2025-02-05 | <details><summary>accap...</summary><p>accapted at IEEE International Conference on Next Generation Information System Engineering</p></details> |
| **[Watermark Smoothing Attacks against Language Models](http://arxiv.org/abs/2407.14206v2)** | 2025-02-05 |  |

