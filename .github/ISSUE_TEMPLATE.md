---
title: Latest 15 Papers - March 06, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLM-Safety Evaluations Lack Robustness](http://arxiv.org/abs/2503.02574v1)** | 2025-03-04 |  |
| **[Adaptive Attacks Break Defenses Against Indirect Prompt Injection Attacks on LLM Agents](http://arxiv.org/abs/2503.00061v2)** | 2025-03-04 | <details><summary>17 pa...</summary><p>17 pages, 5 figures, 6 tables (NAACL 2025 Findings)</p></details> |
| **[Confidential Prompting: Protecting User Prompts from Cloud LLM Providers](http://arxiv.org/abs/2409.19134v3)** | 2025-03-04 |  |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v5)** | 2025-03-03 |  |
| **[Optimization-based Prompt Injection Attack to LLM-as-a-Judge](http://arxiv.org/abs/2403.17710v4)** | 2025-03-03 | <details><summary>To ap...</summary><p>To appear in the Proceedings of The ACM Conference on Computer and Communications Security (CCS), 2024</p></details> |
| **[We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs](http://arxiv.org/abs/2406.10279v3)** | 2025-03-02 | <details><summary>To ap...</summary><p>To appear in the 2025 USENIX Security Symposium. 22 pages, 14 figures, 8 tables. Edited from original version for submission to a different conference. No change to original results or findings</p></details> |
| **[SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters](http://arxiv.org/abs/2407.01902v2)** | 2025-03-02 | <details><summary>Accep...</summary><p>Accepted by NAACL 2025</p></details> |
| **[Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies](http://arxiv.org/abs/2503.00724v1)** | 2025-03-02 |  |
| **[BadJudge: Backdoor Vulnerabilities of LLM-as-a-Judge](http://arxiv.org/abs/2503.00596v1)** | 2025-03-01 | <details><summary>Publi...</summary><p>Published to ICLR 2025</p></details> |
| **[Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore](http://arxiv.org/abs/2405.04286v2)** | 2025-03-01 | COLING 2025 |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLM-Safety Evaluations Lack Robustness](http://arxiv.org/abs/2503.02574v1)** | 2025-03-04 |  |
| **[Adaptive Attacks Break Defenses Against Indirect Prompt Injection Attacks on LLM Agents](http://arxiv.org/abs/2503.00061v2)** | 2025-03-04 | <details><summary>17 pa...</summary><p>17 pages, 5 figures, 6 tables (NAACL 2025 Findings)</p></details> |
| **[Confidential Prompting: Protecting User Prompts from Cloud LLM Providers](http://arxiv.org/abs/2409.19134v3)** | 2025-03-04 |  |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v5)** | 2025-03-03 |  |
| **[Optimization-based Prompt Injection Attack to LLM-as-a-Judge](http://arxiv.org/abs/2403.17710v4)** | 2025-03-03 | <details><summary>To ap...</summary><p>To appear in the Proceedings of The ACM Conference on Computer and Communications Security (CCS), 2024</p></details> |
| **[We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs](http://arxiv.org/abs/2406.10279v3)** | 2025-03-02 | <details><summary>To ap...</summary><p>To appear in the 2025 USENIX Security Symposium. 22 pages, 14 figures, 8 tables. Edited from original version for submission to a different conference. No change to original results or findings</p></details> |
| **[SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters](http://arxiv.org/abs/2407.01902v2)** | 2025-03-02 | <details><summary>Accep...</summary><p>Accepted by NAACL 2025</p></details> |
| **[Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies](http://arxiv.org/abs/2503.00724v1)** | 2025-03-02 |  |
| **[BadJudge: Backdoor Vulnerabilities of LLM-as-a-Judge](http://arxiv.org/abs/2503.00596v1)** | 2025-03-01 | <details><summary>Publi...</summary><p>Published to ICLR 2025</p></details> |
| **[Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore](http://arxiv.org/abs/2405.04286v2)** | 2025-03-01 | COLING 2025 |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Safe AI Clinicians: A Comprehensive Study on Large Language Model Jailbreaking in Healthcare](http://arxiv.org/abs/2501.18632v2)** | 2025-03-04 |  |
| **[TPIA: Towards Target-specific Prompt Injection Attack against Code-oriented Large Language Models](http://arxiv.org/abs/2407.09164v5)** | 2025-03-04 |  |
| **[Continual Multi-Robot Learning from Black-Box Visual Place Recognition Models](http://arxiv.org/abs/2503.02256v1)** | 2025-03-04 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, technical report</p></details> |
| **[A Lightweight and Secure Deep Learning Model for Privacy-Preserving Federated Learning in Intelligent Enterprises](http://arxiv.org/abs/2503.02017v1)** | 2025-03-03 | <details><summary>11 pa...</summary><p>11 pages, 7 figures, IEEE Internet of Things Journal (2024)</p></details> |
| **[Jailbreaking Safeguarded Text-to-Image Models via Large Language Models](http://arxiv.org/abs/2503.01839v1)** | 2025-03-03 |  |
| **[Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models](http://arxiv.org/abs/2503.01781v1)** | 2025-03-03 |  |
| **[Zero-Trust Artificial Intelligence Model Security Based on Moving Target Defense and Content Disarm and Reconstruction](http://arxiv.org/abs/2503.01758v1)** | 2025-03-03 |  |
| **[Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models](http://arxiv.org/abs/2503.01742v1)** | 2025-03-03 |  |
| **[AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World Settings](http://arxiv.org/abs/2411.17711v2)** | 2025-03-03 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Safe AI Clinicians: A Comprehensive Study on Large Language Model Jailbreaking in Healthcare](http://arxiv.org/abs/2501.18632v2)** | 2025-03-04 |  |
| **[TPIA: Towards Target-specific Prompt Injection Attack against Code-oriented Large Language Models](http://arxiv.org/abs/2407.09164v5)** | 2025-03-04 |  |
| **[Continual Multi-Robot Learning from Black-Box Visual Place Recognition Models](http://arxiv.org/abs/2503.02256v1)** | 2025-03-04 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, technical report</p></details> |
| **[A Lightweight and Secure Deep Learning Model for Privacy-Preserving Federated Learning in Intelligent Enterprises](http://arxiv.org/abs/2503.02017v1)** | 2025-03-03 | <details><summary>11 pa...</summary><p>11 pages, 7 figures, IEEE Internet of Things Journal (2024)</p></details> |
| **[Jailbreaking Safeguarded Text-to-Image Models via Large Language Models](http://arxiv.org/abs/2503.01839v1)** | 2025-03-03 |  |
| **[Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models](http://arxiv.org/abs/2503.01781v1)** | 2025-03-03 |  |
| **[Zero-Trust Artificial Intelligence Model Security Based on Moving Target Defense and Content Disarm and Reconstruction](http://arxiv.org/abs/2503.01758v1)** | 2025-03-03 |  |
| **[Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models](http://arxiv.org/abs/2503.01742v1)** | 2025-03-03 |  |
| **[AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World Settings](http://arxiv.org/abs/2411.17711v2)** | 2025-03-03 |  |

