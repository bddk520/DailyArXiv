---
title: Latest 15 Papers - July 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems](http://arxiv.org/abs/2507.15613v1)** | 2025-07-21 | 26 pages |
| **[From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](http://arxiv.org/abs/2506.15170v2)** | 2025-07-20 |  |
| **[Byzantine-Robust Decentralized Coordination of LLM Agents](http://arxiv.org/abs/2507.14928v1)** | 2025-07-20 |  |
| **[Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree](http://arxiv.org/abs/2507.14799v1)** | 2025-07-20 | <details><summary>EMNLP...</summary><p>EMNLP 2025 System Demonstrations Submission</p></details> |
| **[Configurable multi-agent framework for scalable and realistic testing of llm-based agents](http://arxiv.org/abs/2507.14705v1)** | 2025-07-19 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v3)** | 2025-07-19 |  |
| **[Blackbox Dataset Inference for LLM](http://arxiv.org/abs/2507.03619v2)** | 2025-07-18 |  |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v4)** | 2025-07-18 | <details><summary>Final...</summary><p>Final Version and Paper Accepted at IEEE ITSC 2025</p></details> |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v2)** | 2025-07-17 |  |
| **[Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](http://arxiv.org/abs/2507.13474v1)** | 2025-07-17 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems](http://arxiv.org/abs/2507.15613v1)** | 2025-07-21 | 26 pages |
| **[From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](http://arxiv.org/abs/2506.15170v2)** | 2025-07-20 |  |
| **[Byzantine-Robust Decentralized Coordination of LLM Agents](http://arxiv.org/abs/2507.14928v1)** | 2025-07-20 |  |
| **[Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree](http://arxiv.org/abs/2507.14799v1)** | 2025-07-20 | <details><summary>EMNLP...</summary><p>EMNLP 2025 System Demonstrations Submission</p></details> |
| **[Configurable multi-agent framework for scalable and realistic testing of llm-based agents](http://arxiv.org/abs/2507.14705v1)** | 2025-07-19 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v3)** | 2025-07-19 |  |
| **[Blackbox Dataset Inference for LLM](http://arxiv.org/abs/2507.03619v2)** | 2025-07-18 |  |
| **[From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](http://arxiv.org/abs/2502.02145v4)** | 2025-07-18 | <details><summary>Final...</summary><p>Final Version and Paper Accepted at IEEE ITSC 2025</p></details> |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v2)** | 2025-07-17 |  |
| **[Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](http://arxiv.org/abs/2507.13474v1)** | 2025-07-17 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BackdoorDM: A Comprehensive Benchmark for Backdoor Learning on Diffusion Model](http://arxiv.org/abs/2502.11798v2)** | 2025-07-21 |  |
| **[Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models](http://arxiv.org/abs/2405.20090v5)** | 2025-07-21 | <details><summary>This ...</summary><p>This paper is accepted by ACM MM 2025</p></details> |
| **[Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models](http://arxiv.org/abs/2503.01781v2)** | 2025-07-21 | <details><summary>Accep...</summary><p>Accepted to CoLM 2025</p></details> |
| **[In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](http://arxiv.org/abs/2507.15285v1)** | 2025-07-21 | <details><summary>Submi...</summary><p>Submitted to IEEE-TIFS</p></details> |
| **[ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model](http://arxiv.org/abs/2507.15067v1)** | 2025-07-20 | 15 pages, 12 tables |
| **[Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model](http://arxiv.org/abs/2507.14668v1)** | 2025-07-19 | 15 pages, 14 figures |
| **[VLA-Mark: A cross modal watermark for large vision-language alignment model](http://arxiv.org/abs/2507.14067v1)** | 2025-07-18 |  |
| **[The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems](http://arxiv.org/abs/2507.14007v1)** | 2025-07-18 |  |
| **[GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](http://arxiv.org/abs/2507.13598v1)** | 2025-07-18 | <details><summary>Warni...</summary><p>Warning: This paper contains NSFW content. Reader discretion is advised</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v1)** | 2025-07-17 | <details><summary>Worki...</summary><p>Working in progress. 22 pages (8+ for main); 25 figures; 1 table</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BackdoorDM: A Comprehensive Benchmark for Backdoor Learning on Diffusion Model](http://arxiv.org/abs/2502.11798v2)** | 2025-07-21 |  |
| **[Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models](http://arxiv.org/abs/2405.20090v5)** | 2025-07-21 | <details><summary>This ...</summary><p>This paper is accepted by ACM MM 2025</p></details> |
| **[Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models](http://arxiv.org/abs/2503.01781v2)** | 2025-07-21 | <details><summary>Accep...</summary><p>Accepted to CoLM 2025</p></details> |
| **[In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](http://arxiv.org/abs/2507.15285v1)** | 2025-07-21 | <details><summary>Submi...</summary><p>Submitted to IEEE-TIFS</p></details> |
| **[ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model](http://arxiv.org/abs/2507.15067v1)** | 2025-07-20 | 15 pages, 12 tables |
| **[Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model](http://arxiv.org/abs/2507.14668v1)** | 2025-07-19 | 15 pages, 14 figures |
| **[VLA-Mark: A cross modal watermark for large vision-language alignment model](http://arxiv.org/abs/2507.14067v1)** | 2025-07-18 |  |
| **[The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems](http://arxiv.org/abs/2507.14007v1)** | 2025-07-18 |  |
| **[GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](http://arxiv.org/abs/2507.13598v1)** | 2025-07-18 | <details><summary>Warni...</summary><p>Warning: This paper contains NSFW content. Reader discretion is advised</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v1)** | 2025-07-17 | <details><summary>Worki...</summary><p>Working in progress. 22 pages (8+ for main); 25 figures; 1 table</p></details> |

