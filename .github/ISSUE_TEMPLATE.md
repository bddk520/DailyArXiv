---
title: Latest 15 Papers - June 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](http://arxiv.org/abs/2506.10949v1)** | 2025-06-12 |  |
| **[Improving LLM Safety Alignment with Dual-Objective Optimization](http://arxiv.org/abs/2503.03710v2)** | 2025-06-12 | ICML 2025 |
| **[SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](http://arxiv.org/abs/2506.10424v1)** | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted by the 34th USENIX Security Symposium 2025. Code is available at https://github.com/KaiyuanZh/SOFT</p></details> |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v1)** | 2025-06-12 |  |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v2)** | 2025-06-11 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v2)** | 2025-06-11 |  |
| **[LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge](http://arxiv.org/abs/2506.09443v1)** | 2025-06-11 |  |
| **[Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](http://arxiv.org/abs/2406.15481v3)** | 2025-06-11 | <details><summary>To ap...</summary><p>To appear in ACL 2025</p></details> |
| **[AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](http://arxiv.org/abs/2506.08885v2)** | 2025-06-11 |  |
| **[Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis](http://arxiv.org/abs/2506.08561v2)** | 2025-06-11 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](http://arxiv.org/abs/2506.10949v1)** | 2025-06-12 |  |
| **[Improving LLM Safety Alignment with Dual-Objective Optimization](http://arxiv.org/abs/2503.03710v2)** | 2025-06-12 | ICML 2025 |
| **[SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](http://arxiv.org/abs/2506.10424v1)** | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted by the 34th USENIX Security Symposium 2025. Code is available at https://github.com/KaiyuanZh/SOFT</p></details> |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v1)** | 2025-06-12 |  |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v2)** | 2025-06-11 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v2)** | 2025-06-11 |  |
| **[LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge](http://arxiv.org/abs/2506.09443v1)** | 2025-06-11 |  |
| **[Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](http://arxiv.org/abs/2406.15481v3)** | 2025-06-11 | <details><summary>To ap...</summary><p>To appear in ACL 2025</p></details> |
| **[AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](http://arxiv.org/abs/2506.08885v2)** | 2025-06-11 |  |
| **[Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis](http://arxiv.org/abs/2506.08561v2)** | 2025-06-11 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Weak-to-Strong Jailbreaking on Large Language Models](http://arxiv.org/abs/2401.17256v3)** | 2025-06-12 | ICML 2025 |
| **[Breaking Distortion-free Watermarks in Large Language Models](http://arxiv.org/abs/2502.18608v2)** | 2025-06-12 | <details><summary>22 pa...</summary><p>22 pages, 5 figures, 4 tables, earlier version presented at AAAI'25 Workshop on Preventing and Detecting LLM Generated Misinformation</p></details> |
| **[A hierarchical approach for assessing the vulnerability of tree-based classification models to membership inference attack](http://arxiv.org/abs/2502.09396v2)** | 2025-06-12 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v1)** | 2025-06-12 |  |
| **[Towards Action Hijacking of Large Language Model-based Agent](http://arxiv.org/abs/2412.10807v2)** | 2025-06-12 |  |
| **[CapST: Leveraging Capsule Networks and Temporal Attention for Accurate Model Attribution in Deep-fake Videos](http://arxiv.org/abs/2311.03782v4)** | 2025-06-12 |  |
| **[IoTGeM: Generalizable Models for Behaviour-Based IoT Attack Detection](http://arxiv.org/abs/2401.01343v2)** | 2025-06-12 | <details><summary>32 pa...</summary><p>32 pages (17 main, 15 supplementary appendix), 21 figures, 15 tables</p></details> |
| **[DiffUMI: Training-Free Universal Model Inversion via Unconditional Diffusion for Face Recognition](http://arxiv.org/abs/2504.18015v2)** | 2025-06-12 |  |
| **[Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](http://arxiv.org/abs/2403.12503v2)** | 2025-06-11 |  |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v1)** | 2025-06-11 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Weak-to-Strong Jailbreaking on Large Language Models](http://arxiv.org/abs/2401.17256v3)** | 2025-06-12 | ICML 2025 |
| **[Breaking Distortion-free Watermarks in Large Language Models](http://arxiv.org/abs/2502.18608v2)** | 2025-06-12 | <details><summary>22 pa...</summary><p>22 pages, 5 figures, 4 tables, earlier version presented at AAAI'25 Workshop on Preventing and Detecting LLM Generated Misinformation</p></details> |
| **[A hierarchical approach for assessing the vulnerability of tree-based classification models to membership inference attack](http://arxiv.org/abs/2502.09396v2)** | 2025-06-12 |  |
| **[SoK: Evaluating Jailbreak Guardrails for Large Language Models](http://arxiv.org/abs/2506.10597v1)** | 2025-06-12 |  |
| **[Towards Action Hijacking of Large Language Model-based Agent](http://arxiv.org/abs/2412.10807v2)** | 2025-06-12 |  |
| **[CapST: Leveraging Capsule Networks and Temporal Attention for Accurate Model Attribution in Deep-fake Videos](http://arxiv.org/abs/2311.03782v4)** | 2025-06-12 |  |
| **[IoTGeM: Generalizable Models for Behaviour-Based IoT Attack Detection](http://arxiv.org/abs/2401.01343v2)** | 2025-06-12 | <details><summary>32 pa...</summary><p>32 pages (17 main, 15 supplementary appendix), 21 figures, 15 tables</p></details> |
| **[DiffUMI: Training-Free Universal Model Inversion via Unconditional Diffusion for Face Recognition](http://arxiv.org/abs/2504.18015v2)** | 2025-06-12 |  |
| **[Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](http://arxiv.org/abs/2403.12503v2)** | 2025-06-11 |  |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v1)** | 2025-06-11 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |

