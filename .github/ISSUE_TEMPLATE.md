---
title: Latest 15 Papers - September 24, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM](http://arxiv.org/abs/2509.18058v1)** | 2025-09-22 |  |
| **[Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs](http://arxiv.org/abs/2505.17601v3)** | 2025-09-21 |  |
| **[AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software](http://arxiv.org/abs/2509.16861v1)** | 2025-09-21 | <details><summary>Accep...</summary><p>Accepted to the ASE 2025 International Conference on Automated Software Engineering, Industry Showcase Track</p></details> |
| **[Design and Development of an Intelligent LLM-based LDAP Honeypot](http://arxiv.org/abs/2509.16682v1)** | 2025-09-20 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v3)** | 2025-09-20 | <details><summary>Accep...</summary><p>Accepted by EMNLP2025</p></details> |
| **[From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](http://arxiv.org/abs/2509.14289v2)** | 2025-09-19 |  |
| **[Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs](http://arxiv.org/abs/2501.16534v2)** | 2025-09-19 |  |
| **[Inverting Trojans in LLMs](http://arxiv.org/abs/2509.16203v1)** | 2025-09-19 |  |
| **[On the Security of Tool-Invocation Prompts for LLM-Based Agentic Systems: An Empirical Risk Assessment](http://arxiv.org/abs/2509.05755v4)** | 2025-09-19 |  |
| **[Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](http://arxiv.org/abs/2509.15739v1)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 Findings</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM](http://arxiv.org/abs/2509.18058v1)** | 2025-09-22 |  |
| **[Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs](http://arxiv.org/abs/2505.17601v3)** | 2025-09-21 |  |
| **[AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software](http://arxiv.org/abs/2509.16861v1)** | 2025-09-21 | <details><summary>Accep...</summary><p>Accepted to the ASE 2025 International Conference on Automated Software Engineering, Industry Showcase Track</p></details> |
| **[Design and Development of an Intelligent LLM-based LDAP Honeypot](http://arxiv.org/abs/2509.16682v1)** | 2025-09-20 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v3)** | 2025-09-20 | <details><summary>Accep...</summary><p>Accepted by EMNLP2025</p></details> |
| **[From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](http://arxiv.org/abs/2509.14289v2)** | 2025-09-19 |  |
| **[Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs](http://arxiv.org/abs/2501.16534v2)** | 2025-09-19 |  |
| **[Inverting Trojans in LLMs](http://arxiv.org/abs/2509.16203v1)** | 2025-09-19 |  |
| **[On the Security of Tool-Invocation Prompts for LLM-Based Agentic Systems: An Empirical Risk Assessment](http://arxiv.org/abs/2509.05755v4)** | 2025-09-19 |  |
| **[Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](http://arxiv.org/abs/2509.15739v1)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 Findings</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Large Language Models for Cyber Security: A Systematic Literature Review](http://arxiv.org/abs/2405.04760v5)** | 2025-09-22 | <details><summary>Accep...</summary><p>Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)</p></details> |
| **[Proxy-Embedding as an Adversarial Teacher: An Embedding-Guided Bidirectional Attack for Referring Expression Segmentation Models](http://arxiv.org/abs/2506.16157v2)** | 2025-09-22 | 20pages, 5figures |
| **[SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models](http://arxiv.org/abs/2509.17371v1)** | 2025-09-22 |  |
| **[SUA: Stealthy Multimodal Large Language Model Unlearning Attack](http://arxiv.org/abs/2506.17265v2)** | 2025-09-21 | EMNLP25 |
| **[Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](http://arxiv.org/abs/2506.11113v2)** | 2025-09-21 |  |
| **[Rethinking Backdoor Detection Evaluation for Language Models](http://arxiv.org/abs/2409.00399v2)** | 2025-09-21 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v2)** | 2025-09-20 | <details><summary>EMNLP...</summary><p>EMNLP 2025 Main Conference. 23 pages (8+ for main); 25 figures; 1 table</p></details> |
| **[FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts](http://arxiv.org/abs/2502.21059v3)** | 2025-09-20 | <details><summary>Accep...</summary><p>Accepted to Findings of EMNLP 2025</p></details> |
| **[Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking](http://arxiv.org/abs/2502.12970v3)** | 2025-09-20 | EMNLP 2025 |
| **[Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](http://arxiv.org/abs/2507.11630v2)** | 2025-09-20 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Large Language Models for Cyber Security: A Systematic Literature Review](http://arxiv.org/abs/2405.04760v5)** | 2025-09-22 | <details><summary>Accep...</summary><p>Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)</p></details> |
| **[Proxy-Embedding as an Adversarial Teacher: An Embedding-Guided Bidirectional Attack for Referring Expression Segmentation Models](http://arxiv.org/abs/2506.16157v2)** | 2025-09-22 | 20pages, 5figures |
| **[SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models](http://arxiv.org/abs/2509.17371v1)** | 2025-09-22 |  |
| **[SUA: Stealthy Multimodal Large Language Model Unlearning Attack](http://arxiv.org/abs/2506.17265v2)** | 2025-09-21 | EMNLP25 |
| **[Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](http://arxiv.org/abs/2506.11113v2)** | 2025-09-21 |  |
| **[Rethinking Backdoor Detection Evaluation for Language Models](http://arxiv.org/abs/2409.00399v2)** | 2025-09-21 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025</p></details> |
| **[Automating Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2507.13255v2)** | 2025-09-20 | <details><summary>EMNLP...</summary><p>EMNLP 2025 Main Conference. 23 pages (8+ for main); 25 figures; 1 table</p></details> |
| **[FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts](http://arxiv.org/abs/2502.21059v3)** | 2025-09-20 | <details><summary>Accep...</summary><p>Accepted to Findings of EMNLP 2025</p></details> |
| **[Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking](http://arxiv.org/abs/2502.12970v3)** | 2025-09-20 | EMNLP 2025 |
| **[Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](http://arxiv.org/abs/2507.11630v2)** | 2025-09-20 |  |

