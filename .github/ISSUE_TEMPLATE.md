---
title: Latest 15 Papers - June 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text](http://arxiv.org/abs/2502.14921v2)** | 2025-06-06 | <details><summary>42nd ...</summary><p>42nd International Conference on Machine Learning (ICML 2025)</p></details> |
| **[FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting](http://arxiv.org/abs/2501.16029v2)** | 2025-06-06 |  |
| **[UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](http://arxiv.org/abs/2503.01908v2)** | 2025-06-06 |  |
| **[To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt](http://arxiv.org/abs/2506.05739v1)** | 2025-06-06 | <details><summary>To ap...</summary><p>To appear in the Industry Track of the 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2025)</p></details> |
| **[TracLLM: A Generic Framework for Attributing Long Context LLMs](http://arxiv.org/abs/2506.04202v2)** | 2025-06-06 | <details><summary>To ap...</summary><p>To appear in USENIX Security Symposium 2025. The code and data are at: https://github.com/Wang-Yanting/TracLLM</p></details> |
| **[Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS](http://arxiv.org/abs/2506.01245v2)** | 2025-06-06 |  |
| **[SoK: Are Watermarks in LLMs Ready for Deployment?](http://arxiv.org/abs/2506.05594v1)** | 2025-06-05 |  |
| **[Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets](http://arxiv.org/abs/2506.05346v1)** | 2025-06-05 | <details><summary>Proje...</summary><p>Project Page: https://hsiung.cc/llm-similarity-risk/</p></details> |
| **[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](http://arxiv.org/abs/2505.23847v2)** | 2025-06-05 |  |
| **[On Automating Security Policies with Contemporary LLMs](http://arxiv.org/abs/2506.04838v1)** | 2025-06-05 | <details><summary>Short...</summary><p>Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES 2025)</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text](http://arxiv.org/abs/2502.14921v2)** | 2025-06-06 | <details><summary>42nd ...</summary><p>42nd International Conference on Machine Learning (ICML 2025)</p></details> |
| **[FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting](http://arxiv.org/abs/2501.16029v2)** | 2025-06-06 |  |
| **[UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](http://arxiv.org/abs/2503.01908v2)** | 2025-06-06 |  |
| **[To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt](http://arxiv.org/abs/2506.05739v1)** | 2025-06-06 | <details><summary>To ap...</summary><p>To appear in the Industry Track of the 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2025)</p></details> |
| **[TracLLM: A Generic Framework for Attributing Long Context LLMs](http://arxiv.org/abs/2506.04202v2)** | 2025-06-06 | <details><summary>To ap...</summary><p>To appear in USENIX Security Symposium 2025. The code and data are at: https://github.com/Wang-Yanting/TracLLM</p></details> |
| **[Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS](http://arxiv.org/abs/2506.01245v2)** | 2025-06-06 |  |
| **[SoK: Are Watermarks in LLMs Ready for Deployment?](http://arxiv.org/abs/2506.05594v1)** | 2025-06-05 |  |
| **[Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets](http://arxiv.org/abs/2506.05346v1)** | 2025-06-05 | <details><summary>Proje...</summary><p>Project Page: https://hsiung.cc/llm-similarity-risk/</p></details> |
| **[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](http://arxiv.org/abs/2505.23847v2)** | 2025-06-05 |  |
| **[On Automating Security Policies with Contemporary LLMs](http://arxiv.org/abs/2506.04838v1)** | 2025-06-05 | <details><summary>Short...</summary><p>Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES 2025)</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models](http://arxiv.org/abs/2506.06060v1)** | 2025-06-06 | 10 pages, 4 figures |
| **[Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models](http://arxiv.org/abs/2506.06018v1)** | 2025-06-06 |  |
| **[Stealix: Model Stealing via Prompt Evolution](http://arxiv.org/abs/2506.05867v1)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted at ICML 2025. The project page is at https://zhixiongzh.github.io/stealix/</p></details> |
| **[PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning](http://arxiv.org/abs/2410.08811v2)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted at ICML 2025. Tingchen Fu and Fazl Barez are core research contributors</p></details> |
| **[Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Audio-Language Models](http://arxiv.org/abs/2411.14842v2)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures](http://arxiv.org/abs/2410.14667v3)** | 2025-06-06 | ICML 2025 |
| **[A Comprehensive Survey on Concept Erasure in Text-to-Image Diffusion Models](http://arxiv.org/abs/2502.14896v2)** | 2025-06-06 |  |
| **[FIST: A Structured Threat Modeling Framework for Fraud Incidents](http://arxiv.org/abs/2506.05740v1)** | 2025-06-06 |  |
| **[FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model](http://arxiv.org/abs/2506.05640v1)** | 2025-06-06 |  |
| **[Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?](http://arxiv.org/abs/2506.05263v1)** | 2025-06-05 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models](http://arxiv.org/abs/2506.06060v1)** | 2025-06-06 | 10 pages, 4 figures |
| **[Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models](http://arxiv.org/abs/2506.06018v1)** | 2025-06-06 |  |
| **[Stealix: Model Stealing via Prompt Evolution](http://arxiv.org/abs/2506.05867v1)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted at ICML 2025. The project page is at https://zhixiongzh.github.io/stealix/</p></details> |
| **[PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning](http://arxiv.org/abs/2410.08811v2)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted at ICML 2025. Tingchen Fu and Fazl Barez are core research contributors</p></details> |
| **[Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Audio-Language Models](http://arxiv.org/abs/2411.14842v2)** | 2025-06-06 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures](http://arxiv.org/abs/2410.14667v3)** | 2025-06-06 | ICML 2025 |
| **[A Comprehensive Survey on Concept Erasure in Text-to-Image Diffusion Models](http://arxiv.org/abs/2502.14896v2)** | 2025-06-06 |  |
| **[FIST: A Structured Threat Modeling Framework for Fraud Incidents](http://arxiv.org/abs/2506.05740v1)** | 2025-06-06 |  |
| **[FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model](http://arxiv.org/abs/2506.05640v1)** | 2025-06-06 |  |
| **[Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?](http://arxiv.org/abs/2506.05263v1)** | 2025-06-05 |  |

