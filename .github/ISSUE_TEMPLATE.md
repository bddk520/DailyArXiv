---
title: Latest 15 Papers - April 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |
| **[SAEs $\textit{Can}$ Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs](http://arxiv.org/abs/2504.08192v1)** | 2025-04-11 |  |
| **[Geneshift: Impact of different scenario shift on Jailbreaking LLM](http://arxiv.org/abs/2504.08104v1)** | 2025-04-10 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](http://arxiv.org/abs/2504.06575v2)** | 2025-04-10 |  |
| **[LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks](http://arxiv.org/abs/2410.02916v3)** | 2025-04-09 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v2)** | 2025-04-09 |  |
| **[StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](http://arxiv.org/abs/2504.05804v1)** | 2025-04-08 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v1)** | 2025-04-08 |  |
| **[ShadowCoT: Cognitive Hijacking for Stealthy Reasoning Backdoors in LLMs](http://arxiv.org/abs/2504.05605v1)** | 2025-04-08 | <details><summary>Zhao ...</summary><p>Zhao et al., 16 pages, 2025, uploaded by Hanzhou Wu, Shanghai University</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |
| **[SAEs $\textit{Can}$ Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs](http://arxiv.org/abs/2504.08192v1)** | 2025-04-11 |  |
| **[Geneshift: Impact of different scenario shift on Jailbreaking LLM](http://arxiv.org/abs/2504.08104v1)** | 2025-04-10 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](http://arxiv.org/abs/2504.06575v2)** | 2025-04-10 |  |
| **[AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment](http://arxiv.org/abs/2410.11283v2)** | 2025-04-09 | <details><summary>Publi...</summary><p>Published at the Neurips Safe Generative AI Workshop 2024</p></details> |
| **[LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks](http://arxiv.org/abs/2410.02916v3)** | 2025-04-09 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v2)** | 2025-04-09 |  |
| **[StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](http://arxiv.org/abs/2504.05804v1)** | 2025-04-08 |  |
| **[Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](http://arxiv.org/abs/2504.05652v1)** | 2025-04-08 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |
| **[Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](http://arxiv.org/abs/2504.08623v1)** | 2025-04-11 | <details><summary>11 pa...</summary><p>11 pages, 2 figures, 1 table</p></details> |
| **[An Early Experience with Confidential Computing Architecture for On-Device Model Protection](http://arxiv.org/abs/2504.08508v1)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted to the 8th Workshop on System Software for Trusted Execution (SysTEX 2025)</p></details> |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v2)** | 2025-04-11 | <details><summary>Submi...</summary><p>Submitted to CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models](http://arxiv.org/abs/2504.08205v1)** | 2025-04-11 | <details><summary>Prese...</summary><p>Presented as a poster at ACSAC 2024</p></details> |
| **[Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings](http://arxiv.org/abs/2501.18998v2)** | 2025-04-10 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v2)** | 2025-04-10 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Code Generation with Small Language Models: A Deep Evaluation on Codeforces](http://arxiv.org/abs/2504.07343v1)** | 2025-04-09 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |
| **[Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](http://arxiv.org/abs/2504.08623v1)** | 2025-04-11 | <details><summary>11 pa...</summary><p>11 pages, 2 figures, 1 table</p></details> |
| **[An Early Experience with Confidential Computing Architecture for On-Device Model Protection](http://arxiv.org/abs/2504.08508v1)** | 2025-04-11 | <details><summary>Accep...</summary><p>Accepted to the 8th Workshop on System Software for Trusted Execution (SysTEX 2025)</p></details> |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v2)** | 2025-04-11 | <details><summary>Submi...</summary><p>Submitted to CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models](http://arxiv.org/abs/2504.08205v1)** | 2025-04-11 | <details><summary>Prese...</summary><p>Presented as a poster at ACSAC 2024</p></details> |
| **[Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings](http://arxiv.org/abs/2501.18998v2)** | 2025-04-10 |  |
| **[Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)** | 2025-04-10 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v1)** | 2025-04-10 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |
| **[The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning](http://arxiv.org/abs/2502.04106v2)** | 2025-04-10 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Code Generation with Small Language Models: A Deep Evaluation on Codeforces](http://arxiv.org/abs/2504.07343v1)** | 2025-04-09 |  |

