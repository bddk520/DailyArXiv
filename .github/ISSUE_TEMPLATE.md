---
title: Latest 15 Papers - July 25, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v2)** | 2025-07-23 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v4)** | 2025-07-22 |  |
| **[Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](http://arxiv.org/abs/2507.16291v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by EAI ICDF2C 2025</p></details> |
| **[Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems](http://arxiv.org/abs/2507.15613v1)** | 2025-07-21 | 26 pages |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v2)** | 2025-07-23 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v4)** | 2025-07-22 |  |
| **[Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](http://arxiv.org/abs/2507.16291v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by EAI ICDF2C 2025</p></details> |
| **[Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems](http://arxiv.org/abs/2507.15613v1)** | 2025-07-21 | 26 pages |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v4)** | 2025-07-23 |  |
| **[Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models](http://arxiv.org/abs/2504.05815v2)** | 2025-07-23 |  |
| **[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models](http://arxiv.org/abs/2502.20650v4)** | 2025-07-23 |  |
| **[LLM4MEA: Data-free Model Extraction Attacks on Sequential Recommenders via Large Language Models](http://arxiv.org/abs/2507.16969v1)** | 2025-07-22 |  |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v2)** | 2025-07-22 | <details><summary>This ...</summary><p>This version includes updated results and expanded discussion</p></details> |
| **[Benchmarking machine learning models for predicting aerofoil performance](http://arxiv.org/abs/2504.15993v2)** | 2025-07-22 | <details><summary>9 pag...</summary><p>9 pages, 10 figures, submitted to EWTEC</p></details> |
| **[Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?](http://arxiv.org/abs/2507.16393v1)** | 2025-07-22 | Accepted at FG 2025 |
| **[CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage](http://arxiv.org/abs/2507.16872v1)** | 2025-07-22 |  |
| **[Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation](http://arxiv.org/abs/2505.17579v2)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted to EUSIPCO 2025</p></details> |
| **[Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models](http://arxiv.org/abs/2507.16257v1)** | 2025-07-22 | ACMMM 2025 Accepted |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v4)** | 2025-07-23 |  |
| **[Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models](http://arxiv.org/abs/2504.05815v2)** | 2025-07-23 |  |
| **[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models](http://arxiv.org/abs/2502.20650v4)** | 2025-07-23 |  |
| **[LLM4MEA: Data-free Model Extraction Attacks on Sequential Recommenders via Large Language Models](http://arxiv.org/abs/2507.16969v1)** | 2025-07-22 |  |
| **[More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment](http://arxiv.org/abs/2504.02193v2)** | 2025-07-22 | <details><summary>This ...</summary><p>This version includes updated results and expanded discussion</p></details> |
| **[Benchmarking machine learning models for predicting aerofoil performance](http://arxiv.org/abs/2504.15993v2)** | 2025-07-22 | <details><summary>9 pag...</summary><p>9 pages, 10 figures, submitted to EWTEC</p></details> |
| **[Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?](http://arxiv.org/abs/2507.16393v1)** | 2025-07-22 | Accepted at FG 2025 |
| **[CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage](http://arxiv.org/abs/2507.16872v1)** | 2025-07-22 |  |
| **[Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation](http://arxiv.org/abs/2505.17579v2)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted to EUSIPCO 2025</p></details> |
| **[Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models](http://arxiv.org/abs/2507.16257v1)** | 2025-07-22 | ACMMM 2025 Accepted |

