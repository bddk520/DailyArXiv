---
title: Latest 15 Papers - January 28, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v1)** | 2026-01-26 |  |
| **[AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110v1)** | 2026-01-26 |  |
| **[Jailbreak-as-a-Service++: Unveiling Distributed AI-Driven Malicious Information Campaigns Powered by LLM Crowdsourcing](https://arxiv.org/abs/2505.21184v4)** | 2026-01-24 |  |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697v2)** | 2026-01-24 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](https://arxiv.org/abs/2510.14005v3)** | 2026-01-24 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133v1)** | 2026-01-23 | <details><summary>Accep...</summary><p>Accepted to AAAI 2026. 13 pages, 3 figures, 10 tables. Code available at: https://github.com/FujitsuResearch/knexa-fl</p></details> |
| **[LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890v1)** | 2026-01-23 |  |
| **[LLM Jailbreak Detection for (Almost) Free!](https://arxiv.org/abs/2509.14558v2)** | 2026-01-23 | <details><summary>EMNLP...</summary><p>EMNLP 2025 (Findings) https://aclanthology.org/2025.findings-emnlp.309/</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v1)** | 2026-01-26 |  |
| **[AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110v1)** | 2026-01-26 |  |
| **[Jailbreak-as-a-Service++: Unveiling Distributed AI-Driven Malicious Information Campaigns Powered by LLM Crowdsourcing](https://arxiv.org/abs/2505.21184v4)** | 2026-01-24 |  |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697v2)** | 2026-01-24 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |
| **[PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](https://arxiv.org/abs/2510.14005v3)** | 2026-01-24 | <details><summary>The c...</summary><p>The code is available at https://github.com/weizou52/PIShield</p></details> |
| **[Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133v1)** | 2026-01-23 | <details><summary>Accep...</summary><p>Accepted to AAAI 2026. 13 pages, 3 figures, 10 tables. Code available at: https://github.com/FujitsuResearch/knexa-fl</p></details> |
| **[LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890v1)** | 2026-01-23 |  |
| **[LLM Jailbreak Detection for (Almost) Free!](https://arxiv.org/abs/2509.14558v2)** | 2026-01-23 | <details><summary>EMNLP...</summary><p>EMNLP 2025 (Findings) https://aclanthology.org/2025.findings-emnlp.309/</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[CtrlRAG: Black-box Document Poisoning Attacks for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2503.06950v2)** | 2026-01-26 |  |
| **[Beyond Data Privacy: New Privacy Risks for Large Language Models](https://arxiv.org/abs/2509.14278v2)** | 2026-01-26 | <details><summary>Publi...</summary><p>Published in the IEEE Data Engineering Bulletin: http://sites.computer.org/debull/A25dec/issue1.htm</p></details> |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303v3)** | 2026-01-26 | 12 pages, 21 figures |
| **[Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair](https://arxiv.org/abs/2509.05372v2)** | 2026-01-26 |  |
| **[Detecting Training Data of Large Language Models via Expectation Maximization](https://arxiv.org/abs/2410.07582v3)** | 2026-01-26 | EACL 2026 |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](https://arxiv.org/abs/2510.02712v3)** | 2026-01-25 |  |
| **[Spoofing-Aware Speaker Verification via Wavelet Prompt Tuning and Multi-Model Ensembles](https://arxiv.org/abs/2601.17557v1)** | 2026-01-24 | <details><summary>Syste...</summary><p>System description of the T03 team in the WildSpoof Challenge at ICASSP 2026</p></details> |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536v1)** | 2026-01-24 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[CtrlRAG: Black-box Document Poisoning Attacks for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2503.06950v2)** | 2026-01-26 |  |
| **[Beyond Data Privacy: New Privacy Risks for Large Language Models](https://arxiv.org/abs/2509.14278v2)** | 2026-01-26 | <details><summary>Publi...</summary><p>Published in the IEEE Data Engineering Bulletin: http://sites.computer.org/debull/A25dec/issue1.htm</p></details> |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303v3)** | 2026-01-26 | 12 pages, 21 figures |
| **[Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair](https://arxiv.org/abs/2509.05372v2)** | 2026-01-26 |  |
| **[Detecting Training Data of Large Language Models via Expectation Maximization](https://arxiv.org/abs/2410.07582v3)** | 2026-01-26 | EACL 2026 |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](https://arxiv.org/abs/2510.02712v3)** | 2026-01-25 |  |
| **[Spoofing-Aware Speaker Verification via Wavelet Prompt Tuning and Multi-Model Ensembles](https://arxiv.org/abs/2601.17557v1)** | 2026-01-24 | <details><summary>Syste...</summary><p>System description of the T03 team in the WildSpoof Challenge at ICASSP 2026</p></details> |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536v1)** | 2026-01-24 |  |

