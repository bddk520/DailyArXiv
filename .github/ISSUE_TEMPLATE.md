---
title: Latest 15 Papers - May 26, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](http://arxiv.org/abs/2505.16947v1)** | 2025-05-22 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework](http://arxiv.org/abs/2505.16888v1)** | 2025-05-22 |  |
| **[When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques](http://arxiv.org/abs/2505.16765v1)** | 2025-05-22 |  |
| **[Firewalls to Secure Dynamic LLM Agentic Networks](http://arxiv.org/abs/2502.01822v4)** | 2025-05-22 |  |
| **[Finetuning-Activated Backdoors in LLMs](http://arxiv.org/abs/2505.16567v1)** | 2025-05-22 |  |
| **[PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks](http://arxiv.org/abs/2505.13862v2)** | 2025-05-22 |  |
| **[Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](http://arxiv.org/abs/2505.15738v1)** | 2025-05-21 |  |
| **[A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](http://arxiv.org/abs/2505.15683v1)** | 2025-05-21 |  |
| **[Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](http://arxiv.org/abs/2505.15656v1)** | 2025-05-21 | 19 pages |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](http://arxiv.org/abs/2505.16947v1)** | 2025-05-22 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework](http://arxiv.org/abs/2505.16888v1)** | 2025-05-22 |  |
| **[When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques](http://arxiv.org/abs/2505.16765v1)** | 2025-05-22 |  |
| **[Firewalls to Secure Dynamic LLM Agentic Networks](http://arxiv.org/abs/2502.01822v4)** | 2025-05-22 |  |
| **[Finetuning-Activated Backdoors in LLMs](http://arxiv.org/abs/2505.16567v1)** | 2025-05-22 |  |
| **[PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks](http://arxiv.org/abs/2505.13862v2)** | 2025-05-22 |  |
| **[Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](http://arxiv.org/abs/2505.15738v1)** | 2025-05-21 |  |
| **[A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](http://arxiv.org/abs/2505.15683v1)** | 2025-05-21 |  |
| **[Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](http://arxiv.org/abs/2505.15656v1)** | 2025-05-21 | 19 pages |
| **[Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](http://arxiv.org/abs/2505.15337v1)** | 2025-05-21 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Are Concepts Erased From Diffusion Models?](http://arxiv.org/abs/2505.17013v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project Page: https://nyu-dice-lab.github.io/when-are-concepts-erased/</p></details> |
| **[Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models](http://arxiv.org/abs/2505.16957v1)** | 2025-05-22 |  |
| **[Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability](http://arxiv.org/abs/2505.16789v1)** | 2025-05-22 |  |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](http://arxiv.org/abs/2505.16670v1)** | 2025-05-22 |  |
| **[Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models](http://arxiv.org/abs/2412.16555v2)** | 2025-05-22 |  |
| **[From Evaluation to Defense: Advancing Safety in Video Large Language Models](http://arxiv.org/abs/2505.16643v1)** | 2025-05-22 | <details><summary>49 pa...</summary><p>49 pages, 12 figures, 17 tables</p></details> |
| **[BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization](http://arxiv.org/abs/2505.16640v1)** | 2025-05-22 | <details><summary>19 pa...</summary><p>19 pages, 12 figures, 6 tables</p></details> |
| **[CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning](http://arxiv.org/abs/2505.16559v1)** | 2025-05-22 |  |
| **[Language-based Security and Time-inserting Supervisor](http://arxiv.org/abs/2505.16503v1)** | 2025-05-22 |  |
| **[Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](http://arxiv.org/abs/2505.16446v1)** | 2025-05-22 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Are Concepts Erased From Diffusion Models?](http://arxiv.org/abs/2505.17013v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project Page: https://nyu-dice-lab.github.io/when-are-concepts-erased/</p></details> |
| **[Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models](http://arxiv.org/abs/2505.16957v1)** | 2025-05-22 |  |
| **[Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability](http://arxiv.org/abs/2505.16789v1)** | 2025-05-22 |  |
| **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](http://arxiv.org/abs/2505.16670v1)** | 2025-05-22 |  |
| **[Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models](http://arxiv.org/abs/2412.16555v2)** | 2025-05-22 |  |
| **[From Evaluation to Defense: Advancing Safety in Video Large Language Models](http://arxiv.org/abs/2505.16643v1)** | 2025-05-22 | <details><summary>49 pa...</summary><p>49 pages, 12 figures, 17 tables</p></details> |
| **[BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization](http://arxiv.org/abs/2505.16640v1)** | 2025-05-22 | <details><summary>19 pa...</summary><p>19 pages, 12 figures, 6 tables</p></details> |
| **[CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning](http://arxiv.org/abs/2505.16559v1)** | 2025-05-22 |  |
| **[Language-based Security and Time-inserting Supervisor](http://arxiv.org/abs/2505.16503v1)** | 2025-05-22 |  |
| **[Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](http://arxiv.org/abs/2505.16446v1)** | 2025-05-22 |  |

