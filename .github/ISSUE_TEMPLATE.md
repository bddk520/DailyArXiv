---
title: Latest 15 Papers - July 04, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](http://arxiv.org/abs/2507.01752v1)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](http://arxiv.org/abs/2507.01513v1)** | 2025-07-02 |  |
| **[Don't Say No: Jailbreaking LLM by Suppressing Refusal](http://arxiv.org/abs/2404.16369v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v4)** | 2025-07-01 |  |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](http://arxiv.org/abs/2506.23260v1)** | 2025-06-29 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, 6 tables</p></details> |
| **[Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation](http://arxiv.org/abs/2506.23034v1)** | 2025-06-28 |  |
| **[Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](http://arxiv.org/abs/2506.22776v1)** | 2025-06-28 | 13 pages, 6 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](http://arxiv.org/abs/2507.01752v1)** | 2025-07-02 |  |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](http://arxiv.org/abs/2507.01513v1)** | 2025-07-02 |  |
| **[Don't Say No: Jailbreaking LLM by Suppressing Refusal](http://arxiv.org/abs/2404.16369v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v4)** | 2025-07-01 |  |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](http://arxiv.org/abs/2506.23260v1)** | 2025-06-29 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, 6 tables</p></details> |
| **[Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation](http://arxiv.org/abs/2506.23034v1)** | 2025-06-28 |  |
| **[Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](http://arxiv.org/abs/2506.22776v1)** | 2025-06-28 | 13 pages, 6 figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[Backdooring Bias (B^2) into Stable Diffusion Models](http://arxiv.org/abs/2406.15213v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted to USENIX Security '25</p></details> |
| **[CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs](http://arxiv.org/abs/2507.00817v1)** | 2025-07-01 |  |
| **[Impact of Fine-Tuning Methods on Memorization in Large Language Models](http://arxiv.org/abs/2507.00258v1)** | 2025-06-30 |  |
| **[Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)](http://arxiv.org/abs/2311.10248v3)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2025. This is the full version</p></details> |
| **[Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](http://arxiv.org/abs/2506.24056v1)** | 2025-06-30 |  |
| **[Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures](http://arxiv.org/abs/2506.23622v1)** | 2025-06-30 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v1)** | 2025-06-30 |  |
| **[Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](http://arxiv.org/abs/2506.23576v1)** | 2025-06-30 | 26 pages, 1 figure |
| **[Automating Adjudication of Cardiovascular Events Using Large Language Models](http://arxiv.org/abs/2503.17222v2)** | 2025-06-29 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks](http://arxiv.org/abs/2507.01694v1)** | 2025-07-02 | 7 pages, 5 figures |
| **[Backdooring Bias (B^2) into Stable Diffusion Models](http://arxiv.org/abs/2406.15213v3)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted to USENIX Security '25</p></details> |
| **[CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs](http://arxiv.org/abs/2507.00817v1)** | 2025-07-01 |  |
| **[Impact of Fine-Tuning Methods on Memorization in Large Language Models](http://arxiv.org/abs/2507.00258v1)** | 2025-06-30 |  |
| **[Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version)](http://arxiv.org/abs/2311.10248v3)** | 2025-06-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2025. This is the full version</p></details> |
| **[Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](http://arxiv.org/abs/2506.24056v1)** | 2025-06-30 |  |
| **[Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures](http://arxiv.org/abs/2506.23622v1)** | 2025-06-30 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v1)** | 2025-06-30 |  |
| **[Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](http://arxiv.org/abs/2506.23576v1)** | 2025-06-30 | 26 pages, 1 figure |
| **[Automating Adjudication of Cardiovascular Events Using Large Language Models](http://arxiv.org/abs/2503.17222v2)** | 2025-06-29 |  |

