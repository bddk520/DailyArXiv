---
title: Latest 15 Papers - September 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](http://arxiv.org/abs/2504.15241v3)** | 2025-09-26 | Preprint |
| **[QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA](http://arxiv.org/abs/2506.08123v4)** | 2025-09-26 | <details><summary>Accep...</summary><p>Accepted to Findings of EMNLP 2025</p></details> |
| **[The Rogue Scalpel: Activation Steering Compromises LLM Safety](http://arxiv.org/abs/2509.22067v1)** | 2025-09-26 |  |
| **[Active Attacks: Red-teaming LLMs via Adaptive Environments](http://arxiv.org/abs/2509.21947v1)** | 2025-09-26 | <details><summary>22 pa...</summary><p>22 pages, 7 figures, 18 tables</p></details> |
| **[You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors](http://arxiv.org/abs/2509.21884v1)** | 2025-09-26 | <details><summary>29 pa...</summary><p>29 pages, 10 tables, 6figures, accepted by CCS 25</p></details> |
| **[Improving LLM Unlearning Robustness via Random Perturbations](http://arxiv.org/abs/2501.19202v4)** | 2025-09-25 | <details><summary>29 pa...</summary><p>29 pages, 13 figures, 8 tables</p></details> |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v3)** | 2025-09-25 |  |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[RLCracker: Exposing the Vulnerability of LLM Watermarks with Adaptive RL Attacks](http://arxiv.org/abs/2509.20924v1)** | 2025-09-25 |  |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v2)** | 2025-09-25 | Preprint |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](http://arxiv.org/abs/2504.15241v3)** | 2025-09-26 | Preprint |
| **[QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA](http://arxiv.org/abs/2506.08123v4)** | 2025-09-26 | <details><summary>Accep...</summary><p>Accepted to Findings of EMNLP 2025</p></details> |
| **[The Rogue Scalpel: Activation Steering Compromises LLM Safety](http://arxiv.org/abs/2509.22067v1)** | 2025-09-26 |  |
| **[Active Attacks: Red-teaming LLMs via Adaptive Environments](http://arxiv.org/abs/2509.21947v1)** | 2025-09-26 | <details><summary>22 pa...</summary><p>22 pages, 7 figures, 18 tables</p></details> |
| **[You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors](http://arxiv.org/abs/2509.21884v1)** | 2025-09-26 | <details><summary>29 pa...</summary><p>29 pages, 10 tables, 6figures, accepted by CCS 25</p></details> |
| **[Improving LLM Unlearning Robustness via Random Perturbations](http://arxiv.org/abs/2501.19202v4)** | 2025-09-25 | <details><summary>29 pa...</summary><p>29 pages, 13 figures, 8 tables</p></details> |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v3)** | 2025-09-25 |  |
| **[Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools](http://arxiv.org/abs/2509.21011v1)** | 2025-09-25 |  |
| **[RLCracker: Exposing the Vulnerability of LLM Watermarks with Adaptive RL Attacks](http://arxiv.org/abs/2509.20924v1)** | 2025-09-25 |  |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v2)** | 2025-09-25 | Preprint |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v6)** | 2025-09-26 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Jailbreaking on Text-to-Video Models via Scene Splitting Strategy](http://arxiv.org/abs/2509.22292v1)** | 2025-09-26 |  |
| **[GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](http://arxiv.org/abs/2509.21192v2)** | 2025-09-26 | <details><summary>16 pa...</summary><p>16 pages, 5 figures, 4 tables</p></details> |
| **[Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models](http://arxiv.org/abs/2505.15130v3)** | 2025-09-26 |  |
| **[Guidance Watermarking for Diffusion Models](http://arxiv.org/abs/2509.22126v1)** | 2025-09-26 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v6)** | 2025-09-26 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[Jailbreaking on Text-to-Video Models via Scene Splitting Strategy](http://arxiv.org/abs/2509.22292v1)** | 2025-09-26 |  |
| **[GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](http://arxiv.org/abs/2509.21192v2)** | 2025-09-26 | <details><summary>16 pa...</summary><p>16 pages, 5 figures, 4 tables</p></details> |
| **[Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models](http://arxiv.org/abs/2505.15130v3)** | 2025-09-26 |  |
| **[Guidance Watermarking for Diffusion Models](http://arxiv.org/abs/2509.22126v1)** | 2025-09-26 |  |
| **[Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning](http://arxiv.org/abs/2509.22082v1)** | 2025-09-26 |  |
| **[Partially Functional Dynamic Backdoor Diffusion-based Causal Model](http://arxiv.org/abs/2509.00472v2)** | 2025-09-26 | 10 pages, 2 figures |
| **[Resource Consumption Red-Teaming for Large Vision-Language Models](http://arxiv.org/abs/2507.18053v2)** | 2025-09-26 |  |
| **[SBFA: Single Sneaky Bit Flip Attack to Break Large Language Models](http://arxiv.org/abs/2509.21843v1)** | 2025-09-26 | <details><summary>10 pa...</summary><p>10 pages, 4 figures, 5 tables, 2 equations. Topics: Bit-flip attacks, adversarial attacks, large language models (LLMs)</p></details> |
| **[Towards Minimal Causal Representations for Human Multimodal Language Understanding](http://arxiv.org/abs/2509.21805v1)** | 2025-09-26 |  |

