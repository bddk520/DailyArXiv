---
title: Latest 15 Papers - August 25, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](http://arxiv.org/abs/2508.05469v2)** | 2025-08-21 | <details><summary>Add A...</summary><p>Add AUC results, pre-reg conformance, theory section clarification. 12 pages</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v2)** | 2025-08-21 |  |
| **[Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](http://arxiv.org/abs/2508.15449v1)** | 2025-08-21 | <details><summary>10 pa...</summary><p>10 pages, 9 figures, Under review as a full paper at AAAI 2026. A preliminary version is under review at the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](http://arxiv.org/abs/2508.15310v1)** | 2025-08-21 | EMNLP 2025 |
| **[MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs](http://arxiv.org/abs/2508.15036v1)** | 2025-08-20 | <details><summary>This ...</summary><p>This paper will appear in CCS 2025</p></details> |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection](http://arxiv.org/abs/2508.14128v1)** | 2025-08-19 | 11 pages, 1 figure |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v2)** | 2025-08-18 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |
| **[RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](http://arxiv.org/abs/2508.13152v1)** | 2025-08-18 | <details><summary>Accep...</summary><p>Accepted to TACL 2025. This version is a pre-MIT Press publication version</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](http://arxiv.org/abs/2508.05469v2)** | 2025-08-21 | <details><summary>Add A...</summary><p>Add AUC results, pre-reg conformance, theory section clarification. 12 pages</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v2)** | 2025-08-21 |  |
| **[Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](http://arxiv.org/abs/2508.15449v1)** | 2025-08-21 | <details><summary>10 pa...</summary><p>10 pages, 9 figures, Under review as a full paper at AAAI 2026. A preliminary version is under review at the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](http://arxiv.org/abs/2508.15310v1)** | 2025-08-21 | EMNLP 2025 |
| **[MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs](http://arxiv.org/abs/2508.15036v1)** | 2025-08-20 | <details><summary>This ...</summary><p>This paper will appear in CCS 2025</p></details> |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection](http://arxiv.org/abs/2508.14128v1)** | 2025-08-19 | 11 pages, 1 figure |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v2)** | 2025-08-18 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |
| **[RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](http://arxiv.org/abs/2508.13152v1)** | 2025-08-18 | <details><summary>Accep...</summary><p>Accepted to TACL 2025. This version is a pre-MIT Press publication version</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](http://arxiv.org/abs/2508.15648v1)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted by EMNLP 2025, 15 pages, 4 figures, 6 tables</p></details> |
| **[DualMark: Identifying Model and Training Data Origins in Generated Audio](http://arxiv.org/abs/2508.15521v1)** | 2025-08-21 | 13 pages, 5 figures |
| **[On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking](http://arxiv.org/abs/2508.15481v1)** | 2025-08-21 |  |
| **[A Study of Privacy-preserving Language Modeling Approaches](http://arxiv.org/abs/2508.15421v1)** | 2025-08-21 |  |
| **[Tensor Train Decomposition for Adversarial Attacks on Computer Vision Models](http://arxiv.org/abs/2312.12556v2)** | 2025-08-21 |  |
| **[Adversarial Attacks against Neural Ranking Models via In-Context Learning](http://arxiv.org/abs/2508.15283v1)** | 2025-08-21 |  |
| **[CopyrightShield: Enhancing Diffusion Model Security against Copyright Infringement Attacks](http://arxiv.org/abs/2412.01528v2)** | 2025-08-21 |  |
| **[SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks](http://arxiv.org/abs/2508.15182v1)** | 2025-08-21 |  |
| **[A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives](http://arxiv.org/abs/2508.15031v1)** | 2025-08-20 |  |
| **[TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](http://arxiv.org/abs/2508.15020v1)** | 2025-08-20 | <details><summary>Accep...</summary><p>Accepted at ICCVW-CV4BIOM 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](http://arxiv.org/abs/2508.15648v1)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted by EMNLP 2025, 15 pages, 4 figures, 6 tables</p></details> |
| **[DualMark: Identifying Model and Training Data Origins in Generated Audio](http://arxiv.org/abs/2508.15521v1)** | 2025-08-21 | 13 pages, 5 figures |
| **[On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking](http://arxiv.org/abs/2508.15481v1)** | 2025-08-21 |  |
| **[A Study of Privacy-preserving Language Modeling Approaches](http://arxiv.org/abs/2508.15421v1)** | 2025-08-21 |  |
| **[Tensor Train Decomposition for Adversarial Attacks on Computer Vision Models](http://arxiv.org/abs/2312.12556v2)** | 2025-08-21 |  |
| **[Adversarial Attacks against Neural Ranking Models via In-Context Learning](http://arxiv.org/abs/2508.15283v1)** | 2025-08-21 |  |
| **[CopyrightShield: Enhancing Diffusion Model Security against Copyright Infringement Attacks](http://arxiv.org/abs/2412.01528v2)** | 2025-08-21 |  |
| **[SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks](http://arxiv.org/abs/2508.15182v1)** | 2025-08-21 |  |
| **[A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives](http://arxiv.org/abs/2508.15031v1)** | 2025-08-20 |  |
| **[TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](http://arxiv.org/abs/2508.15020v1)** | 2025-08-20 | <details><summary>Accep...</summary><p>Accepted at ICCVW-CV4BIOM 2025</p></details> |

