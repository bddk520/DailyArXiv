---
title: Latest 15 Papers - April 22, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Detecting Malicious Source Code in PyPI Packages with LLMs: Does RAG Come in Handy?](http://arxiv.org/abs/2504.13769v1)** | 2025-04-18 | <details><summary>The p...</summary><p>The paper has been peer-reviewed and accepted for publication to the 29th International Conference on Evaluation and Assessment in Software Engineering (EASE 2025)</p></details> |
| **[AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](http://arxiv.org/abs/2410.09024v3)** | 2025-04-18 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025</p></details> |
| **[DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification](http://arxiv.org/abs/2504.13562v1)** | 2025-04-18 |  |
| **[Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](http://arxiv.org/abs/2404.02151v4)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025. Updates in the v3: GPT-4o and Claude 3.5 Sonnet results, improved writing. Updates in the v2: more models (Llama3, Phi-3, Nemotron-4-340B), jailbreak artifacts for all attacks are available, evaluation with different judges (Llama-3-70B and Llama Guard 2), more experiments (convergence plots, ablation on the suffix length for random search), examples of jailbroken generation</p></details> |
| **[Does Refusal Training in LLMs Generalize to the Past Tense?](http://arxiv.org/abs/2407.11969v4)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025. Updates in v2 and v3: added GPT-4o, Claude 3.5 Sonnet, o1-mini, and o1-preview results. Code and jailbreak artifacts: https://github.com/tml-epfl/llm-past-tense</p></details> |
| **[GraphAttack: Exploiting Representational Blindspots in LLM Safety Mechanisms](http://arxiv.org/abs/2504.13052v1)** | 2025-04-17 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v2)** | 2025-04-17 | <details><summary>Proje...</summary><p>Project Page: https://ai.zjuicsr.cn/firewall</p></details> |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Detecting Malicious Source Code in PyPI Packages with LLMs: Does RAG Come in Handy?](http://arxiv.org/abs/2504.13769v1)** | 2025-04-18 | <details><summary>The p...</summary><p>The paper has been peer-reviewed and accepted for publication to the 29th International Conference on Evaluation and Assessment in Software Engineering (EASE 2025)</p></details> |
| **[AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](http://arxiv.org/abs/2410.09024v3)** | 2025-04-18 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025</p></details> |
| **[DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification](http://arxiv.org/abs/2504.13562v1)** | 2025-04-18 |  |
| **[Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](http://arxiv.org/abs/2404.02151v4)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025. Updates in the v3: GPT-4o and Claude 3.5 Sonnet results, improved writing. Updates in the v2: more models (Llama3, Phi-3, Nemotron-4-340B), jailbreak artifacts for all attacks are available, evaluation with different judges (Llama-3-70B and Llama Guard 2), more experiments (convergence plots, ablation on the suffix length for random search), examples of jailbroken generation</p></details> |
| **[Does Refusal Training in LLMs Generalize to the Past Tense?](http://arxiv.org/abs/2407.11969v4)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025. Updates in v2 and v3: added GPT-4o, Claude 3.5 Sonnet, o1-mini, and o1-preview results. Code and jailbreak artifacts: https://github.com/tml-epfl/llm-past-tense</p></details> |
| **[GraphAttack: Exploiting Representational Blindspots in LLM Safety Mechanisms](http://arxiv.org/abs/2504.13052v1)** | 2025-04-17 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v2)** | 2025-04-17 | <details><summary>Proje...</summary><p>Project Page: https://ai.zjuicsr.cn/firewall</p></details> |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models](http://arxiv.org/abs/2504.13775v1)** | 2025-04-18 | 16 pages, 6 figures |
| **[Few-shot Model Extraction Attacks against Sequential Recommender Systems](http://arxiv.org/abs/2411.11677v2)** | 2025-04-18 | <details><summary>It re...</summary><p>It requires substantial modifications.The symbols in the mathematical formulas are not explained in detail</p></details> |
| **[Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection](http://arxiv.org/abs/2406.11260v3)** | 2025-04-18 | <details><summary>WWW'2...</summary><p>WWW'25 research track accepted</p></details> |
| **[Large Language Models for Validating Network Protocol Parsers](http://arxiv.org/abs/2504.13515v1)** | 2025-04-18 |  |
| **[Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models](http://arxiv.org/abs/2504.05050v2)** | 2025-04-18 |  |
| **[How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference](http://arxiv.org/abs/2501.00824v4)** | 2025-04-18 | Under review |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v2)** | 2025-04-17 |  |
| **[From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models](http://arxiv.org/abs/2407.16928v3)** | 2025-04-17 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v2)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models](http://arxiv.org/abs/2504.13775v1)** | 2025-04-18 | 16 pages, 6 figures |
| **[Few-shot Model Extraction Attacks against Sequential Recommender Systems](http://arxiv.org/abs/2411.11677v2)** | 2025-04-18 | <details><summary>It re...</summary><p>It requires substantial modifications.The symbols in the mathematical formulas are not explained in detail</p></details> |
| **[Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection](http://arxiv.org/abs/2406.11260v3)** | 2025-04-18 | <details><summary>WWW'2...</summary><p>WWW'25 research track accepted</p></details> |
| **[Large Language Models for Validating Network Protocol Parsers](http://arxiv.org/abs/2504.13515v1)** | 2025-04-18 |  |
| **[Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models](http://arxiv.org/abs/2504.05050v2)** | 2025-04-18 |  |
| **[How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference](http://arxiv.org/abs/2501.00824v4)** | 2025-04-18 | Under review |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v2)** | 2025-04-17 |  |
| **[From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models](http://arxiv.org/abs/2407.16928v3)** | 2025-04-17 |  |
| **[PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization](http://arxiv.org/abs/2504.07717v2)** | 2025-04-17 | <details><summary>Accep...</summary><p>Accepted at SIGIR 2025</p></details> |

