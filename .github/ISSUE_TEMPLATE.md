---
title: Latest 15 Papers - February 03, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching](https://arxiv.org/abs/2601.23088v1)** | 2026-01-30 |  |
| **[ChatInject: Abusing Chat Templates for Prompt Injection in LLM Agents](https://arxiv.org/abs/2509.22830v2)** | 2026-01-30 | ICLR 2026 |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v2)** | 2026-01-30 |  |
| **[OSNIP: Breaking the Privacy-Utility-Efficiency Trilemma in LLM Inference via Obfuscated Semantic Null Space](https://arxiv.org/abs/2601.22752v1)** | 2026-01-30 |  |
| **[AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises](https://arxiv.org/abs/2601.22720v1)** | 2026-01-30 |  |
| **[AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs](https://arxiv.org/abs/2601.22710v1)** | 2026-01-30 |  |
| **[FraudShield: Knowledge Graph Empowered Defense for LLMs against Fraud Attacks](https://arxiv.org/abs/2601.22485v1)** | 2026-01-30 | WWW 2026 |
| **[A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking: Expanding NIST Taxonomy](https://arxiv.org/abs/2601.22240v1)** | 2026-01-29 | <details><summary>27 pa...</summary><p>27 pages, 14 figures, 11 tables, submitted to Elsevier Computer Science Review</p></details> |
| **[FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682v1)** | 2026-01-29 | 20 Pages |
| **[ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533v1)** | 2026-01-29 | 58 pages |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching](https://arxiv.org/abs/2601.23088v1)** | 2026-01-30 |  |
| **[ChatInject: Abusing Chat Templates for Prompt Injection in LLM Agents](https://arxiv.org/abs/2509.22830v2)** | 2026-01-30 | ICLR 2026 |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v2)** | 2026-01-30 |  |
| **[OSNIP: Breaking the Privacy-Utility-Efficiency Trilemma in LLM Inference via Obfuscated Semantic Null Space](https://arxiv.org/abs/2601.22752v1)** | 2026-01-30 |  |
| **[AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises](https://arxiv.org/abs/2601.22720v1)** | 2026-01-30 |  |
| **[AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs](https://arxiv.org/abs/2601.22710v1)** | 2026-01-30 |  |
| **[FraudShield: Knowledge Graph Empowered Defense for LLMs against Fraud Attacks](https://arxiv.org/abs/2601.22485v1)** | 2026-01-30 | WWW 2026 |
| **[A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking: Expanding NIST Taxonomy](https://arxiv.org/abs/2601.22240v1)** | 2026-01-29 | <details><summary>27 pa...</summary><p>27 pages, 14 figures, 11 tables, submitted to Elsevier Computer Science Review</p></details> |
| **[FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682v1)** | 2026-01-29 | 20 Pages |
| **[ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533v1)** | 2026-01-29 | 58 pages |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models](https://arxiv.org/abs/2601.23255v1)** | 2026-01-30 | <details><summary>to be...</summary><p>to be published at EACL 2026 main conference</p></details> |
| **[Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing](https://arxiv.org/abs/2601.10543v2)** | 2026-01-30 |  |
| **[Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models](https://arxiv.org/abs/2510.04347v2)** | 2026-01-30 | <details><summary>17 pa...</summary><p>17 pages total (9 pages main text + 6 pages appendix + references), 16 figures. Preprint version; the final camera-ready version may differ. Accepted to ICLR 2026</p></details> |
| **[Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models](https://arxiv.org/abs/2601.22818v1)** | 2026-01-30 |  |
| **[Okara: Detection and Attribution of TLS Man-in-the-Middle Vulnerabilities in Android Apps with Foundation Models](https://arxiv.org/abs/2601.22770v1)** | 2026-01-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2026</p></details> |
| **[Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models](https://arxiv.org/abs/2601.22737v1)** | 2026-01-30 |  |
| **[AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises](https://arxiv.org/abs/2601.22720v1)** | 2026-01-30 |  |
| **[AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs](https://arxiv.org/abs/2601.22710v1)** | 2026-01-30 |  |
| **[Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling](https://arxiv.org/abs/2601.22636v1)** | 2026-01-30 |  |
| **[Multi-Level Safety Continual Projection for Fine-Tuned Large Language Models without Retraining](https://arxiv.org/abs/2508.09190v4)** | 2026-01-30 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models](https://arxiv.org/abs/2601.23255v1)** | 2026-01-30 | <details><summary>to be...</summary><p>to be published at EACL 2026 main conference</p></details> |
| **[Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures](https://arxiv.org/abs/2601.23081v1)** | 2026-01-30 |  |
| **[Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing](https://arxiv.org/abs/2601.10543v2)** | 2026-01-30 |  |
| **[Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models](https://arxiv.org/abs/2510.04347v2)** | 2026-01-30 | <details><summary>17 pa...</summary><p>17 pages total (9 pages main text + 6 pages appendix + references), 16 figures. Preprint version; the final camera-ready version may differ. Accepted to ICLR 2026</p></details> |
| **[Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models](https://arxiv.org/abs/2601.22818v1)** | 2026-01-30 |  |
| **[Okara: Detection and Attribution of TLS Man-in-the-Middle Vulnerabilities in Android Apps with Foundation Models](https://arxiv.org/abs/2601.22770v1)** | 2026-01-30 | <details><summary>Accep...</summary><p>Accepted to ACISP 2026</p></details> |
| **[Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models](https://arxiv.org/abs/2601.22737v1)** | 2026-01-30 |  |
| **[AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises](https://arxiv.org/abs/2601.22720v1)** | 2026-01-30 |  |
| **[AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs](https://arxiv.org/abs/2601.22710v1)** | 2026-01-30 |  |
| **[Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling](https://arxiv.org/abs/2601.22636v1)** | 2026-01-30 |  |

