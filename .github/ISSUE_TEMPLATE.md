---
title: Latest 15 Papers - June 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v2)** | 2025-06-16 |  |
| **[From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs](http://arxiv.org/abs/2506.13434v1)** | 2025-06-16 | 10 pages |
| **[Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs](http://arxiv.org/abs/2506.13285v1)** | 2025-06-16 |  |
| **[Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks](http://arxiv.org/abs/2506.13276v1)** | 2025-06-16 |  |
| **[Detecting Hard-Coded Credentials in Software Repositories via LLMs](http://arxiv.org/abs/2506.13090v1)** | 2025-06-16 | <details><summary>Accep...</summary><p>Accepted to the ACM Digital Threats: Research and Practice (DTRAP)</p></details> |
| **[Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions](http://arxiv.org/abs/2502.04322v2)** | 2025-06-16 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v2)** | 2025-06-15 |  |
| **[SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression](http://arxiv.org/abs/2506.12707v1)** | 2025-06-15 |  |
| **[Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity](http://arxiv.org/abs/2506.12685v1)** | 2025-06-15 | <details><summary>10 pa...</summary><p>10 pages, 2 figures, 3 tables</p></details> |
| **[Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](http://arxiv.org/abs/2506.10949v2)** | 2025-06-14 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v2)** | 2025-06-16 |  |
| **[From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs](http://arxiv.org/abs/2506.13434v1)** | 2025-06-16 | 10 pages |
| **[Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs](http://arxiv.org/abs/2506.13285v1)** | 2025-06-16 |  |
| **[Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks](http://arxiv.org/abs/2506.13276v1)** | 2025-06-16 |  |
| **[Detecting Hard-Coded Credentials in Software Repositories via LLMs](http://arxiv.org/abs/2506.13090v1)** | 2025-06-16 | <details><summary>Accep...</summary><p>Accepted to the ACM Digital Threats: Research and Practice (DTRAP)</p></details> |
| **[Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions](http://arxiv.org/abs/2502.04322v2)** | 2025-06-16 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](http://arxiv.org/abs/2506.10364v2)** | 2025-06-15 |  |
| **[SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression](http://arxiv.org/abs/2506.12707v1)** | 2025-06-15 |  |
| **[Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity](http://arxiv.org/abs/2506.12685v1)** | 2025-06-15 | <details><summary>10 pa...</summary><p>10 pages, 2 figures, 3 tables</p></details> |
| **[Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](http://arxiv.org/abs/2506.10949v2)** | 2025-06-14 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability](http://arxiv.org/abs/2506.13746v1)** | 2025-06-16 |  |
| **[Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models](http://arxiv.org/abs/2506.13726v1)** | 2025-06-16 | <details><summary>Accep...</summary><p>Accepted to LLMSEC 2025</p></details> |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v2)** | 2025-06-16 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |
| **[CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models](http://arxiv.org/abs/2502.07225v2)** | 2025-06-16 |  |
| **[Jailbreak Strength and Model Similarity Predict Transferability](http://arxiv.org/abs/2506.12913v1)** | 2025-06-15 |  |
| **[TrojanTO: Action-Level Backdoor Attacks against Trajectory Optimization Models](http://arxiv.org/abs/2506.12815v1)** | 2025-06-15 | 23 pages, 6 figures |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v3)** | 2025-06-15 | <details><summary>Submi...</summary><p>Submitted for review in January 22, 2025, revised under shepherding</p></details> |
| **[NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models](http://arxiv.org/abs/2506.12706v1)** | 2025-06-15 |  |
| **[FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training](http://arxiv.org/abs/2410.23142v3)** | 2025-06-14 |  |
| **[MEraser: An Effective Fingerprint Erasure Approach for Large Language Models](http://arxiv.org/abs/2506.12551v1)** | 2025-06-14 | <details><summary>Accep...</summary><p>Accepted by ACL 2025, Main Conference, Long Paper</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability](http://arxiv.org/abs/2506.13746v1)** | 2025-06-16 |  |
| **[Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models](http://arxiv.org/abs/2506.13726v1)** | 2025-06-16 | <details><summary>Accep...</summary><p>Accepted to LLMSEC 2025</p></details> |
| **[When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](http://arxiv.org/abs/2506.09975v2)** | 2025-06-16 | <details><summary>to ap...</summary><p>to appear in ACL Findings</p></details> |
| **[Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models](http://arxiv.org/abs/2506.13206v1)** | 2025-06-16 |  |
| **[CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models](http://arxiv.org/abs/2502.07225v2)** | 2025-06-16 |  |
| **[Jailbreak Strength and Model Similarity Predict Transferability](http://arxiv.org/abs/2506.12913v1)** | 2025-06-15 |  |
| **[TrojanTO: Action-Level Backdoor Attacks against Trajectory Optimization Models](http://arxiv.org/abs/2506.12815v1)** | 2025-06-15 | 23 pages, 6 figures |
| **[I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](http://arxiv.org/abs/2505.06738v3)** | 2025-06-15 | <details><summary>Submi...</summary><p>Submitted for review in January 22, 2025, revised under shepherding</p></details> |
| **[NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models](http://arxiv.org/abs/2506.12706v1)** | 2025-06-15 |  |
| **[FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training](http://arxiv.org/abs/2410.23142v3)** | 2025-06-14 |  |

