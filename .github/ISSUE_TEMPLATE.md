---
title: Latest 15 Papers - October 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](http://arxiv.org/abs/2509.14285v2)** | 2025-10-01 | <details><summary>IEEE ...</summary><p>IEEE Conference standard paper</p></details> |
| **[LLM Watermark Evasion via Bias Inversion](http://arxiv.org/abs/2509.23019v2)** | 2025-10-01 |  |
| **[Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization](http://arxiv.org/abs/2509.20230v3)** | 2025-09-30 |  |
| **[QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety](http://arxiv.org/abs/2506.12299v3)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accept to ACLW 2025 (WOAH); fix typo</p></details> |
| **[Dagger Behind Smile: Fool LLMs with a Happy Ending Story](http://arxiv.org/abs/2501.13115v3)** | 2025-09-30 | EMNLP 2025 Findings |
| **[STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents](http://arxiv.org/abs/2509.25624v1)** | 2025-09-30 |  |
| **[Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety](http://arxiv.org/abs/2503.05021v2)** | 2025-09-29 | ACL 2025 Findings |
| **[Watermark under Fire: A Robustness Evaluation of LLM Watermarking](http://arxiv.org/abs/2411.13425v4)** | 2025-09-29 | <details><summary>25 pa...</summary><p>25 pages. Accepted by The 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)</p></details> |
| **[SemanticShield: LLM-Powered Audits Expose Shilling Attacks in Recommender Systems](http://arxiv.org/abs/2509.24961v1)** | 2025-09-29 |  |
| **[HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment](http://arxiv.org/abs/2509.24384v1)** | 2025-09-29 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](http://arxiv.org/abs/2509.14285v2)** | 2025-10-01 | <details><summary>IEEE ...</summary><p>IEEE Conference standard paper</p></details> |
| **[LLM Watermark Evasion via Bias Inversion](http://arxiv.org/abs/2509.23019v2)** | 2025-10-01 |  |
| **[Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization](http://arxiv.org/abs/2509.20230v3)** | 2025-09-30 |  |
| **[QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety](http://arxiv.org/abs/2506.12299v3)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accept to ACLW 2025 (WOAH); fix typo</p></details> |
| **[Dagger Behind Smile: Fool LLMs with a Happy Ending Story](http://arxiv.org/abs/2501.13115v3)** | 2025-09-30 | EMNLP 2025 Findings |
| **[STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents](http://arxiv.org/abs/2509.25624v1)** | 2025-09-30 |  |
| **[Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety](http://arxiv.org/abs/2503.05021v2)** | 2025-09-29 | ACL 2025 Findings |
| **[Watermark under Fire: A Robustness Evaluation of LLM Watermarking](http://arxiv.org/abs/2411.13425v4)** | 2025-09-29 | <details><summary>25 pa...</summary><p>25 pages. Accepted by The 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)</p></details> |
| **[SemanticShield: LLM-Powered Audits Expose Shilling Attacks in Recommender Systems](http://arxiv.org/abs/2509.24961v1)** | 2025-09-29 |  |
| **[HarmMetric Eval: Benchmarking Metrics and Judges for LLM Harmfulness Assessment](http://arxiv.org/abs/2509.24384v1)** | 2025-09-29 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework for Double-Blind Federated Adaptation of Foundation Models](http://arxiv.org/abs/2502.01289v2)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to ICCV 2025</p></details> |
| **[Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](http://arxiv.org/abs/2506.15674v2)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 (Main)</p></details> |
| **[MLAAD: The Multi-Language Audio Anti-Spoofing Dataset](http://arxiv.org/abs/2401.09512v8)** | 2025-10-01 | IJCNN 2024 |
| **[EVALOOOP: A Self-Consistency-Centered Framework for Assessing Large Language Model Robustness in Programming](http://arxiv.org/abs/2505.12185v4)** | 2025-10-01 | 20 pages, 4 figures |
| **[LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](http://arxiv.org/abs/2506.11402v2)** | 2025-10-01 | <details><summary>46 pa...</summary><p>46 pages, 17 figures, 26 tables. Submitted for publication. for associated blog post, see https://pradyut3501.github.io/lora-spur-corr/</p></details> |
| **[Phantom: General Backdoor Attacks on Retrieval Augmented Language Generation](http://arxiv.org/abs/2405.20485v3)** | 2025-10-01 |  |
| **[Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models](http://arxiv.org/abs/2509.26584v1)** | 2025-09-30 |  |
| **[STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models](http://arxiv.org/abs/2509.26473v1)** | 2025-09-30 |  |
| **[SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models](http://arxiv.org/abs/2509.26345v1)** | 2025-09-30 | 27 pages, 5 figure |
| **[Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions](http://arxiv.org/abs/2501.01872v6)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted at EMNLP 2025 (Main)</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework for Double-Blind Federated Adaptation of Foundation Models](http://arxiv.org/abs/2502.01289v2)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to ICCV 2025</p></details> |
| **[Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](http://arxiv.org/abs/2506.15674v2)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 (Main)</p></details> |
| **[MLAAD: The Multi-Language Audio Anti-Spoofing Dataset](http://arxiv.org/abs/2401.09512v8)** | 2025-10-01 | IJCNN 2024 |
| **[EVALOOOP: A Self-Consistency-Centered Framework for Assessing Large Language Model Robustness in Programming](http://arxiv.org/abs/2505.12185v4)** | 2025-10-01 | 20 pages, 4 figures |
| **[LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](http://arxiv.org/abs/2506.11402v2)** | 2025-10-01 | <details><summary>46 pa...</summary><p>46 pages, 17 figures, 26 tables. Submitted for publication. for associated blog post, see https://pradyut3501.github.io/lora-spur-corr/</p></details> |
| **[Phantom: General Backdoor Attacks on Retrieval Augmented Language Generation](http://arxiv.org/abs/2405.20485v3)** | 2025-10-01 |  |
| **[Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models](http://arxiv.org/abs/2509.26584v1)** | 2025-09-30 |  |
| **[STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models](http://arxiv.org/abs/2509.26473v1)** | 2025-09-30 |  |
| **[SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models](http://arxiv.org/abs/2509.26345v1)** | 2025-09-30 | 27 pages, 5 figure |
| **[Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions](http://arxiv.org/abs/2501.01872v6)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted at EMNLP 2025 (Main)</p></details> |

