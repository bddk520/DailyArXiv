---
title: Latest 15 Papers - December 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044v1)** | 2025-12-03 |  |
| **[Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents](https://arxiv.org/abs/2504.03111v3)** | 2025-12-03 | <details><summary>Netwo...</summary><p>Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs](https://arxiv.org/abs/2512.03720v1)** | 2025-12-03 |  |
| **[SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting](https://arxiv.org/abs/2512.03620v1)** | 2025-12-03 |  |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](https://arxiv.org/abs/2507.01513v2)** | 2025-12-03 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers](https://arxiv.org/abs/2512.02318v2)** | 2025-12-03 |  |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](https://arxiv.org/abs/2508.09442v2)** | 2025-12-03 | <details><summary>This ...</summary><p>This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v2)** | 2025-12-02 |  |
| **[Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation](https://arxiv.org/abs/2405.13068v3)** | 2025-12-02 |  |
| **[TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?](https://arxiv.org/abs/2512.02261v1)** | 2025-12-01 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044v1)** | 2025-12-03 |  |
| **[Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents](https://arxiv.org/abs/2504.03111v3)** | 2025-12-03 | <details><summary>Netwo...</summary><p>Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs](https://arxiv.org/abs/2512.03720v1)** | 2025-12-03 |  |
| **[SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting](https://arxiv.org/abs/2512.03620v1)** | 2025-12-03 |  |
| **[SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism](https://arxiv.org/abs/2507.01513v2)** | 2025-12-03 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers](https://arxiv.org/abs/2512.02318v2)** | 2025-12-03 |  |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](https://arxiv.org/abs/2508.09442v2)** | 2025-12-03 | <details><summary>This ...</summary><p>This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v2)** | 2025-12-02 |  |
| **[Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation](https://arxiv.org/abs/2405.13068v3)** | 2025-12-02 |  |
| **[TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?](https://arxiv.org/abs/2512.02261v1)** | 2025-12-01 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Defense That Attacks: How Robust Models Become Better Attackers](https://arxiv.org/abs/2512.02830v2)** | 2025-12-03 |  |
| **[Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882v1)** | 2025-12-03 |  |
| **[A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception](https://arxiv.org/abs/2512.03641v1)** | 2025-12-03 | 24 Pages, 4 Tables |
| **[Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564v1)** | 2025-12-03 |  |
| **[Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models](https://arxiv.org/abs/2512.03356v1)** | 2025-12-03 |  |
| **[Empirical assessment of the perception of graphical threat model acceptability](https://arxiv.org/abs/2512.03351v1)** | 2025-12-03 | <details><summary>Accep...</summary><p>Accepted into the Asia-Pacific Software Engineering Conference (APSEC) 2025. Will appear in APSEC 2025 proceedings</p></details> |
| **[SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models](https://arxiv.org/abs/2506.00821v2)** | 2025-12-02 |  |
| **[The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models](https://arxiv.org/abs/2507.18725v2)** | 2025-12-02 | <details><summary>9 pag...</summary><p>9 pages for main part</p></details> |
| **[Invasive Context Engineering to Control Large Language Models](https://arxiv.org/abs/2512.03001v1)** | 2025-12-02 | 4 pages |
| **[OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295v2)** | 2025-12-02 | WACV2026 Accepted |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Defense That Attacks: How Robust Models Become Better Attackers](https://arxiv.org/abs/2512.02830v2)** | 2025-12-03 |  |
| **[Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882v1)** | 2025-12-03 |  |
| **[A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception](https://arxiv.org/abs/2512.03641v1)** | 2025-12-03 | 24 Pages, 4 Tables |
| **[Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564v1)** | 2025-12-03 |  |
| **[Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models](https://arxiv.org/abs/2512.03356v1)** | 2025-12-03 |  |
| **[Empirical assessment of the perception of graphical threat model acceptability](https://arxiv.org/abs/2512.03351v1)** | 2025-12-03 | <details><summary>Accep...</summary><p>Accepted into the Asia-Pacific Software Engineering Conference (APSEC) 2025. Will appear in APSEC 2025 proceedings</p></details> |
| **[SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models](https://arxiv.org/abs/2506.00821v2)** | 2025-12-02 |  |
| **[The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models](https://arxiv.org/abs/2507.18725v2)** | 2025-12-02 | <details><summary>9 pag...</summary><p>9 pages for main part</p></details> |
| **[Invasive Context Engineering to Control Large Language Models](https://arxiv.org/abs/2512.03001v1)** | 2025-12-02 | 4 pages |
| **[OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295v2)** | 2025-12-02 | WACV2026 Accepted |

