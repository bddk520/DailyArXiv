---
title: Latest 15 Papers - August 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v1)** | 2025-08-14 | Preprint |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](http://arxiv.org/abs/2508.10390v1)** | 2025-08-14 |  |
| **[MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs](http://arxiv.org/abs/2506.22557v2)** | 2025-08-13 |  |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v2)** | 2025-08-13 |  |
| **[Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM](http://arxiv.org/abs/2508.05775v2)** | 2025-08-13 |  |
| **[NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](http://arxiv.org/abs/2508.09473v1)** | 2025-08-13 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v4)** | 2025-08-13 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](http://arxiv.org/abs/2508.09442v1)** | 2025-08-13 |  |
| **[One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs](http://arxiv.org/abs/2502.18862v2)** | 2025-08-12 | <details><summary>Publi...</summary><p>Published at COLM 2025. 30 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro and https://github.com/jacobdunefsky/one-shot-steering-misalignment</p></details> |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v1)** | 2025-08-12 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v1)** | 2025-08-14 | Preprint |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](http://arxiv.org/abs/2508.10390v1)** | 2025-08-14 |  |
| **[MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs](http://arxiv.org/abs/2506.22557v2)** | 2025-08-13 |  |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v2)** | 2025-08-13 |  |
| **[Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM](http://arxiv.org/abs/2508.05775v2)** | 2025-08-13 |  |
| **[NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](http://arxiv.org/abs/2508.09473v1)** | 2025-08-13 |  |
| **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](http://arxiv.org/abs/2409.20002v4)** | 2025-08-13 | <details><summary>This ...</summary><p>This work was submitted for review on Sept. 5, 2024, and the initial version was uploaded to Arxiv on Sept. 30, 2024. The latest version reflects the up-to-date experimental results</p></details> |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](http://arxiv.org/abs/2508.09442v1)** | 2025-08-13 |  |
| **[One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs](http://arxiv.org/abs/2502.18862v2)** | 2025-08-12 | <details><summary>Publi...</summary><p>Published at COLM 2025. 30 pages, 7 figures. Code is available at https://github.com/jacobdunefsky/one-shot-steering-repro and https://github.com/jacobdunefsky/one-shot-steering-misalignment</p></details> |
| **[Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs](http://arxiv.org/abs/2508.09288v1)** | 2025-08-12 | <details><summary>2 fig...</summary><p>2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Leveraging large language models for SQL behavior-based database intrusion detection](http://arxiv.org/abs/2508.05690v2)** | 2025-08-14 |  |
| **[An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach](http://arxiv.org/abs/2402.13871v2)** | 2025-08-14 |  |
| **[BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](http://arxiv.org/abs/2508.03221v2)** | 2025-08-14 |  |
| **[A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning](http://arxiv.org/abs/2508.10315v1)** | 2025-08-14 |  |
| **[Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models](http://arxiv.org/abs/2508.10243v1)** | 2025-08-14 |  |
| **[Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model](http://arxiv.org/abs/2508.10110v1)** | 2025-08-13 |  |
| **[Security Concerns for Large Language Models: A Survey](http://arxiv.org/abs/2505.18889v3)** | 2025-08-13 |  |
| **[Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research](http://arxiv.org/abs/2508.09815v1)** | 2025-08-13 |  |
| **[Model Poisoning Attacks to Federated Learning via Multi-Round Consistency](http://arxiv.org/abs/2404.15611v3)** | 2025-08-13 | CVPR 2025 |
| **[Towards Black-Box Membership Inference Attack for Diffusion Models](http://arxiv.org/abs/2405.20771v5)** | 2025-08-13 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Leveraging large language models for SQL behavior-based database intrusion detection](http://arxiv.org/abs/2508.05690v2)** | 2025-08-14 |  |
| **[An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach](http://arxiv.org/abs/2402.13871v2)** | 2025-08-14 |  |
| **[BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models](http://arxiv.org/abs/2508.03221v2)** | 2025-08-14 |  |
| **[A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning](http://arxiv.org/abs/2508.10315v1)** | 2025-08-14 |  |
| **[Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models](http://arxiv.org/abs/2508.10243v1)** | 2025-08-14 |  |
| **[Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model](http://arxiv.org/abs/2508.10110v1)** | 2025-08-13 |  |
| **[Security Concerns for Large Language Models: A Survey](http://arxiv.org/abs/2505.18889v3)** | 2025-08-13 |  |
| **[Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research](http://arxiv.org/abs/2508.09815v1)** | 2025-08-13 |  |
| **[Model Poisoning Attacks to Federated Learning via Multi-Round Consistency](http://arxiv.org/abs/2404.15611v3)** | 2025-08-13 | CVPR 2025 |
| **[Towards Black-Box Membership Inference Attack for Diffusion Models](http://arxiv.org/abs/2405.20771v5)** | 2025-08-13 |  |

