---
title: Latest 15 Papers - February 23, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |
| **[Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346v2)** | 2026-02-19 |  |
| **[AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901v1)** | 2026-02-18 |  |
| **[NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835v1)** | 2026-02-18 |  |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238v2)** | 2026-02-18 |  |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v2)** | 2026-02-18 |  |
| **[The Trojan Example: Jailbreaking LLMs through Template Filling and Unsafety Reasoning](https://arxiv.org/abs/2510.21190v2)** | 2026-02-18 | under review |
| **[Mind the Gap: Evaluating LLMs for High-Level Malicious Package Detection vs. Fine-Grained Indicator Identification](https://arxiv.org/abs/2602.16304v1)** | 2026-02-18 |  |
| **[The Vulnerability of LLM Rankers to Prompt Injection Attacks](https://arxiv.org/abs/2602.16752v1)** | 2026-02-18 | 18 pages, 7 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |
| **[Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346v2)** | 2026-02-19 |  |
| **[AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901v1)** | 2026-02-18 |  |
| **[NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835v1)** | 2026-02-18 |  |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238v2)** | 2026-02-18 |  |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v2)** | 2026-02-18 |  |
| **[The Trojan Example: Jailbreaking LLMs through Template Filling and Unsafety Reasoning](https://arxiv.org/abs/2510.21190v2)** | 2026-02-18 | under review |
| **[Mind the Gap: Evaluating LLMs for High-Level Malicious Package Detection vs. Fine-Grained Indicator Identification](https://arxiv.org/abs/2602.16304v1)** | 2026-02-18 |  |
| **[The Vulnerability of LLM Rankers to Prompt Injection Attacks](https://arxiv.org/abs/2602.16752v1)** | 2026-02-18 | 18 pages, 7 figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Defining and Evaluating Physical Safety for Large Language Models](https://arxiv.org/abs/2411.02317v2)** | 2026-02-19 |  |
| **[Grothendieck Topologies and Sheaf-Theoretic Foundations of Cryptographic Security: Attacker Models and $Σ$-Protocols as the First Step](https://arxiv.org/abs/2602.17301v1)** | 2026-02-19 | <details><summary>9 pag...</summary><p>9 pages (12pt). We present a categorical and Grothendieck-topological model of Σ-protocols, providing a formal structural interpretation of interactive proof systems, knowledge soundness, and attacker models</p></details> |
| **[Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977v1)** | 2026-02-19 | Pre-print |
| **[IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832v1)** | 2026-02-18 | <details><summary>Accep...</summary><p>Accepted in EACL Industry Track Oral, 2026</p></details> |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents](https://arxiv.org/abs/2602.16520v1)** | 2026-02-18 | <details><summary>5 pag...</summary><p>5 pages and 1 figure. Appendix: an additional 5 pages</p></details> |
| **[Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks](https://arxiv.org/abs/2602.16760v1)** | 2026-02-18 | <details><summary>21 pa...</summary><p>21 pages, 21 tables, no figures</p></details> |
| **[Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406v2)** | 2026-02-18 | Accepted at FPS 2025 |
| **[The Weight of a Bit: EMFI Sensitivity Analysis of Embedded Deep Learning Models](https://arxiv.org/abs/2602.16309v1)** | 2026-02-18 |  |
| **[Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694v4)** | 2026-02-18 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Defining and Evaluating Physical Safety for Large Language Models](https://arxiv.org/abs/2411.02317v2)** | 2026-02-19 |  |
| **[Grothendieck Topologies and Sheaf-Theoretic Foundations of Cryptographic Security: Attacker Models and $Σ$-Protocols as the First Step](https://arxiv.org/abs/2602.17301v1)** | 2026-02-19 | <details><summary>9 pag...</summary><p>9 pages (12pt). We present a categorical and Grothendieck-topological model of Σ-protocols, providing a formal structural interpretation of interactive proof systems, knowledge soundness, and attacker models</p></details> |
| **[Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977v1)** | 2026-02-19 | Pre-print |
| **[IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832v1)** | 2026-02-18 | <details><summary>Accep...</summary><p>Accepted in EACL Industry Track Oral, 2026</p></details> |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents](https://arxiv.org/abs/2602.16520v1)** | 2026-02-18 | <details><summary>5 pag...</summary><p>5 pages and 1 figure. Appendix: an additional 5 pages</p></details> |
| **[Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks](https://arxiv.org/abs/2602.16760v1)** | 2026-02-18 | <details><summary>21 pa...</summary><p>21 pages, 21 tables, no figures</p></details> |
| **[Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406v2)** | 2026-02-18 | Accepted at FPS 2025 |
| **[The Weight of a Bit: EMFI Sensitivity Analysis of Embedded Deep Learning Models](https://arxiv.org/abs/2602.16309v1)** | 2026-02-18 |  |
| **[Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694v4)** | 2026-02-18 |  |

