---
title: Latest 15 Papers - December 02, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905v2)** | 2025-11-28 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Are LLMs Good Safety Agents or a Propaganda Engine?](https://arxiv.org/abs/2511.23174v1)** | 2025-11-28 | <details><summary>15 pa...</summary><p>15 pages, 7 tables, 4 figures</p></details> |
| **[Ghosting Your LLM: Without The Knowledge of Your Gradient and Data](https://arxiv.org/abs/2511.22700v1)** | 2025-11-27 |  |
| **[CacheTrap: Injecting Trojans in LLMs without Leaving any Traces in Inputs or Weights](https://arxiv.org/abs/2511.22681v1)** | 2025-11-27 |  |
| **[Distillability of LLM Security Logic: Predicting Attack Success Rate of Outline Filling Attack via Ranking Regression](https://arxiv.org/abs/2511.22044v1)** | 2025-11-27 |  |
| **[Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization](https://arxiv.org/abs/2511.19218v2)** | 2025-11-26 |  |
| **[Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs](https://arxiv.org/abs/2510.02833v4)** | 2025-11-26 | <details><summary>Publi...</summary><p>Published as a conference paper at NeurIPS 2025</p></details> |
| **[TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization](https://arxiv.org/abs/2511.18581v2)** | 2025-11-26 |  |
| **[Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment](https://arxiv.org/abs/2511.06852v4)** | 2025-11-24 | AAAI-26-AIA |
| **[AttackPilot: Autonomous Inference Attacks Against ML Services With LLM-Based Agents](https://arxiv.org/abs/2511.19536v1)** | 2025-11-24 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905v2)** | 2025-11-28 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Are LLMs Good Safety Agents or a Propaganda Engine?](https://arxiv.org/abs/2511.23174v1)** | 2025-11-28 | <details><summary>15 pa...</summary><p>15 pages, 7 tables, 4 figures</p></details> |
| **[Ghosting Your LLM: Without The Knowledge of Your Gradient and Data](https://arxiv.org/abs/2511.22700v1)** | 2025-11-27 |  |
| **[CacheTrap: Injecting Trojans in LLMs without Leaving any Traces in Inputs or Weights](https://arxiv.org/abs/2511.22681v1)** | 2025-11-27 |  |
| **[Distillability of LLM Security Logic: Predicting Attack Success Rate of Outline Filling Attack via Ranking Regression](https://arxiv.org/abs/2511.22044v1)** | 2025-11-27 |  |
| **[Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization](https://arxiv.org/abs/2511.19218v2)** | 2025-11-26 |  |
| **[Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs](https://arxiv.org/abs/2510.02833v4)** | 2025-11-26 | <details><summary>Publi...</summary><p>Published as a conference paper at NeurIPS 2025</p></details> |
| **[TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization](https://arxiv.org/abs/2511.18581v2)** | 2025-11-26 |  |
| **[Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent Supply Chains](https://arxiv.org/abs/2511.19874v1)** | 2025-11-25 | <details><summary>10 pa...</summary><p>10 pages, 2 figures, 8 tables. Evaluation across 6 production LLMs with 1,198 traces</p></details> |
| **[Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment](https://arxiv.org/abs/2511.06852v4)** | 2025-11-24 | AAAI-26-AIA |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SAEmnesia: Erasing Concepts in Diffusion Models with Supervised Sparse Autoencoders](https://arxiv.org/abs/2509.21379v2)** | 2025-11-28 |  |
| **[Adversarial Confusion Attack: Disrupting Multimodal Large Language Models](https://arxiv.org/abs/2511.20494v2)** | 2025-11-28 |  |
| **[FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning](https://arxiv.org/abs/2511.22265v1)** | 2025-11-27 |  |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](https://arxiv.org/abs/2505.24592v2)** | 2025-11-27 | <details><summary>In Pr...</summary><p>In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) 2026, Singapore</p></details> |
| **[F.A.C.U.L.: Language-Based Interaction with AI Companions in Gaming](https://arxiv.org/abs/2511.13112v2)** | 2025-11-27 | <details><summary>14 pa...</summary><p>14 pages, 11 figures,</p></details> |
| **[PROMPTMINER: Black-Box Prompt Stealing against Text-to-Image Generative Models via Reinforcement Learning and Fuzz Optimization](https://arxiv.org/abs/2511.22119v1)** | 2025-11-27 |  |
| **[ARES: Anomaly Recognition Model For Edge Streams](https://arxiv.org/abs/2511.22078v1)** | 2025-11-27 | Accepted at KDD 2026 |
| **[Evaluating the Robustness of Large Language Model Safety Guardrails Against Adversarial Attacks](https://arxiv.org/abs/2511.22047v1)** | 2025-11-27 | <details><summary>21 pa...</summary><p>21 pages, 9 figures, 6 tables</p></details> |
| **[ABLE: Using Adversarial Pairs to Construct Local Models for Explaining Model Predictions](https://arxiv.org/abs/2511.21952v1)** | 2025-11-26 | <details><summary>10 pa...</summary><p>10 pages, 2 figures. Accepted to KDD 2026 (Research Track)</p></details> |
| **[Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models](https://arxiv.org/abs/2511.21663v1)** | 2025-11-26 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SAEmnesia: Erasing Concepts in Diffusion Models with Supervised Sparse Autoencoders](https://arxiv.org/abs/2509.21379v2)** | 2025-11-28 |  |
| **[Adversarial Confusion Attack: Disrupting Multimodal Large Language Models](https://arxiv.org/abs/2511.20494v2)** | 2025-11-28 |  |
| **[FedRE: A Representation Entanglement Framework for Model-Heterogeneous Federated Learning](https://arxiv.org/abs/2511.22265v1)** | 2025-11-27 |  |
| **[A Flat Minima Perspective on Understanding Augmentations and Model Robustness](https://arxiv.org/abs/2505.24592v2)** | 2025-11-27 | <details><summary>In Pr...</summary><p>In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) 2026, Singapore</p></details> |
| **[F.A.C.U.L.: Language-Based Interaction with AI Companions in Gaming](https://arxiv.org/abs/2511.13112v2)** | 2025-11-27 | <details><summary>14 pa...</summary><p>14 pages, 11 figures,</p></details> |
| **[PROMPTMINER: Black-Box Prompt Stealing against Text-to-Image Generative Models via Reinforcement Learning and Fuzz Optimization](https://arxiv.org/abs/2511.22119v1)** | 2025-11-27 |  |
| **[ARES: Anomaly Recognition Model For Edge Streams](https://arxiv.org/abs/2511.22078v1)** | 2025-11-27 | Accepted at KDD 2026 |
| **[Evaluating the Robustness of Large Language Model Safety Guardrails Against Adversarial Attacks](https://arxiv.org/abs/2511.22047v1)** | 2025-11-27 | <details><summary>21 pa...</summary><p>21 pages, 9 figures, 6 tables</p></details> |
| **[ABLE: Using Adversarial Pairs to Construct Local Models for Explaining Model Predictions](https://arxiv.org/abs/2511.21952v1)** | 2025-11-26 | <details><summary>10 pa...</summary><p>10 pages, 2 figures. Accepted to KDD 2026 (Research Track)</p></details> |
| **[Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models](https://arxiv.org/abs/2511.21663v1)** | 2025-11-26 |  |

