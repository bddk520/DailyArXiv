---
title: Latest 15 Papers - July 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v1)** | 2025-07-08 |  |
| **[ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis](http://arxiv.org/abs/2506.15790v2)** | 2025-07-08 | <details><summary>4 pag...</summary><p>4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on Internetware (Internetware 2025)</p></details> |
| **[Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs](http://arxiv.org/abs/2410.16327v2)** | 2025-07-08 |  |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v1)** | 2025-07-08 |  |
| **[Cascade: Token-Sharded Private LLM Inference](http://arxiv.org/abs/2507.05228v1)** | 2025-07-07 | <details><summary>To be...</summary><p>To be published in ICML 2025 Main Proceedings as "Hidden No More: Attacking and Defending Private Third-Party LLM Inference", together with arXiv:2505.18332</p></details> |
| **[Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2507.04724v1)** | 2025-07-07 |  |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v1)** | 2025-07-06 |  |
| **[Attention Slipping: A Mechanistic Understanding of Jailbreak Attacks and Defenses in LLMs](http://arxiv.org/abs/2507.04365v1)** | 2025-07-06 |  |
| **[Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States](http://arxiv.org/abs/2503.09066v2)** | 2025-07-04 | 4 figures |
| **[Blackbox Dataset Inference for LLM](http://arxiv.org/abs/2507.03619v1)** | 2025-07-04 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v1)** | 2025-07-08 |  |
| **[ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis](http://arxiv.org/abs/2506.15790v2)** | 2025-07-08 | <details><summary>4 pag...</summary><p>4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on Internetware (Internetware 2025)</p></details> |
| **[Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs](http://arxiv.org/abs/2410.16327v2)** | 2025-07-08 |  |
| **[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v1)** | 2025-07-08 |  |
| **[Cascade: Token-Sharded Private LLM Inference](http://arxiv.org/abs/2507.05228v1)** | 2025-07-07 | <details><summary>To be...</summary><p>To be published in ICML 2025 Main Proceedings as "Hidden No More: Attacking and Defending Private Third-Party LLM Inference", together with arXiv:2505.18332</p></details> |
| **[Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2507.04724v1)** | 2025-07-07 |  |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v1)** | 2025-07-06 |  |
| **[Attention Slipping: A Mechanistic Understanding of Jailbreak Attacks and Defenses in LLMs](http://arxiv.org/abs/2507.04365v1)** | 2025-07-06 |  |
| **[Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States](http://arxiv.org/abs/2503.09066v2)** | 2025-07-04 | 4 figures |
| **[Blackbox Dataset Inference for LLM](http://arxiv.org/abs/2507.03619v1)** | 2025-07-04 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models](http://arxiv.org/abs/2507.06078v1)** | 2025-07-08 |  |
| **[From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks](http://arxiv.org/abs/2502.05325v2)** | 2025-07-08 |  |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v3)** | 2025-07-08 |  |
| **[Response Attack: Exploiting Contextual Priming to Jailbreak Large Language Models](http://arxiv.org/abs/2507.05248v1)** | 2025-07-07 | <details><summary>21 pa...</summary><p>21 pages, 9 figures. Code and data available at https://github.com/Dtc7w3PQ/Response-Attack</p></details> |
| **[Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models](http://arxiv.org/abs/2405.20090v4)** | 2025-07-07 | <details><summary>Accep...</summary><p>Accepted by ACM MM 2025</p></details> |
| **[Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2507.04724v1)** | 2025-07-07 |  |
| **[Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message](http://arxiv.org/abs/2507.04673v1)** | 2025-07-07 |  |
| **[Model Inversion Attacks on Llama 3: Extracting PII from Large Language Models](http://arxiv.org/abs/2507.04478v1)** | 2025-07-06 |  |
| **[Arbiter PUF: Uniqueness and Reliability Analysis Using Hybrid CMOS-Stanford Memristor Model](http://arxiv.org/abs/2507.04461v1)** | 2025-07-06 |  |
| **[Can Large Language Models Automate the Refinement of Cellular Network Specifications?](http://arxiv.org/abs/2507.04214v1)** | 2025-07-06 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models](http://arxiv.org/abs/2507.06078v1)** | 2025-07-08 |  |
| **[From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks](http://arxiv.org/abs/2502.05325v2)** | 2025-07-08 |  |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v3)** | 2025-07-08 |  |
| **[Response Attack: Exploiting Contextual Priming to Jailbreak Large Language Models](http://arxiv.org/abs/2507.05248v1)** | 2025-07-07 | <details><summary>21 pa...</summary><p>21 pages, 9 figures. Code and data available at https://github.com/Dtc7w3PQ/Response-Attack</p></details> |
| **[Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models](http://arxiv.org/abs/2405.20090v4)** | 2025-07-07 | <details><summary>Accep...</summary><p>Accepted by ACM MM 2025</p></details> |
| **[Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2507.04724v1)** | 2025-07-07 |  |
| **[Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message](http://arxiv.org/abs/2507.04673v1)** | 2025-07-07 |  |
| **[Model Inversion Attacks on Llama 3: Extracting PII from Large Language Models](http://arxiv.org/abs/2507.04478v1)** | 2025-07-06 |  |
| **[Arbiter PUF: Uniqueness and Reliability Analysis Using Hybrid CMOS-Stanford Memristor Model](http://arxiv.org/abs/2507.04461v1)** | 2025-07-06 |  |
| **[Can Large Language Models Automate the Refinement of Cellular Network Specifications?](http://arxiv.org/abs/2507.04214v1)** | 2025-07-06 |  |

