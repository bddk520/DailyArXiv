---
title: Latest 15 Papers - December 12, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](https://arxiv.org/abs/2512.09872v1)** | 2025-12-10 | <details><summary>Accep...</summary><p>Accepted in IEEE HOST 2026</p></details> |
| **[Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks](https://arxiv.org/abs/2512.09485v1)** | 2025-12-10 | <details><summary>Accep...</summary><p>Accepted by IEEE JSAC. This work has been submitted to the IEEE for possible publication</p></details> |
| **[Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs](https://arxiv.org/abs/2512.09403v1)** | 2025-12-10 |  |
| **[ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321v1)** | 2025-12-10 | <details><summary>To ap...</summary><p>To appear in NDSS 2026</p></details> |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](https://arxiv.org/abs/2503.03704v4)** | 2025-12-10 |  |
| **[When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation](https://arxiv.org/abs/2512.08875v1)** | 2025-12-09 |  |
| **[Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs](https://arxiv.org/abs/2512.08417v1)** | 2025-12-09 | <details><summary>Accep...</summary><p>Accepted by Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[TeleAI-Safety: A comprehensive LLM jailbreaking benchmark towards attacks, defenses, and evaluations](https://arxiv.org/abs/2512.05485v2)** | 2025-12-08 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v2)** | 2025-12-08 |  |
| **[Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference](https://arxiv.org/abs/2508.09442v3)** | 2025-12-08 | <details><summary>This ...</summary><p>This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](https://arxiv.org/abs/2512.09872v1)** | 2025-12-10 | <details><summary>Accep...</summary><p>Accepted in IEEE HOST 2026</p></details> |
| **[Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs](https://arxiv.org/abs/2512.09742v1)** | 2025-12-10 | 70 pages, 47 figures |
| **[Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks](https://arxiv.org/abs/2512.09485v1)** | 2025-12-10 | <details><summary>Accep...</summary><p>Accepted by IEEE JSAC. This work has been submitted to the IEEE for possible publication</p></details> |
| **[Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs](https://arxiv.org/abs/2512.09403v1)** | 2025-12-10 |  |
| **[ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321v1)** | 2025-12-10 | <details><summary>To ap...</summary><p>To appear in NDSS 2026</p></details> |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](https://arxiv.org/abs/2503.03704v4)** | 2025-12-10 |  |
| **[When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation](https://arxiv.org/abs/2512.08875v1)** | 2025-12-09 |  |
| **[Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs](https://arxiv.org/abs/2512.08417v1)** | 2025-12-09 | <details><summary>Accep...</summary><p>Accepted by Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[TeleAI-Safety: A comprehensive LLM jailbreaking benchmark towards attacks, defenses, and evaluations](https://arxiv.org/abs/2512.05485v2)** | 2025-12-08 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v2)** | 2025-12-08 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654v1)** | 2025-12-10 | <details><summary>NeurI...</summary><p>NeurIPS 2025 AI for Music Workshop NeurIPS 2025 Workshop on Creativity & Generative AI</p></details> |
| **[Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution](https://arxiv.org/abs/2510.16443v2)** | 2025-12-10 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](https://arxiv.org/abs/2501.02968v4)** | 2025-12-10 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[Gradient-Free Privacy Leakage in Federated Language Models through Selective Weight Tampering](https://arxiv.org/abs/2310.16152v4)** | 2025-12-09 | <details><summary>21 pa...</summary><p>21 pages (including bibliography and Appendix), Submitted to PETS'26</p></details> |
| **[Toward Quantitative Modeling of Cybersecurity Risks Due to AI Misuse](https://arxiv.org/abs/2512.08864v1)** | 2025-12-09 |  |
| **[3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models](https://arxiv.org/abs/2507.10733v2)** | 2025-12-09 | 20 pages, 12 figures |
| **[Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models](https://arxiv.org/abs/2512.08832v1)** | 2025-12-09 |  |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v1)** | 2025-12-09 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version)</p></details> |
| **[An Explainable AI Model for the Detecting Malicious Smart Contracts Based on EVM Opcode Based Features](https://arxiv.org/abs/2512.08782v1)** | 2025-12-09 |  |
| **[Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222v2)** | 2025-12-09 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654v1)** | 2025-12-10 | <details><summary>NeurI...</summary><p>NeurIPS 2025 AI for Music Workshop NeurIPS 2025 Workshop on Creativity & Generative AI</p></details> |
| **[Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution](https://arxiv.org/abs/2510.16443v2)** | 2025-12-10 |  |
| **[FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to Retrieval-Augmented Generation Models](https://arxiv.org/abs/2501.02968v4)** | 2025-12-10 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.13757</p></details> |
| **[Gradient-Free Privacy Leakage in Federated Language Models through Selective Weight Tampering](https://arxiv.org/abs/2310.16152v4)** | 2025-12-09 | <details><summary>21 pa...</summary><p>21 pages (including bibliography and Appendix), Submitted to PETS'26</p></details> |
| **[Toward Quantitative Modeling of Cybersecurity Risks Due to AI Misuse](https://arxiv.org/abs/2512.08864v1)** | 2025-12-09 |  |
| **[3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models](https://arxiv.org/abs/2507.10733v2)** | 2025-12-09 | 20 pages, 12 figures |
| **[Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models](https://arxiv.org/abs/2512.08832v1)** | 2025-12-09 |  |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v1)** | 2025-12-09 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version)</p></details> |
| **[An Explainable AI Model for the Detecting Malicious Smart Contracts Based on EVM Opcode Based Features](https://arxiv.org/abs/2512.08782v1)** | 2025-12-09 |  |
| **[Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222v2)** | 2025-12-09 |  |

