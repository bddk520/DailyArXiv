---
title: Latest 15 Papers - December 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](https://arxiv.org/abs/2505.14886v2)** | 2025-12-19 | 9 main pages |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](https://arxiv.org/abs/2508.17361v2)** | 2025-12-18 |  |
| **[MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](https://arxiv.org/abs/2512.16962v1)** | 2025-12-18 | <details><summary>14 pa...</summary><p>14 pages, 1 figure, includes appendix</p></details> |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489v3)** | 2025-12-18 | <details><summary>Publi...</summary><p>Published in NeurIPS 2025</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v3)** | 2025-12-17 | <details><summary>Updat...</summary><p>Updated with new baselines and experimental results</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v4)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[Quantifying Return on Security Controls in LLM Systems](https://arxiv.org/abs/2512.15081v1)** | 2025-12-17 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, 3 tables</p></details> |
| **[MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846v1)** | 2025-12-16 |  |
| **[Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space](https://arxiv.org/abs/2512.14448v1)** | 2025-12-16 |  |
| **[PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design](https://arxiv.org/abs/2512.14233v1)** | 2025-12-16 | 13 pages, 6 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](https://arxiv.org/abs/2505.14886v2)** | 2025-12-19 | 9 main pages |
| **[Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias](https://arxiv.org/abs/2508.17361v2)** | 2025-12-18 |  |
| **[MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](https://arxiv.org/abs/2512.16962v1)** | 2025-12-18 | <details><summary>14 pa...</summary><p>14 pages, 1 figure, includes appendix</p></details> |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489v3)** | 2025-12-18 | <details><summary>Publi...</summary><p>Published in NeurIPS 2025</p></details> |
| **[The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search](https://arxiv.org/abs/2512.01353v3)** | 2025-12-17 | <details><summary>Updat...</summary><p>Updated with new baselines and experimental results</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](https://arxiv.org/abs/2509.14285v4)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted at the 11th IEEE WIECON-ECE 2025</p></details> |
| **[Quantifying Return on Security Controls in LLM Systems](https://arxiv.org/abs/2512.15081v1)** | 2025-12-17 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, 3 tables</p></details> |
| **[MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846v1)** | 2025-12-16 |  |
| **[Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space](https://arxiv.org/abs/2512.14448v1)** | 2025-12-16 |  |
| **[PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design](https://arxiv.org/abs/2512.14233v1)** | 2025-12-16 | 13 pages, 6 figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Robustness of Vision in Open Foundation Models](https://arxiv.org/abs/2512.17902v1)** | 2025-12-19 |  |
| **[Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features](https://arxiv.org/abs/2507.00724v2)** | 2025-12-19 |  |
| **[CNFinBench: A Benchmark for Safety and Compliance of Large Language Models in Finance](https://arxiv.org/abs/2512.09506v2)** | 2025-12-19 |  |
| **[Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008v2)** | 2025-12-19 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026 main track</p></details> |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v3)** | 2025-12-18 |  |
| **[MoAPT: Mixture of Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2505.17509v2)** | 2025-12-18 |  |
| **[In-Context Probing for Membership Inference in Fine-Tuned Language Models](https://arxiv.org/abs/2512.16292v1)** | 2025-12-18 |  |
| **[DualGuard: Dual-stream Large Language Model Watermarking Defense against Paraphrase and Spoofing Attack](https://arxiv.org/abs/2512.16182v1)** | 2025-12-18 |  |
| **[Time will Tell: Large-scale De-anonymization of Hidden I2P Services via Live Behavior Alignment (Extended Version)](https://arxiv.org/abs/2512.15510v1)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted to appear at the Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Unveiling the Attribute Misbinding Threat in Identity-Preserving Models](https://arxiv.org/abs/2512.15818v1)** | 2025-12-17 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Robustness of Vision in Open Foundation Models](https://arxiv.org/abs/2512.17902v1)** | 2025-12-19 |  |
| **[Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features](https://arxiv.org/abs/2507.00724v2)** | 2025-12-19 |  |
| **[CNFinBench: A Benchmark for Safety and Compliance of Large Language Models in Finance](https://arxiv.org/abs/2512.09506v2)** | 2025-12-19 |  |
| **[Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008v2)** | 2025-12-19 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026 main track</p></details> |
| **[Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503v3)** | 2025-12-18 |  |
| **[MoAPT: Mixture of Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2505.17509v2)** | 2025-12-18 |  |
| **[In-Context Probing for Membership Inference in Fine-Tuned Language Models](https://arxiv.org/abs/2512.16292v1)** | 2025-12-18 |  |
| **[DualGuard: Dual-stream Large Language Model Watermarking Defense against Paraphrase and Spoofing Attack](https://arxiv.org/abs/2512.16182v1)** | 2025-12-18 |  |
| **[Time will Tell: Large-scale De-anonymization of Hidden I2P Services via Live Behavior Alignment (Extended Version)](https://arxiv.org/abs/2512.15510v1)** | 2025-12-17 | <details><summary>Accep...</summary><p>Accepted to appear at the Network and Distributed System Security (NDSS) Symposium 2026</p></details> |
| **[Unveiling the Attribute Misbinding Threat in Identity-Preserving Models](https://arxiv.org/abs/2512.15818v1)** | 2025-12-17 |  |

