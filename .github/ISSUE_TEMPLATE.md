---
title: Latest 15 Papers - July 28, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v2)** | 2025-07-24 |  |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v2)** | 2025-07-23 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v4)** | 2025-07-22 |  |
| **[Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](http://arxiv.org/abs/2507.16291v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by EAI ICDF2C 2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v2)** | 2025-07-24 |  |
| **[LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](http://arxiv.org/abs/2506.15606v2)** | 2025-07-23 |  |
| **[Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](http://arxiv.org/abs/2507.17636v1)** | 2025-07-23 |  |
| **[Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks](http://arxiv.org/abs/2507.10054v2)** | 2025-07-23 | <details><summary>Accep...</summary><p>Accepted to ICSME 2025</p></details> |
| **[Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](http://arxiv.org/abs/2507.17259v1)** | 2025-07-23 |  |
| **[When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](http://arxiv.org/abs/2507.16773v1)** | 2025-07-22 |  |
| **[Depth Gives a False Sense of Privacy: LLM Internal States Inversion](http://arxiv.org/abs/2507.16372v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by USENIX Security 2025. Please cite this paper as "Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25)."</p></details> |
| **[ShadowCode: Towards (Automatic) External Prompt Injection Attack against Code LLMs](http://arxiv.org/abs/2407.09164v6)** | 2025-07-22 |  |
| **[OMNISEC: LLM-Driven Provenance-based Intrusion Detection via Retrieval-Augmented Behavior Prompting](http://arxiv.org/abs/2503.03108v4)** | 2025-07-22 |  |
| **[Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](http://arxiv.org/abs/2507.16291v1)** | 2025-07-22 | <details><summary>Accep...</summary><p>Accepted by EAI ICDF2C 2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[On Reconstructing Training Data From Bayesian Posteriors and Trained Models](http://arxiv.org/abs/2507.18372v1)** | 2025-07-24 |  |
| **[BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](http://arxiv.org/abs/2507.18305v1)** | 2025-07-24 |  |
| **[LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models](http://arxiv.org/abs/2507.18302v1)** | 2025-07-24 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models](http://arxiv.org/abs/2507.18249v1)** | 2025-07-24 | 12 pages |
| **[Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification](http://arxiv.org/abs/2507.18113v1)** | 2025-07-24 |  |
| **[Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](http://arxiv.org/abs/2503.17724v2)** | 2025-07-24 |  |
| **[RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models](http://arxiv.org/abs/2507.18053v1)** | 2025-07-24 |  |
| **[Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering](http://arxiv.org/abs/2507.18034v1)** | 2025-07-24 |  |
| **[ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](http://arxiv.org/abs/2507.18031v1)** | 2025-07-24 |  |
| **[From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models](http://arxiv.org/abs/2507.17922v1)** | 2025-07-23 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[On Reconstructing Training Data From Bayesian Posteriors and Trained Models](http://arxiv.org/abs/2507.18372v1)** | 2025-07-24 |  |
| **[BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](http://arxiv.org/abs/2507.18305v1)** | 2025-07-24 |  |
| **[LoRA-Leak: Membership Inference Attacks Against LoRA Fine-tuned Language Models](http://arxiv.org/abs/2507.18302v1)** | 2025-07-24 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Auto-SGCR: Automated Generation of Smart Grid Cyber Range Using IEC 61850 Standard Models](http://arxiv.org/abs/2507.18249v1)** | 2025-07-24 | 12 pages |
| **[Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification](http://arxiv.org/abs/2507.18113v1)** | 2025-07-24 |  |
| **[Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](http://arxiv.org/abs/2503.17724v2)** | 2025-07-24 |  |
| **[RECALLED: An Unbounded Resource Consumption Attack on Large Vision-Language Models](http://arxiv.org/abs/2507.18053v1)** | 2025-07-24 |  |
| **[Removing Box-Free Watermarks for Image-to-Image Models via Query-Based Reverse Engineering](http://arxiv.org/abs/2507.18034v1)** | 2025-07-24 |  |
| **[ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](http://arxiv.org/abs/2507.18031v1)** | 2025-07-24 |  |
| **[From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models](http://arxiv.org/abs/2507.17922v1)** | 2025-07-23 |  |

