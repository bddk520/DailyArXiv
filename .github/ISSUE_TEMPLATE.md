---
title: Latest 15 Papers - April 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |
| **[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](http://arxiv.org/abs/2504.11182v1)** | 2025-04-15 |  |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v1)** | 2025-04-15 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v1)** | 2025-04-14 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |
| **[From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security](http://arxiv.org/abs/2412.15004v3)** | 2025-04-14 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v1)** | 2025-04-13 |  |
| **[AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender](http://arxiv.org/abs/2504.09466v1)** | 2025-04-13 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 9 tables</p></details> |
| **[SaRO: Enhancing LLM Safety through Reasoning-based Alignment](http://arxiv.org/abs/2504.09420v1)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |
| **[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](http://arxiv.org/abs/2504.11182v1)** | 2025-04-15 |  |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v1)** | 2025-04-15 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v1)** | 2025-04-14 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |
| **[From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security](http://arxiv.org/abs/2412.15004v3)** | 2025-04-14 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v1)** | 2025-04-13 |  |
| **[AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender](http://arxiv.org/abs/2504.09466v1)** | 2025-04-13 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 9 tables</p></details> |
| **[SaRO: Enhancing LLM Safety through Reasoning-based Alignment](http://arxiv.org/abs/2504.09420v1)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v1)** | 2025-04-15 | CVPR 2025 |
| **[Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models](http://arxiv.org/abs/2504.11106v1)** | 2025-04-15 |  |
| **[FLSSM: A Federated Learning Storage Security Model with Homomorphic Encryption](http://arxiv.org/abs/2504.11088v1)** | 2025-04-15 |  |
| **[MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness](http://arxiv.org/abs/2312.04960v4)** | 2025-04-15 |  |
| **[QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models](http://arxiv.org/abs/2504.11038v1)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted by NAACL 2025 main</p></details> |
| **[Defending Against Frequency-Based Attacks with Diffusion Models](http://arxiv.org/abs/2504.11034v1)** | 2025-04-15 | <details><summary>Confe...</summary><p>Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 5th Workshop on Adversarial Machine Learning in Computer Vision: Foundation Models + X</p></details> |
| **[Protecting Copyright of Medical Pre-trained Language Models: Training-Free Backdoor Model Watermarking](http://arxiv.org/abs/2409.10570v2)** | 2025-04-15 | 9 pages |
| **[Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense](http://arxiv.org/abs/2412.21051v2)** | 2025-04-15 | <details><summary>7 pag...</summary><p>7 pages; In submission</p></details> |
| **[Adversarial Prompt Distillation for Vision-Language Models](http://arxiv.org/abs/2411.15244v2)** | 2025-04-15 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v1)** | 2025-04-15 | CVPR 2025 |
| **[Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models](http://arxiv.org/abs/2504.11106v1)** | 2025-04-15 |  |
| **[FLSSM: A Federated Learning Storage Security Model with Homomorphic Encryption](http://arxiv.org/abs/2504.11088v1)** | 2025-04-15 |  |
| **[MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness](http://arxiv.org/abs/2312.04960v4)** | 2025-04-15 |  |
| **[QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models](http://arxiv.org/abs/2504.11038v1)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted by NAACL 2025 main</p></details> |
| **[Defending Against Frequency-Based Attacks with Diffusion Models](http://arxiv.org/abs/2504.11034v1)** | 2025-04-15 | <details><summary>Confe...</summary><p>Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 5th Workshop on Adversarial Machine Learning in Computer Vision: Foundation Models + X</p></details> |
| **[Protecting Copyright of Medical Pre-trained Language Models: Training-Free Backdoor Model Watermarking](http://arxiv.org/abs/2409.10570v2)** | 2025-04-15 | 9 pages |
| **[Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense](http://arxiv.org/abs/2412.21051v2)** | 2025-04-15 | <details><summary>7 pag...</summary><p>7 pages; In submission</p></details> |
| **[Adversarial Prompt Distillation for Vision-Language Models](http://arxiv.org/abs/2411.15244v2)** | 2025-04-15 |  |

