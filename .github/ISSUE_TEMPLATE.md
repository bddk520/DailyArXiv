---
title: Latest 15 Papers - September 01, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Publish to Perish: Prompt Injection Attacks on LLM-Assisted Peer Review](http://arxiv.org/abs/2508.20863v1)** | 2025-08-28 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](http://arxiv.org/abs/2508.20697v1)** | 2025-08-28 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |
| **[CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics](http://arxiv.org/abs/2508.20643v1)** | 2025-08-28 | <details><summary>Code:...</summary><p>Code: https://github.com/SmartData-Polito/LLM_Agent_Cybersecurity_Forensic</p></details> |
| **[RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis](http://arxiv.org/abs/2411.18948v4)** | 2025-08-28 |  |
| **[Ransomware 3.0: Self-Composing and LLM-Orchestrated](http://arxiv.org/abs/2508.20444v1)** | 2025-08-28 |  |
| **[Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](http://arxiv.org/abs/2508.20038v2)** | 2025-08-28 | EMNLP 2025 findings |
| **[Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](http://arxiv.org/abs/2508.20333v1)** | 2025-08-28 |  |
| **[IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement](http://arxiv.org/abs/2508.20151v1)** | 2025-08-27 | 17 pages, 9 figures |
| **[Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey](http://arxiv.org/abs/2508.19870v1)** | 2025-08-27 | 35 pages |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v2)** | 2025-08-27 | v0.2 |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Publish to Perish: Prompt Injection Attacks on LLM-Assisted Peer Review](http://arxiv.org/abs/2508.20863v1)** | 2025-08-28 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](http://arxiv.org/abs/2508.20697v1)** | 2025-08-28 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |
| **[CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics](http://arxiv.org/abs/2508.20643v1)** | 2025-08-28 | <details><summary>Code:...</summary><p>Code: https://github.com/SmartData-Polito/LLM_Agent_Cybersecurity_Forensic</p></details> |
| **[RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis](http://arxiv.org/abs/2411.18948v4)** | 2025-08-28 |  |
| **[Ransomware 3.0: Self-Composing and LLM-Orchestrated](http://arxiv.org/abs/2508.20444v1)** | 2025-08-28 |  |
| **[Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](http://arxiv.org/abs/2508.20038v2)** | 2025-08-28 | EMNLP 2025 findings |
| **[Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](http://arxiv.org/abs/2508.20333v1)** | 2025-08-28 |  |
| **[IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement](http://arxiv.org/abs/2508.20151v1)** | 2025-08-27 | 17 pages, 9 figures |
| **[Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey](http://arxiv.org/abs/2508.19870v1)** | 2025-08-27 | 35 pages |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v2)** | 2025-08-27 | v0.2 |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](http://arxiv.org/abs/2508.21004v1)** | 2025-08-28 |  |
| **[Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](http://arxiv.org/abs/2508.20718v1)** | 2025-08-28 |  |
| **[Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application](http://arxiv.org/abs/2503.06989v4)** | 2025-08-28 |  |
| **[Breaking Diffusion with Cache: Exploiting Approximate Caches in Diffusion Models](http://arxiv.org/abs/2508.20424v1)** | 2025-08-28 |  |
| **[Governable AI: Provable Safety Under Extreme Threat Models](http://arxiv.org/abs/2508.20411v1)** | 2025-08-28 |  |
| **[CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](http://arxiv.org/abs/2508.02997v3)** | 2025-08-27 |  |
| **[Adversarial Manipulation of Reasoning Models using Internal Representations](http://arxiv.org/abs/2507.03167v2)** | 2025-08-27 | <details><summary>Accep...</summary><p>Accepted to the ICML 2025 Workshop on Reliable and Responsible Foundation Models (R2FM). 20 pages, 12 figures</p></details> |
| **[The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again](http://arxiv.org/abs/2508.19774v1)** | 2025-08-27 |  |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v2)** | 2025-08-27 | <details><summary>CVPR ...</summary><p>CVPR 2025 (Corrected the results on the Aircraft dataset)</p></details> |
| **[A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives](http://arxiv.org/abs/2508.15031v2)** | 2025-08-27 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](http://arxiv.org/abs/2508.21004v1)** | 2025-08-28 |  |
| **[Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](http://arxiv.org/abs/2508.20718v1)** | 2025-08-28 |  |
| **[Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application](http://arxiv.org/abs/2503.06989v4)** | 2025-08-28 |  |
| **[Breaking Diffusion with Cache: Exploiting Approximate Caches in Diffusion Models](http://arxiv.org/abs/2508.20424v1)** | 2025-08-28 |  |
| **[Governable AI: Provable Safety Under Extreme Threat Models](http://arxiv.org/abs/2508.20411v1)** | 2025-08-28 |  |
| **[CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](http://arxiv.org/abs/2508.02997v3)** | 2025-08-27 |  |
| **[Adversarial Manipulation of Reasoning Models using Internal Representations](http://arxiv.org/abs/2507.03167v2)** | 2025-08-27 | <details><summary>Accep...</summary><p>Accepted to the ICML 2025 Workshop on Reliable and Responsible Foundation Models (R2FM). 20 pages, 12 figures</p></details> |
| **[The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again](http://arxiv.org/abs/2508.19774v1)** | 2025-08-27 |  |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v2)** | 2025-08-27 | <details><summary>CVPR ...</summary><p>CVPR 2025 (Corrected the results on the Aircraft dataset)</p></details> |
| **[A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives](http://arxiv.org/abs/2508.15031v2)** | 2025-08-27 |  |

