---
title: Latest 15 Papers - August 12, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v1)** | 2025-08-08 | v0.1 |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v1)** | 2025-08-08 |  |
| **[Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications](http://arxiv.org/abs/2411.14110v2)** | 2025-08-08 |  |
| **[LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage](http://arxiv.org/abs/2412.05734v2)** | 2025-08-08 | <details><summary>Accep...</summary><p>Accepted by COLM 2025</p></details> |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When AIOps Become "AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v1)** | 2025-08-08 | v0.1 |
| **[LLM Robustness Leaderboard v1 --Technical report](http://arxiv.org/abs/2508.06296v1)** | 2025-08-08 |  |
| **[Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications](http://arxiv.org/abs/2411.14110v2)** | 2025-08-08 |  |
| **[LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage](http://arxiv.org/abs/2412.05734v2)** | 2025-08-08 | <details><summary>Accep...</summary><p>Accepted by COLM 2025</p></details> |
| **[Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](http://arxiv.org/abs/2508.04894v1)** | 2025-08-06 |  |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v4)** | 2025-08-06 |  |
| **[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)** | 2025-08-06 |  |
| **[CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts](http://arxiv.org/abs/2505.16888v2)** | 2025-08-06 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v2)** | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (Findings), camera-ready version</p></details> |
| **[Tool Unlearning for Tool-Augmented LLMs](http://arxiv.org/abs/2502.01083v2)** | 2025-08-06 | <details><summary>ICML ...</summary><p>ICML 2025 https://clu-uml.github.io/MU-Bench-Project-Page/</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions](http://arxiv.org/abs/2501.01872v3)** | 2025-08-08 | <details><summary>Our c...</summary><p>Our code is publicly available at https://github.com/UKPLab/arxiv2025-poate-attack</p></details> |
| **[In-Training Defenses against Emergent Misalignment in Language Models](http://arxiv.org/abs/2508.06249v1)** | 2025-08-08 | Under review |
| **[SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses](http://arxiv.org/abs/2411.11195v3)** | 2025-08-08 |  |
| **[SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](http://arxiv.org/abs/2508.06127v1)** | 2025-08-08 | <details><summary>8 pag...</summary><p>8 pages,recived by ICCV2025</p></details> |
| **[Adaptive Backtracking for Privacy Protection in Large Language Models](http://arxiv.org/abs/2508.06087v1)** | 2025-08-08 |  |
| **[FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](http://arxiv.org/abs/2501.15509v3)** | 2025-08-08 |  |
| **[Bayesian weighted discrete-time dynamic models for association football prediction](http://arxiv.org/abs/2508.05891v1)** | 2025-08-07 |  |
| **[Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](http://arxiv.org/abs/2508.00649v2)** | 2025-08-07 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[JULI: Jailbreak Large Language Models by Self-Introspection](http://arxiv.org/abs/2505.11790v3)** | 2025-08-07 |  |
| **[From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](http://arxiv.org/abs/2508.05409v1)** | 2025-08-07 | 19 Pages, 24 Figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions](http://arxiv.org/abs/2501.01872v3)** | 2025-08-08 | <details><summary>Our c...</summary><p>Our code is publicly available at https://github.com/UKPLab/arxiv2025-poate-attack</p></details> |
| **[In-Training Defenses against Emergent Misalignment in Language Models](http://arxiv.org/abs/2508.06249v1)** | 2025-08-08 | Under review |
| **[SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses](http://arxiv.org/abs/2411.11195v3)** | 2025-08-08 |  |
| **[Rethinking the Bias of Foundation Model under Long-tailed Distribution](http://arxiv.org/abs/2501.15955v3)** | 2025-08-08 | <details><summary>Publi...</summary><p>Published as a conference paper in ICML 2025</p></details> |
| **[SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](http://arxiv.org/abs/2508.06127v1)** | 2025-08-08 | <details><summary>8 pag...</summary><p>8 pages,recived by ICCV2025</p></details> |
| **[Adaptive Backtracking for Privacy Protection in Large Language Models](http://arxiv.org/abs/2508.06087v1)** | 2025-08-08 |  |
| **[FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](http://arxiv.org/abs/2501.15509v3)** | 2025-08-08 |  |
| **[Bayesian weighted discrete-time dynamic models for association football prediction](http://arxiv.org/abs/2508.05891v1)** | 2025-08-07 |  |
| **[Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](http://arxiv.org/abs/2508.00649v2)** | 2025-08-07 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[JULI: Jailbreak Large Language Models by Self-Introspection](http://arxiv.org/abs/2505.11790v3)** | 2025-08-07 |  |

