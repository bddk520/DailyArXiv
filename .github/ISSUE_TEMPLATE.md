---
title: Latest 15 Papers - January 15, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[STELP: Secure Transpilation and Execution of LLM-Generated Programs](https://arxiv.org/abs/2601.05467v2)** | 2026-01-13 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](https://arxiv.org/abs/2510.14381v2)** | 2026-01-13 | <details><summary>Proce...</summary><p>Proceedings of the 19th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2026)</p></details> |
| **[STAR: Detecting Inference-time Backdoors in LLM Reasoning via State-Transition Amplification Ratio](https://arxiv.org/abs/2601.08511v1)** | 2026-01-13 | 16 pages, 5 figures |
| **[Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety](https://arxiv.org/abs/2601.08000v1)** | 2026-01-12 |  |
| **[SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations](https://arxiv.org/abs/2601.07835v1)** | 2026-01-12 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v3)** | 2026-01-12 |  |
| **[Memory Poisoning Attack and Defense on Memory Based LLM-Agents](https://arxiv.org/abs/2601.05504v2)** | 2026-01-12 |  |
| **[Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2601.07122v1)** | 2026-01-12 |  |
| **[NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144v2)** | 2026-01-11 |  |
| **[Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems](https://arxiv.org/abs/2601.07072v1)** | 2026-01-11 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[STELP: Secure Transpilation and Execution of LLM-Generated Programs](https://arxiv.org/abs/2601.05467v2)** | 2026-01-13 |  |
| **[Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers](https://arxiv.org/abs/2510.14381v2)** | 2026-01-13 | <details><summary>Proce...</summary><p>Proceedings of the 19th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2026)</p></details> |
| **[STAR: Detecting Inference-time Backdoors in LLM Reasoning via State-Transition Amplification Ratio](https://arxiv.org/abs/2601.08511v1)** | 2026-01-13 | 16 pages, 5 figures |
| **[Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety](https://arxiv.org/abs/2601.08000v1)** | 2026-01-12 |  |
| **[SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations](https://arxiv.org/abs/2601.07835v1)** | 2026-01-12 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v3)** | 2026-01-12 |  |
| **[Memory Poisoning Attack and Defense on Memory Based LLM-Agents](https://arxiv.org/abs/2601.05504v2)** | 2026-01-12 |  |
| **[Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2601.07122v1)** | 2026-01-12 |  |
| **[NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144v2)** | 2026-01-11 |  |
| **[Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems](https://arxiv.org/abs/2601.07072v1)** | 2026-01-11 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TROJail: Trajectory-Level Optimization for Multi-Turn Large Language Model Jailbreaks with Process Rewards](https://arxiv.org/abs/2512.07761v2)** | 2026-01-13 | 21 pages, 15 figures |
| **[SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models](https://arxiv.org/abs/2601.08623v1)** | 2026-01-13 | <details><summary>Code ...</summary><p>Code at https://github.com/ryliu68/SafeRedir</p></details> |
| **[Robust CAPTCHA Using Audio Illusions in the Era of Large Language Models: from Evaluation to Advances](https://arxiv.org/abs/2601.08516v1)** | 2026-01-13 |  |
| **[BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts](https://arxiv.org/abs/2601.08490v1)** | 2026-01-13 | <details><summary>Accep...</summary><p>Accepted at TMLR 2026</p></details> |
| **[DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection](https://arxiv.org/abs/2601.08223v1)** | 2026-01-13 |  |
| **[Measuring the Impact of Student Gaming Behaviors on Learner Modeling](https://arxiv.org/abs/2512.18659v3)** | 2026-01-12 | <details><summary>Full ...</summary><p>Full research paper accepted at Learning Analytics and Knowledge (LAK '26) conference, see https://doi.org/10.1145/3785022.3785036</p></details> |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](https://arxiv.org/abs/2510.05699v2)** | 2026-01-12 | <details><summary>To ap...</summary><p>To appear at USENIX Security Symposium 2026</p></details> |
| **[From static to adaptive: immune memory-based jailbreak detection for large language models](https://arxiv.org/abs/2512.03356v2)** | 2026-01-12 |  |
| **[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772v4)** | 2026-01-12 |  |
| **[A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291v1)** | 2026-01-12 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TROJail: Trajectory-Level Optimization for Multi-Turn Large Language Model Jailbreaks with Process Rewards](https://arxiv.org/abs/2512.07761v2)** | 2026-01-13 | 21 pages, 15 figures |
| **[SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models](https://arxiv.org/abs/2601.08623v1)** | 2026-01-13 | <details><summary>Code ...</summary><p>Code at https://github.com/ryliu68/SafeRedir</p></details> |
| **[Robust CAPTCHA Using Audio Illusions in the Era of Large Language Models: from Evaluation to Advances](https://arxiv.org/abs/2601.08516v1)** | 2026-01-13 |  |
| **[BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts](https://arxiv.org/abs/2601.08490v1)** | 2026-01-13 | <details><summary>Accep...</summary><p>Accepted at TMLR 2026</p></details> |
| **[DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection](https://arxiv.org/abs/2601.08223v1)** | 2026-01-13 |  |
| **[ForgetMark: Stealthy Fingerprint Embedding via Targeted Unlearning in Language Models](https://arxiv.org/abs/2601.08189v1)** | 2026-01-13 |  |
| **[Measuring the Impact of Student Gaming Behaviors on Learner Modeling](https://arxiv.org/abs/2512.18659v3)** | 2026-01-12 | <details><summary>Full ...</summary><p>Full research paper accepted at Learning Analytics and Knowledge (LAK '26) conference, see https://doi.org/10.1145/3785022.3785036</p></details> |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](https://arxiv.org/abs/2510.05699v2)** | 2026-01-12 | <details><summary>To ap...</summary><p>To appear at USENIX Security Symposium 2026</p></details> |
| **[From static to adaptive: immune memory-based jailbreak detection for large language models](https://arxiv.org/abs/2512.03356v2)** | 2026-01-12 |  |
| **[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772v4)** | 2026-01-12 |  |

