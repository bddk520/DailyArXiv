---
title: Latest 15 Papers - June 02, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](http://arxiv.org/abs/2505.23559v1)** | 2025-05-29 |  |
| **[Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context](http://arxiv.org/abs/2412.16359v3)** | 2025-05-29 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.14644</p></details> |
| **[Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](http://arxiv.org/abs/2505.22943v1)** | 2025-05-28 | <details><summary>ACL 2...</summary><p>ACL 2025 Main. Code is released at https://vision.snu.ac.kr/projects/mac</p></details> |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v1)** | 2025-05-28 |  |
| **[Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](http://arxiv.org/abs/2505.22852v1)** | 2025-05-28 |  |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v2)** | 2025-05-28 | <details><summary>Follo...</summary><p>Follow-up work from arXiv:2405.01886</p></details> |
| **[Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing](http://arxiv.org/abs/2505.22298v1)** | 2025-05-28 | ACL 2025 Findings |
| **[Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](http://arxiv.org/abs/2502.19041v2)** | 2025-05-28 | <details><summary>16 pa...</summary><p>16 pages, 12 figures, ACL 2025 findings</p></details> |
| **[MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](http://arxiv.org/abs/2505.20824v1)** | 2025-05-27 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v4)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](http://arxiv.org/abs/2505.23559v1)** | 2025-05-29 |  |
| **[Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context](http://arxiv.org/abs/2412.16359v3)** | 2025-05-29 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2407.14644</p></details> |
| **[Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](http://arxiv.org/abs/2505.22943v1)** | 2025-05-28 | <details><summary>ACL 2...</summary><p>ACL 2025 Main. Code is released at https://vision.snu.ac.kr/projects/mac</p></details> |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v1)** | 2025-05-28 |  |
| **[Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](http://arxiv.org/abs/2505.22852v1)** | 2025-05-28 |  |
| **[The Aloe Family Recipe for Open and Specialized Healthcare LLMs](http://arxiv.org/abs/2505.04388v2)** | 2025-05-28 | <details><summary>Follo...</summary><p>Follow-up work from arXiv:2405.01886</p></details> |
| **[Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing](http://arxiv.org/abs/2505.22298v1)** | 2025-05-28 | ACL 2025 Findings |
| **[Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](http://arxiv.org/abs/2502.19041v2)** | 2025-05-28 | <details><summary>16 pa...</summary><p>16 pages, 12 figures, ACL 2025 findings</p></details> |
| **[MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](http://arxiv.org/abs/2505.20824v1)** | 2025-05-27 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v4)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models](http://arxiv.org/abs/2505.23561v1)** | 2025-05-29 | <details><summary>This ...</summary><p>This paper is accepted by ACL 2025 main conference</p></details> |
| **[SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures](http://arxiv.org/abs/2410.14667v2)** | 2025-05-29 |  |
| **[Hijacking Large Language Models via Adversarial In-Context Learning](http://arxiv.org/abs/2311.09948v3)** | 2025-05-29 |  |
| **[Learning to Poison Large Language Models for Downstream Manipulation](http://arxiv.org/abs/2402.13459v3)** | 2025-05-29 |  |
| **[Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models](http://arxiv.org/abs/2412.16555v3)** | 2025-05-29 |  |
| **[DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](http://arxiv.org/abs/2502.11647v2)** | 2025-05-29 |  |
| **[Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates](http://arxiv.org/abs/2402.17390v2)** | 2025-05-29 |  |
| **[Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models](http://arxiv.org/abs/2505.23404v1)** | 2025-05-29 |  |
| **[Dimension-Reduction Attack! Video Generative Models are Experts on Controllable Image Synthesis](http://arxiv.org/abs/2505.23325v1)** | 2025-05-29 |  |
| **[Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction](http://arxiv.org/abs/2502.17541v2)** | 2025-05-29 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models](http://arxiv.org/abs/2505.23561v1)** | 2025-05-29 | <details><summary>This ...</summary><p>This paper is accepted by ACL 2025 main conference</p></details> |
| **[SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures](http://arxiv.org/abs/2410.14667v2)** | 2025-05-29 |  |
| **[Hijacking Large Language Models via Adversarial In-Context Learning](http://arxiv.org/abs/2311.09948v3)** | 2025-05-29 |  |
| **[Learning to Poison Large Language Models for Downstream Manipulation](http://arxiv.org/abs/2402.13459v3)** | 2025-05-29 |  |
| **[Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models](http://arxiv.org/abs/2412.16555v3)** | 2025-05-29 |  |
| **[DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](http://arxiv.org/abs/2502.11647v2)** | 2025-05-29 |  |
| **[Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates](http://arxiv.org/abs/2402.17390v2)** | 2025-05-29 |  |
| **[Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models](http://arxiv.org/abs/2505.23404v1)** | 2025-05-29 |  |
| **[Dimension-Reduction Attack! Video Generative Models are Experts on Controllable Image Synthesis](http://arxiv.org/abs/2505.23325v1)** | 2025-05-29 |  |
| **[Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction](http://arxiv.org/abs/2502.17541v2)** | 2025-05-29 |  |

