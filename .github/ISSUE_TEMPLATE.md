---
title: Latest 15 Papers - July 02, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v3)** | 2025-06-29 |  |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](http://arxiv.org/abs/2506.23260v1)** | 2025-06-29 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, 6 tables</p></details> |
| **[Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation](http://arxiv.org/abs/2506.23034v1)** | 2025-06-28 |  |
| **[Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](http://arxiv.org/abs/2506.22776v1)** | 2025-06-28 | 13 pages, 6 figures |
| **[MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs](http://arxiv.org/abs/2506.22557v1)** | 2025-06-27 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v3)** | 2025-06-27 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v3)** | 2025-06-27 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](http://arxiv.org/abs/2412.02113v2)** | 2025-06-30 | 11 pages |
| **[TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](http://arxiv.org/abs/2506.23423v1)** | 2025-06-29 | ICML 2025 |
| **[GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs](http://arxiv.org/abs/2411.13757v3)** | 2025-06-29 |  |
| **[From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](http://arxiv.org/abs/2506.23260v1)** | 2025-06-29 | <details><summary>29 pa...</summary><p>29 pages, 15 figures, 6 tables</p></details> |
| **[Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation](http://arxiv.org/abs/2506.23034v1)** | 2025-06-28 |  |
| **[Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](http://arxiv.org/abs/2506.22776v1)** | 2025-06-28 | 13 pages, 6 figures |
| **[MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs](http://arxiv.org/abs/2506.22557v1)** | 2025-06-27 |  |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v3)** | 2025-06-27 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v3)** | 2025-06-27 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](http://arxiv.org/abs/2506.24056v1)** | 2025-06-30 |  |
| **[Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures](http://arxiv.org/abs/2506.23622v1)** | 2025-06-30 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v1)** | 2025-06-30 |  |
| **[Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](http://arxiv.org/abs/2506.23576v1)** | 2025-06-30 | 26 pages, 1 figure |
| **[Automating Adjudication of Cardiovascular Events Using Large Language Models](http://arxiv.org/abs/2503.17222v2)** | 2025-06-29 |  |
| **[MedLeak: Multimodal Medical Data Leakage in Secure Federated Learning with Crafted Models](http://arxiv.org/abs/2407.09972v2)** | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted by the IEEE/ACM conference on Connected Health: Applications, Systems and Engineering Technologies 2025 (CHASE'25)</p></details> |
| **[Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy](http://arxiv.org/abs/2503.07661v2)** | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[KeTS: Kernel-based Trust Segmentation against Model Poisoning Attacks](http://arxiv.org/abs/2501.06729v2)** | 2025-06-29 |  |
| **[Efficient malicious information detection method based on set partitioning for large-scale Internet of Things](http://arxiv.org/abs/2502.11538v2)** | 2025-06-29 | 21 pages, 5 figures |
| **[Learning Counterfactually Decoupled Attention for Open-World Model Attribution](http://arxiv.org/abs/2506.23074v1)** | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025. Code: \url{https://github.com/yzheng97/CDAL}</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](http://arxiv.org/abs/2506.24056v1)** | 2025-06-30 |  |
| **[Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures](http://arxiv.org/abs/2506.23622v1)** | 2025-06-30 |  |
| **[SoK: Semantic Privacy in Large Language Models](http://arxiv.org/abs/2506.23603v1)** | 2025-06-30 |  |
| **[Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](http://arxiv.org/abs/2506.23576v1)** | 2025-06-30 | 26 pages, 1 figure |
| **[Automating Adjudication of Cardiovascular Events Using Large Language Models](http://arxiv.org/abs/2503.17222v2)** | 2025-06-29 |  |
| **[MedLeak: Multimodal Medical Data Leakage in Secure Federated Learning with Crafted Models](http://arxiv.org/abs/2407.09972v2)** | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted by the IEEE/ACM conference on Connected Health: Applications, Systems and Engineering Technologies 2025 (CHASE'25)</p></details> |
| **[Towards Generalized and Stealthy Watermarking for Generative Code Models](http://arxiv.org/abs/2506.20926v2)** | 2025-06-29 | 13 pages |
| **[Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy](http://arxiv.org/abs/2503.07661v2)** | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted by ICCV 2025</p></details> |
| **[KeTS: Kernel-based Trust Segmentation against Model Poisoning Attacks](http://arxiv.org/abs/2501.06729v2)** | 2025-06-29 |  |
| **[Efficient malicious information detection method based on set partitioning for large-scale Internet of Things](http://arxiv.org/abs/2502.11538v2)** | 2025-06-29 | 21 pages, 5 figures |

