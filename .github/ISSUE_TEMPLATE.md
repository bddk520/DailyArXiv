---
title: Latest 15 Papers - April 04, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer](http://arxiv.org/abs/2408.11313v2)** | 2025-04-02 | <details><summary>Be ac...</summary><p>Be accepeted as NAACL2025 Findings</p></details> |
| **[Multilingual and Multi-Accent Jailbreaking of Audio LLMs](http://arxiv.org/abs/2504.01094v1)** | 2025-04-01 | <details><summary>21 pa...</summary><p>21 pages, 6 figures, 15 tables</p></details> |
| **[Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments](http://arxiv.org/abs/2504.00341v1)** | 2025-04-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in the IEEE 2025 International Conference on Communications (ICC2025)</p></details> |
| **[$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](http://arxiv.org/abs/2504.00218v1)** | 2025-03-31 |  |
| **[Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms](http://arxiv.org/abs/2503.24191v1)** | 2025-03-31 | <details><summary>15 pa...</summary><p>15 pages, 13 figures, 4 tables Work In Progress</p></details> |
| **[Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions](http://arxiv.org/abs/2503.23250v1)** | 2025-03-29 |  |
| **[Foot-In-The-Door: A Multi-turn Jailbreak for LLMs](http://arxiv.org/abs/2502.19820v3)** | 2025-03-28 | 19 pages, 8 figures |
| **[Debate-Driven Multi-Agent LLMs for Phishing Email Detection](http://arxiv.org/abs/2503.22038v1)** | 2025-03-27 | <details><summary>Accep...</summary><p>Accepted to the 13th International Symposium on Digital Forensics and Security (ISDFS 2025)</p></details> |
| **[Learning to Lie: Reinforcement Learning Attacks Damage Human-AI Teams and Teams of LLMs](http://arxiv.org/abs/2503.21983v1)** | 2025-03-27 | <details><summary>17 pa...</summary><p>17 pages, 9 figures, accepted to ICLR 2025 Workshop on Human-AI Coevolution</p></details> |
| **[TeleLoRA: Teleporting Model-Specific Alignment Across LLMs](http://arxiv.org/abs/2503.20228v1)** | 2025-03-26 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer](http://arxiv.org/abs/2408.11313v2)** | 2025-04-02 | <details><summary>Be ac...</summary><p>Be accepeted as NAACL2025 Findings</p></details> |
| **[Multilingual and Multi-Accent Jailbreaking of Audio LLMs](http://arxiv.org/abs/2504.01094v1)** | 2025-04-01 | <details><summary>21 pa...</summary><p>21 pages, 6 figures, 15 tables</p></details> |
| **[Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments](http://arxiv.org/abs/2504.00341v1)** | 2025-04-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in the IEEE 2025 International Conference on Communications (ICC2025)</p></details> |
| **[$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](http://arxiv.org/abs/2504.00218v1)** | 2025-03-31 |  |
| **[Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms](http://arxiv.org/abs/2503.24191v1)** | 2025-03-31 | <details><summary>15 pa...</summary><p>15 pages, 13 figures, 4 tables Work In Progress</p></details> |
| **[Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions](http://arxiv.org/abs/2503.23250v1)** | 2025-03-29 |  |
| **[Foot-In-The-Door: A Multi-turn Jailbreak for LLMs](http://arxiv.org/abs/2502.19820v3)** | 2025-03-28 | 19 pages, 8 figures |
| **[Debate-Driven Multi-Agent LLMs for Phishing Email Detection](http://arxiv.org/abs/2503.22038v1)** | 2025-03-27 | <details><summary>Accep...</summary><p>Accepted to the 13th International Symposium on Digital Forensics and Security (ISDFS 2025)</p></details> |
| **[Learning to Lie: Reinforcement Learning Attacks Damage Human-AI Teams and Teams of LLMs](http://arxiv.org/abs/2503.21983v1)** | 2025-03-27 | <details><summary>17 pa...</summary><p>17 pages, 9 figures, accepted to ICLR 2025 Workshop on Human-AI Coevolution</p></details> |
| **[TeleLoRA: Teleporting Model-Specific Alignment Across LLMs](http://arxiv.org/abs/2503.20228v1)** | 2025-03-26 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Implicit Bias Injection Attacks against Text-to-Image Diffusion Models](http://arxiv.org/abs/2504.01819v1)** | 2025-04-02 | Accept to CVPR 2025 |
| **[AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization](http://arxiv.org/abs/2504.01735v1)** | 2025-04-02 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v1)** | 2025-04-02 |  |
| **[PiCo: Jailbreaking Multimodal Large Language Models via $\textbf{Pi}$ctorial $\textbf{Co}$de Contextualization](http://arxiv.org/abs/2504.01444v1)** | 2025-04-02 |  |
| **[STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models](http://arxiv.org/abs/2408.16807v2)** | 2025-04-02 | <details><summary>Accep...</summary><p>Accepted to CVPR-2025. Code: https://github.com/koushiksrivats/robust-concept-erasing</p></details> |
| **[Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks](http://arxiv.org/abs/2504.01308v1)** | 2025-04-02 |  |
| **[Efficient State Estimation of a Networked FlipIt Model](http://arxiv.org/abs/2504.01096v1)** | 2025-04-01 |  |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v1)** | 2025-04-01 |  |
| **[Exposing the Ghost in the Transformer: Abnormal Detection for Large Language Models via Hidden State Forensics](http://arxiv.org/abs/2504.00446v1)** | 2025-04-01 |  |
| **[Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks](http://arxiv.org/abs/2408.15207v3)** | 2025-04-01 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Implicit Bias Injection Attacks against Text-to-Image Diffusion Models](http://arxiv.org/abs/2504.01819v1)** | 2025-04-02 | Accept to CVPR 2025 |
| **[AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization](http://arxiv.org/abs/2504.01735v1)** | 2025-04-02 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v1)** | 2025-04-02 |  |
| **[PiCo: Jailbreaking Multimodal Large Language Models via $\textbf{Pi}$ctorial $\textbf{Co}$de Contextualization](http://arxiv.org/abs/2504.01444v1)** | 2025-04-02 |  |
| **[STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models](http://arxiv.org/abs/2408.16807v2)** | 2025-04-02 | <details><summary>Accep...</summary><p>Accepted to CVPR-2025. Code: https://github.com/koushiksrivats/robust-concept-erasing</p></details> |
| **[Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks](http://arxiv.org/abs/2504.01308v1)** | 2025-04-02 |  |
| **[Efficient State Estimation of a Networked FlipIt Model](http://arxiv.org/abs/2504.01096v1)** | 2025-04-01 |  |
| **[Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models](http://arxiv.org/abs/2504.00638v1)** | 2025-04-01 |  |
| **[Exposing the Ghost in the Transformer: Abnormal Detection for Large Language Models via Hidden State Forensics](http://arxiv.org/abs/2504.00446v1)** | 2025-04-01 |  |
| **[Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks](http://arxiv.org/abs/2408.15207v3)** | 2025-04-01 |  |

