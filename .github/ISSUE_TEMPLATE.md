---
title: Latest 15 Papers - November 06, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |
| **[On The Dangers of Poisoned LLMs In Security Automation](http://arxiv.org/abs/2511.02600v1)** | 2025-11-04 | 5 pages, 1 figure |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v5)** | 2025-11-04 |  |
| **[An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks](http://arxiv.org/abs/2511.02356v1)** | 2025-11-04 |  |
| **[Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks](http://arxiv.org/abs/2511.01746v1)** | 2025-11-03 | 8 pages |
| **[Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges](http://arxiv.org/abs/2511.01375v1)** | 2025-11-03 | <details><summary>under...</summary><p>under review, 28 pages</p></details> |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](http://arxiv.org/abs/2510.10987v2)** | 2025-11-03 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, preprint</p></details> |
| **[ShadowLogic: Backdoors in Any Whitebox LLM](http://arxiv.org/abs/2511.00664v1)** | 2025-11-01 |  |
| **[SLIP: Securing LLMs IP Using Weights Decomposition](http://arxiv.org/abs/2407.10886v3)** | 2025-11-01 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v3)** | 2025-11-01 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |
| **[On The Dangers of Poisoned LLMs In Security Automation](http://arxiv.org/abs/2511.02600v1)** | 2025-11-04 | 5 pages, 1 figure |
| **[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v5)** | 2025-11-04 |  |
| **[An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks](http://arxiv.org/abs/2511.02356v1)** | 2025-11-04 |  |
| **[Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks](http://arxiv.org/abs/2511.01746v1)** | 2025-11-03 | 8 pages |
| **[Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges](http://arxiv.org/abs/2511.01375v1)** | 2025-11-03 | <details><summary>under...</summary><p>under review, 28 pages</p></details> |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](http://arxiv.org/abs/2510.10987v2)** | 2025-11-03 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, preprint</p></details> |
| **[ShadowLogic: Backdoors in Any Whitebox LLM](http://arxiv.org/abs/2511.00664v1)** | 2025-11-01 |  |
| **[SLIP: Securing LLMs IP Using Weights Decomposition](http://arxiv.org/abs/2407.10886v3)** | 2025-11-01 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v3)** | 2025-11-01 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning](http://arxiv.org/abs/2511.02797v1)** | 2025-11-04 |  |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |
| **[Verifying LLM Inference to Prevent Model Weight Exfiltration](http://arxiv.org/abs/2511.02620v1)** | 2025-11-04 |  |
| **[AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](http://arxiv.org/abs/2511.02376v1)** | 2025-11-04 |  |
| **[Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks](http://arxiv.org/abs/2511.01746v1)** | 2025-11-03 | 8 pages |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v2)** | 2025-11-03 |  |
| **[Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models](http://arxiv.org/abs/2511.01634v1)** | 2025-11-03 | 10 pages, 6 figures |
| **[A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model](http://arxiv.org/abs/2511.01317v1)** | 2025-11-03 | 18 pages, 3 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning](http://arxiv.org/abs/2511.02797v1)** | 2025-11-04 |  |
| **[Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning](http://arxiv.org/abs/2412.10924v8)** | 2025-11-04 |  |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |
| **[Verifying LLM Inference to Prevent Model Weight Exfiltration](http://arxiv.org/abs/2511.02620v1)** | 2025-11-04 |  |
| **[AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](http://arxiv.org/abs/2511.02376v1)** | 2025-11-04 |  |
| **[Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks](http://arxiv.org/abs/2511.01746v1)** | 2025-11-03 | 8 pages |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v2)** | 2025-11-03 |  |
| **[Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models](http://arxiv.org/abs/2511.01634v1)** | 2025-11-03 | 10 pages, 6 figures |

