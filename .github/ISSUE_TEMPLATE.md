---
title: Latest 15 Papers - February 18, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v1)** | 2026-02-16 |  |
| **[SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations](https://arxiv.org/abs/2510.04398v3)** | 2026-02-15 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025. Code is available at https://github.com/Buyun-Liang/SECA</p></details> |
| **[The Rogue Scalpel: Activation Steering Compromises LLM Safety](https://arxiv.org/abs/2509.22067v2)** | 2026-02-15 |  |
| **[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](https://arxiv.org/abs/2502.16730v2)** | 2026-02-14 |  |
| **[Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410v2)** | 2026-02-14 |  |
| **[Rubrics as an Attack Surface: Stealthy Preference Drift in LLM Judges](https://arxiv.org/abs/2602.13576v1)** | 2026-02-14 |  |
| **[SecureGate: Learning When to Reveal PII Safely via Token-Gated Dual-Adapters for Federated LLMs](https://arxiv.org/abs/2602.13529v1)** | 2026-02-13 |  |
| **[GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042v1)** | 2026-02-13 |  |
| **[Sparse Autoencoders are Capable LLM Jailbreak Mitigators](https://arxiv.org/abs/2602.12418v1)** | 2026-02-12 | <details><summary>26 pa...</summary><p>26 pages, 14 figures, 3 tables</p></details> |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](https://arxiv.org/abs/2503.03704v5)** | 2026-02-12 | Code released |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v1)** | 2026-02-16 |  |
| **[SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations](https://arxiv.org/abs/2510.04398v3)** | 2026-02-15 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025. Code is available at https://github.com/Buyun-Liang/SECA</p></details> |
| **[The Rogue Scalpel: Activation Steering Compromises LLM Safety](https://arxiv.org/abs/2509.22067v2)** | 2026-02-15 |  |
| **[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](https://arxiv.org/abs/2502.16730v2)** | 2026-02-14 |  |
| **[Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410v2)** | 2026-02-14 |  |
| **[Rubrics as an Attack Surface: Stealthy Preference Drift in LLM Judges](https://arxiv.org/abs/2602.13576v1)** | 2026-02-14 |  |
| **[SecureGate: Learning When to Reveal PII Safely via Token-Gated Dual-Adapters for Federated LLMs](https://arxiv.org/abs/2602.13529v1)** | 2026-02-13 |  |
| **[GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042v1)** | 2026-02-13 |  |
| **[Sparse Autoencoders are Capable LLM Jailbreak Mitigators](https://arxiv.org/abs/2602.12418v1)** | 2026-02-12 | <details><summary>26 pa...</summary><p>26 pages, 14 figures, 3 tables</p></details> |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](https://arxiv.org/abs/2503.03704v5)** | 2026-02-12 | Code released |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol](https://arxiv.org/abs/2512.14166v2)** | 2026-02-16 | 14 pages, 6 figures |
| **[AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises](https://arxiv.org/abs/2602.14740v1)** | 2026-02-16 | <details><summary>45 pa...</summary><p>45 pages, 6 figures, 27 tables</p></details> |
| **[Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks](https://arxiv.org/abs/2602.14689v1)** | 2026-02-16 | <details><summary>54 pa...</summary><p>54 pages, 7 figures, 35 tables</p></details> |
| **[Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models](https://arxiv.org/abs/2602.14399v1)** | 2026-02-16 |  |
| **[Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093v2)** | 2026-02-16 |  |
| **[Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning](https://arxiv.org/abs/2507.07139v2)** | 2026-02-16 | <details><summary>Accep...</summary><p>Accepted by ICLR 2026</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v1)** | 2026-02-15 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[Anticipating Adversary Behavior in DevSecOps Scenarios through Large Language Models](https://arxiv.org/abs/2602.14106v1)** | 2026-02-15 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, paper in proceedings of the X National Cybersecurity Research Conference (JNIC) in Zaragoza, Spain, June, 2025</p></details> |
| **[EVALOOOP: A Self-Consistency-Centered Framework for Assessing Large Language Model Robustness in Programming](https://arxiv.org/abs/2505.12185v5)** | 2026-02-15 | 27 pages, 7 figures |
| **[Learning-Based Automated Adversarial Red-Teaming for Robustness Evaluation of Large Language Models](https://arxiv.org/abs/2512.20677v3)** | 2026-02-14 | accepted by EACL |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol](https://arxiv.org/abs/2512.14166v2)** | 2026-02-16 | 14 pages, 6 figures |
| **[AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises](https://arxiv.org/abs/2602.14740v1)** | 2026-02-16 | <details><summary>45 pa...</summary><p>45 pages, 6 figures, 27 tables</p></details> |
| **[Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks](https://arxiv.org/abs/2602.14689v1)** | 2026-02-16 | <details><summary>54 pa...</summary><p>54 pages, 7 figures, 35 tables</p></details> |
| **[Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models](https://arxiv.org/abs/2602.14399v1)** | 2026-02-16 |  |
| **[Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093v2)** | 2026-02-16 |  |
| **[Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack against Image Generation Model Unlearning](https://arxiv.org/abs/2507.07139v2)** | 2026-02-16 | <details><summary>Accep...</summary><p>Accepted by ICLR 2026</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v1)** | 2026-02-15 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[Anticipating Adversary Behavior in DevSecOps Scenarios through Large Language Models](https://arxiv.org/abs/2602.14106v1)** | 2026-02-15 | <details><summary>8 pag...</summary><p>8 pages, 3 figures, paper in proceedings of the X National Cybersecurity Research Conference (JNIC) in Zaragoza, Spain, June, 2025</p></details> |
| **[EVALOOOP: A Self-Consistency-Centered Framework for Assessing Large Language Model Robustness in Programming](https://arxiv.org/abs/2505.12185v5)** | 2026-02-15 | 27 pages, 7 figures |
| **[Learning-Based Automated Adversarial Red-Teaming for Robustness Evaluation of Large Language Models](https://arxiv.org/abs/2512.20677v3)** | 2026-02-14 | accepted by EACL |

