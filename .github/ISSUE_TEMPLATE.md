---
title: Latest 15 Papers - July 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v1)** | 2025-07-11 |  |
| **[The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v3)** | 2025-07-11 |  |
| **[Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection](http://arxiv.org/abs/2411.01077v4)** | 2025-07-11 |  |
| **[A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](http://arxiv.org/abs/2507.08207v1)** | 2025-07-10 |  |
| **[Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)](http://arxiv.org/abs/2407.14937v2)** | 2025-07-10 | <details><summary>Trans...</summary><p>Transactions of Machine Learning Research (TMLR)</p></details> |
| **[Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](http://arxiv.org/abs/2507.07413v1)** | 2025-07-10 | <details><summary>6 pag...</summary><p>6 pages, IEEE conference</p></details> |
| **[Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](http://arxiv.org/abs/2507.07406v1)** | 2025-07-10 | <details><summary>8 Pag...</summary><p>8 Pages, IEEE Conference</p></details> |
| **[GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods](http://arxiv.org/abs/2502.16903v2)** | 2025-07-09 | <details><summary>Homep...</summary><p>Homepage: https://sproutnan.github.io/AI-Safety_Benchmark/</p></details> |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v2)** | 2025-07-09 |  |
| **[An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs](http://arxiv.org/abs/2507.07146v1)** | 2025-07-09 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1](http://arxiv.org/abs/2507.08621v1)** | 2025-07-11 |  |
| **[The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v3)** | 2025-07-11 |  |
| **[Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection](http://arxiv.org/abs/2411.01077v4)** | 2025-07-11 |  |
| **[A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](http://arxiv.org/abs/2507.08207v1)** | 2025-07-10 |  |
| **[Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)](http://arxiv.org/abs/2407.14937v2)** | 2025-07-10 | <details><summary>Trans...</summary><p>Transactions of Machine Learning Research (TMLR)</p></details> |
| **[Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks](http://arxiv.org/abs/2507.07413v1)** | 2025-07-10 | <details><summary>6 pag...</summary><p>6 pages, IEEE conference</p></details> |
| **[Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models](http://arxiv.org/abs/2507.07406v1)** | 2025-07-10 | <details><summary>8 Pag...</summary><p>8 Pages, IEEE Conference</p></details> |
| **[GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods](http://arxiv.org/abs/2502.16903v2)** | 2025-07-09 | <details><summary>Homep...</summary><p>Homepage: https://sproutnan.github.io/AI-Safety_Benchmark/</p></details> |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v2)** | 2025-07-09 |  |
| **[An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs](http://arxiv.org/abs/2507.07146v1)** | 2025-07-09 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MLAAD: The Multi-Language Audio Anti-Spoofing Dataset](http://arxiv.org/abs/2401.09512v7)** | 2025-07-11 | IJCNN 2024 |
| **[Weak-to-Strong Jailbreaking on Large Language Models](http://arxiv.org/abs/2401.17256v4)** | 2025-07-11 | ICML 2025 |
| **[Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security](http://arxiv.org/abs/2507.08623v1)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted for publication at IEEE International Conference on Quantum Computing and Engineering (QCE) 2025</p></details> |
| **[Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective](http://arxiv.org/abs/2406.14023v5)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 Findings</p></details> |
| **[Invariant-based Robust Weights Watermark for Large Language Models](http://arxiv.org/abs/2507.08288v1)** | 2025-07-11 |  |
| **[Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)](http://arxiv.org/abs/2407.14937v2)** | 2025-07-10 | <details><summary>Trans...</summary><p>Transactions of Machine Learning Research (TMLR)</p></details> |
| **[Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study](http://arxiv.org/abs/2505.19598v2)** | 2025-07-10 |  |
| **[Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](http://arxiv.org/abs/2507.07871v1)** | 2025-07-10 |  |
| **["I am bad": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models](http://arxiv.org/abs/2502.00718v2)** | 2025-07-10 |  |
| **[GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](http://arxiv.org/abs/2507.07735v1)** | 2025-07-10 | 24 pages |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MLAAD: The Multi-Language Audio Anti-Spoofing Dataset](http://arxiv.org/abs/2401.09512v7)** | 2025-07-11 | IJCNN 2024 |
| **[Weak-to-Strong Jailbreaking on Large Language Models](http://arxiv.org/abs/2401.17256v4)** | 2025-07-11 | ICML 2025 |
| **[Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security](http://arxiv.org/abs/2507.08623v1)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted for publication at IEEE International Conference on Quantum Computing and Engineering (QCE) 2025</p></details> |
| **[Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective](http://arxiv.org/abs/2406.14023v5)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 Findings</p></details> |
| **[Invariant-based Robust Weights Watermark for Large Language Models](http://arxiv.org/abs/2507.08288v1)** | 2025-07-11 |  |
| **[Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)](http://arxiv.org/abs/2407.14937v2)** | 2025-07-10 | <details><summary>Trans...</summary><p>Transactions of Machine Learning Research (TMLR)</p></details> |
| **[Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study](http://arxiv.org/abs/2505.19598v2)** | 2025-07-10 |  |
| **[Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](http://arxiv.org/abs/2507.07871v1)** | 2025-07-10 |  |
| **["I am bad": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models](http://arxiv.org/abs/2502.00718v2)** | 2025-07-10 |  |
| **[GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing](http://arxiv.org/abs/2507.07735v1)** | 2025-07-10 | 24 pages |

