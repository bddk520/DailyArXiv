---
title: Latest 15 Papers - October 07, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v2)** | 2025-10-03 |  |
| **[Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs](http://arxiv.org/abs/2510.02833v1)** | 2025-10-03 |  |
| **[XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](http://arxiv.org/abs/2504.21700v2)** | 2025-10-03 |  |
| **[MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols](http://arxiv.org/abs/2510.02694v1)** | 2025-10-03 |  |
| **[ToolTweak: An Attack on Tool Selection in LLM-based Agents](http://arxiv.org/abs/2510.02554v1)** | 2025-10-02 |  |
| **[Detecting Post-generation Edits to Watermarked LLM Outputs via Combinatorial Watermarking](http://arxiv.org/abs/2510.01637v1)** | 2025-10-02 |  |
| **[Defend LLMs Through Self-Consciousness](http://arxiv.org/abs/2508.02961v2)** | 2025-10-01 | <details><summary>compa...</summary><p>company requests to withdraw</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](http://arxiv.org/abs/2509.14285v2)** | 2025-10-01 | <details><summary>IEEE ...</summary><p>IEEE Conference standard paper</p></details> |
| **[Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense](http://arxiv.org/abs/2510.01088v1)** | 2025-10-01 |  |
| **[LLM Watermark Evasion via Bias Inversion](http://arxiv.org/abs/2509.23019v2)** | 2025-10-01 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Permissioned LLMs: Enforcing Access Control in Large Language Models](http://arxiv.org/abs/2505.22860v2)** | 2025-10-03 |  |
| **[Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs](http://arxiv.org/abs/2510.02833v1)** | 2025-10-03 |  |
| **[XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](http://arxiv.org/abs/2504.21700v2)** | 2025-10-03 |  |
| **[MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols](http://arxiv.org/abs/2510.02694v1)** | 2025-10-03 |  |
| **[ToolTweak: An Attack on Tool Selection in LLM-based Agents](http://arxiv.org/abs/2510.02554v1)** | 2025-10-02 |  |
| **[Detecting Post-generation Edits to Watermarked LLM Outputs via Combinatorial Watermarking](http://arxiv.org/abs/2510.01637v1)** | 2025-10-02 |  |
| **[Defend LLMs Through Self-Consciousness](http://arxiv.org/abs/2508.02961v2)** | 2025-10-01 | <details><summary>compa...</summary><p>company requests to withdraw</p></details> |
| **[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](http://arxiv.org/abs/2509.14285v2)** | 2025-10-01 | <details><summary>IEEE ...</summary><p>IEEE Conference standard paper</p></details> |
| **[Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense](http://arxiv.org/abs/2510.01088v1)** | 2025-10-01 |  |
| **[LLM Watermark Evasion via Bias Inversion](http://arxiv.org/abs/2509.23019v2)** | 2025-10-01 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents](http://arxiv.org/abs/2510.03204v1)** | 2025-10-03 |  |
| **[External Data Extraction Attacks against Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2510.02964v1)** | 2025-10-03 |  |
| **[Leave No TRACE: Black-box Detection of Copyrighted Dataset Usage in Large Language Models via Watermarking](http://arxiv.org/abs/2510.02962v1)** | 2025-10-03 |  |
| **[Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting](http://arxiv.org/abs/2510.02913v1)** | 2025-10-03 | <details><summary>Accep...</summary><p>Accepted to the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[Diffusion-aided Task-oriented Semantic Communications with Model Inversion Attack](http://arxiv.org/abs/2506.19886v2)** | 2025-10-03 |  |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](http://arxiv.org/abs/2510.02712v1)** | 2025-10-03 |  |
| **[JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models](http://arxiv.org/abs/2505.17568v2)** | 2025-10-03 |  |
| **[ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks](http://arxiv.org/abs/2510.02677v1)** | 2025-10-03 | 60 pages, 16 figures |
| **[PrisonBreak: Jailbreaking Large Language Models with at Most Twenty-Five Targeted Bit-flips](http://arxiv.org/abs/2412.07192v3)** | 2025-10-02 | Pre-print |
| **[Rigorous Evaluation of Microarchitectural Side-Channels with Statistical Model Checking](http://arxiv.org/abs/2510.02475v1)** | 2025-10-02 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents](http://arxiv.org/abs/2510.03204v1)** | 2025-10-03 |  |
| **[External Data Extraction Attacks against Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2510.02964v1)** | 2025-10-03 |  |
| **[Leave No TRACE: Black-box Detection of Copyrighted Dataset Usage in Large Language Models via Watermarking](http://arxiv.org/abs/2510.02962v1)** | 2025-10-03 |  |
| **[Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting](http://arxiv.org/abs/2510.02913v1)** | 2025-10-03 | <details><summary>Accep...</summary><p>Accepted to the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[Diffusion-aided Task-oriented Semantic Communications with Model Inversion Attack](http://arxiv.org/abs/2506.19886v2)** | 2025-10-03 |  |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](http://arxiv.org/abs/2510.02712v1)** | 2025-10-03 |  |
| **[JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models](http://arxiv.org/abs/2505.17568v2)** | 2025-10-03 |  |
| **[ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks](http://arxiv.org/abs/2510.02677v1)** | 2025-10-03 | 60 pages, 16 figures |
| **[PrisonBreak: Jailbreaking Large Language Models with at Most Twenty-Five Targeted Bit-flips](http://arxiv.org/abs/2412.07192v3)** | 2025-10-02 | Pre-print |
| **[Rigorous Evaluation of Microarchitectural Side-Channels with Statistical Model Checking](http://arxiv.org/abs/2510.02475v1)** | 2025-10-02 |  |

