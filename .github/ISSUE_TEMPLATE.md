---
title: Latest 15 Papers - October 29, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fast-MIA: Efficient and Scalable Membership Inference for LLMs](http://arxiv.org/abs/2510.23074v1)** | 2025-10-27 |  |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v1)** | 2025-10-27 |  |
| **[Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628v1)** | 2025-10-26 | <details><summary>11 pa...</summary><p>11 pages, 5 figures. Preprint version under review in the area of Artificial Intelligence (cs.AI)</p></details> |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](http://arxiv.org/abs/2510.22620v1)** | 2025-10-26 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](http://arxiv.org/abs/2510.19462v2)** | 2025-10-25 |  |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](http://arxiv.org/abs/2503.03704v3)** | 2025-10-24 |  |
| **[Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](http://arxiv.org/abs/2510.21983v1)** | 2025-10-24 |  |
| **[$δ$-STEAL: LLM Stealing Attack with Local Differential Privacy](http://arxiv.org/abs/2510.21946v1)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted at ACML 2025 (PMLR W&CP). Code: https://github.com/kirudang/LDP_Stealing_Attack</p></details> |
| **[Detecting Various DeFi Price Manipulations with LLM Reasoning](http://arxiv.org/abs/2502.11521v2)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted by ASE 2025. Please cite the conference version of this paper, e.g., "Juantao Zhong, Daoyuan Wu, Ye Liu, Maoyi Xie, Yang Liu, Yi Li, Ning Liu. Detecting Various DeFi Price Manipulations with LLM Reasoning. In 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)"</p></details> |
| **[SBASH: a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM Honeypots](http://arxiv.org/abs/2510.21459v1)** | 2025-10-24 | <details><summary>to be...</summary><p>to be published in: The 3rd International Conference on Foundation and Large Language Models (FLLM2025), IEEE, 2025</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fast-MIA: Efficient and Scalable Membership Inference for LLMs](http://arxiv.org/abs/2510.23074v1)** | 2025-10-27 |  |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v1)** | 2025-10-27 |  |
| **[Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628v1)** | 2025-10-26 | <details><summary>11 pa...</summary><p>11 pages, 5 figures. Preprint version under review in the area of Artificial Intelligence (cs.AI)</p></details> |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](http://arxiv.org/abs/2510.22620v1)** | 2025-10-26 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](http://arxiv.org/abs/2510.19462v2)** | 2025-10-25 |  |
| **[Memory Injection Attacks on LLM Agents via Query-Only Interaction](http://arxiv.org/abs/2503.03704v3)** | 2025-10-24 |  |
| **[Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](http://arxiv.org/abs/2510.21983v1)** | 2025-10-24 |  |
| **[$δ$-STEAL: LLM Stealing Attack with Local Differential Privacy](http://arxiv.org/abs/2510.21946v1)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted at ACML 2025 (PMLR W&CP). Code: https://github.com/kirudang/LDP_Stealing_Attack</p></details> |
| **[Detecting Various DeFi Price Manipulations with LLM Reasoning](http://arxiv.org/abs/2502.11521v2)** | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted by ASE 2025. Please cite the conference version of this paper, e.g., "Juantao Zhong, Daoyuan Wu, Ye Liu, Maoyi Xie, Yang Liu, Yi Li, Ning Liu. Detecting Various DeFi Price Manipulations with LLM Reasoning. In 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)"</p></details> |
| **[SBASH: a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM Honeypots](http://arxiv.org/abs/2510.21459v1)** | 2025-10-24 | <details><summary>to be...</summary><p>to be published in: The 3rd International Conference on Foundation and Large Language Models (FLLM2025), IEEE, 2025</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Attention! Your Vision Language Model Could Be Maliciously Manipulated](http://arxiv.org/abs/2505.19911v2)** | 2025-10-27 | NeurIPS 2025 |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v3)** | 2025-10-27 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |
| **[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](http://arxiv.org/abs/2509.11173v3)** | 2025-10-27 | <details><summary>This ...</summary><p>This paper is accepted to IEEE S&P 2026, the code is available at https://github.com/SeekingDream/DLCompilerAttack</p></details> |
| **[Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models](http://arxiv.org/abs/2510.22785v1)** | 2025-10-26 |  |
| **[Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing](http://arxiv.org/abs/2504.05657v2)** | 2025-10-26 | <details><summary>Accep...</summary><p>Accepted to IEEE Transactions on Information Forensics and Security</p></details> |
| **[OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](http://arxiv.org/abs/2510.22535v1)** | 2025-10-26 |  |
| **[CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models](http://arxiv.org/abs/2507.22828v3)** | 2025-10-25 | <details><summary>9 pag...</summary><p>9 pages, accepted by the 2025 ACM Multimedia Conference. Code is available at https://jus1mple.github.io/Image2CaptionAttack</p></details> |
| **[T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model](http://arxiv.org/abs/2510.22300v1)** | 2025-10-25 | AAAI under review |
| **[A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](http://arxiv.org/abs/2503.10635v2)** | 2025-10-25 | <details><summary>NeurI...</summary><p>NeurIPS 2025. Code at: https://github.com/VILA-Lab/M-Attack</p></details> |
| **[Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for Large Language Models](http://arxiv.org/abs/2510.22085v1)** | 2025-10-24 | 18 pages, 5 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Attention! Your Vision Language Model Could Be Maliciously Manipulated](http://arxiv.org/abs/2505.19911v2)** | 2025-10-27 | NeurIPS 2025 |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v3)** | 2025-10-27 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |
| **[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](http://arxiv.org/abs/2509.11173v3)** | 2025-10-27 | <details><summary>This ...</summary><p>This paper is accepted to IEEE S&P 2026, the code is available at https://github.com/SeekingDream/DLCompilerAttack</p></details> |
| **[Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models](http://arxiv.org/abs/2510.22785v1)** | 2025-10-26 |  |
| **[Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing](http://arxiv.org/abs/2504.05657v2)** | 2025-10-26 | <details><summary>Accep...</summary><p>Accepted to IEEE Transactions on Information Forensics and Security</p></details> |
| **[OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](http://arxiv.org/abs/2510.22535v1)** | 2025-10-26 |  |
| **[CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models](http://arxiv.org/abs/2507.22828v3)** | 2025-10-25 | <details><summary>9 pag...</summary><p>9 pages, accepted by the 2025 ACM Multimedia Conference. Code is available at https://jus1mple.github.io/Image2CaptionAttack</p></details> |
| **[T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model](http://arxiv.org/abs/2510.22300v1)** | 2025-10-25 | AAAI under review |
| **[A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](http://arxiv.org/abs/2503.10635v2)** | 2025-10-25 | <details><summary>NeurI...</summary><p>NeurIPS 2025. Code at: https://github.com/VILA-Lab/M-Attack</p></details> |
| **[Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for Large Language Models](http://arxiv.org/abs/2510.22085v1)** | 2025-10-24 | 18 pages, 5 figures |

