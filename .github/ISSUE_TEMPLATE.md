---
title: Latest 15 Papers - April 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v1)** | 2025-04-14 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |
| **[From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security](http://arxiv.org/abs/2412.15004v3)** | 2025-04-14 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v1)** | 2025-04-13 |  |
| **[AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender](http://arxiv.org/abs/2504.09466v1)** | 2025-04-13 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 9 tables</p></details> |
| **[SaRO: Enhancing LLM Safety through Reasoning-based Alignment](http://arxiv.org/abs/2504.09420v1)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |
| **[Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](http://arxiv.org/abs/2501.02406v3)** | 2025-04-12 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v3)** | 2025-04-11 |  |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v1)** | 2025-04-14 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |
| **[From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security](http://arxiv.org/abs/2412.15004v3)** | 2025-04-14 |  |
| **[ControlNET: A Firewall for RAG-based LLM System](http://arxiv.org/abs/2504.09593v1)** | 2025-04-13 |  |
| **[AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender](http://arxiv.org/abs/2504.09466v1)** | 2025-04-13 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 9 tables</p></details> |
| **[SaRO: Enhancing LLM Safety through Reasoning-based Alignment](http://arxiv.org/abs/2504.09420v1)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |
| **[Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](http://arxiv.org/abs/2501.02406v3)** | 2025-04-12 |  |
| **[Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups](http://arxiv.org/abs/2504.06160v3)** | 2025-04-11 |  |
| **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](http://arxiv.org/abs/2504.03767v2)** | 2025-04-11 | <details><summary>27 pa...</summary><p>27 pages, 21 figures, and 2 Tables. Cleans up the TeX source</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Using Large Language Models for Template Detection from Security Event Logs](http://arxiv.org/abs/2409.05045v3)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted for publication in International Journal of Information Security</p></details> |
| **[SnatchML: Hijacking ML models without Training Access](http://arxiv.org/abs/2406.01708v2)** | 2025-04-14 | <details><summary>17 pa...</summary><p>17 pages, 14 figures, 7 tables</p></details> |
| **[Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?](http://arxiv.org/abs/2504.10000v1)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025, codes in process</p></details> |
| **[Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2504.09910v1)** | 2025-04-14 |  |
| **[StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models](http://arxiv.org/abs/2504.09841v1)** | 2025-04-14 | Work in Progress |
| **[An Investigation of Large Language Models and Their Vulnerabilities in Spam Detection](http://arxiv.org/abs/2504.09776v1)** | 2025-04-14 | <details><summary>10 pa...</summary><p>10 pages; presented at HotSoS'2025 as a work in progress paper</p></details> |
| **[NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model](http://arxiv.org/abs/2412.03539v2)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |
| **[Detecting Instruction Fine-tuning Attack on Language Models with Influence Function](http://arxiv.org/abs/2504.09026v1)** | 2025-04-12 |  |
| **[Robust Steganography from Large Language Models](http://arxiv.org/abs/2504.08977v1)** | 2025-04-11 | 36 pages, 9 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Using Large Language Models for Template Detection from Security Event Logs](http://arxiv.org/abs/2409.05045v3)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted for publication in International Journal of Information Security</p></details> |
| **[SnatchML: Hijacking ML models without Training Access](http://arxiv.org/abs/2406.01708v2)** | 2025-04-14 | <details><summary>17 pa...</summary><p>17 pages, 14 figures, 7 tables</p></details> |
| **[Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?](http://arxiv.org/abs/2504.10000v1)** | 2025-04-14 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025, codes in process</p></details> |
| **[Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2504.09910v1)** | 2025-04-14 |  |
| **[StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models](http://arxiv.org/abs/2504.09841v1)** | 2025-04-14 | Work in Progress |
| **[An Investigation of Large Language Models and Their Vulnerabilities in Spam Detection](http://arxiv.org/abs/2504.09776v1)** | 2025-04-14 | <details><summary>10 pa...</summary><p>10 pages; presented at HotSoS'2025 as a work in progress paper</p></details> |
| **[NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model](http://arxiv.org/abs/2412.03539v2)** | 2025-04-13 |  |
| **[Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning](http://arxiv.org/abs/2412.10924v4)** | 2025-04-13 |  |
| **[Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities](http://arxiv.org/abs/2502.05209v2)** | 2025-04-12 |  |
| **[Detecting Instruction Fine-tuning Attack on Language Models with Influence Function](http://arxiv.org/abs/2504.09026v1)** | 2025-04-12 |  |

