---
title: Latest 15 Papers - February 04, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents](https://arxiv.org/abs/2509.25624v2)** | 2026-02-02 |  |
| **[RACA: Representation-Aware Coverage Criteria for LLM Safety Testing](https://arxiv.org/abs/2602.02280v1)** | 2026-02-02 |  |
| **[Code-Mixed Phonetic Perturbations for Red-Teaming LLMs](https://arxiv.org/abs/2505.14226v4)** | 2026-02-02 |  |
| **[Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs](https://arxiv.org/abs/2602.01600v1)** | 2026-02-02 |  |
| **[Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment](https://arxiv.org/abs/2602.01587v1)** | 2026-02-02 | 10 pages |
| **[MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539v1)** | 2026-02-02 |  |
| **[MAS-Shield: A Defense Framework for Secure and Efficient LLM MAS](https://arxiv.org/abs/2511.22924v2)** | 2026-02-02 |  |
| **[Latent Debate: A Surrogate Framework for Interpreting LLM Thinking](https://arxiv.org/abs/2512.01909v2)** | 2026-02-01 | Preprint |
| **[PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209v2)** | 2026-02-01 | <details><summary>accep...</summary><p>accepted at the Trustworthy Agentic AI Workshop @ AAAI 2026 (Singapore, Jan 27, 2026). Workshop PDF: https://trustagenticai.github.io/AAAI2026/AAAI-Workshop/20.pdf</p></details> |
| **[Short-length Adversarial Training Helps LLMs Defend Long-length Jailbreak Attacks: Theoretical and Empirical Evidence](https://arxiv.org/abs/2502.04204v3)** | 2026-01-31 | <details><summary>The T...</summary><p>The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents](https://arxiv.org/abs/2509.25624v2)** | 2026-02-02 |  |
| **[RACA: Representation-Aware Coverage Criteria for LLM Safety Testing](https://arxiv.org/abs/2602.02280v1)** | 2026-02-02 |  |
| **[Code-Mixed Phonetic Perturbations for Red-Teaming LLMs](https://arxiv.org/abs/2505.14226v4)** | 2026-02-02 |  |
| **[Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs](https://arxiv.org/abs/2602.01600v1)** | 2026-02-02 |  |
| **[Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment](https://arxiv.org/abs/2602.01587v1)** | 2026-02-02 | 10 pages |
| **[MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539v1)** | 2026-02-02 |  |
| **[MAS-Shield: A Defense Framework for Secure and Efficient LLM MAS](https://arxiv.org/abs/2511.22924v2)** | 2026-02-02 |  |
| **[Latent Debate: A Surrogate Framework for Interpreting LLM Thinking](https://arxiv.org/abs/2512.01909v2)** | 2026-02-01 | Preprint |
| **[PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209v2)** | 2026-02-01 | <details><summary>accep...</summary><p>accepted at the Trustworthy Agentic AI Workshop @ AAAI 2026 (Singapore, Jan 27, 2026). Workshop PDF: https://trustagenticai.github.io/AAAI2026/AAAI-Workshop/20.pdf</p></details> |
| **[Short-length Adversarial Training Helps LLMs Defend Long-length Jailbreak Attacks: Theoretical and Empirical Evidence](https://arxiv.org/abs/2502.04204v3)** | 2026-01-31 | <details><summary>The T...</summary><p>The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MalCVE: Malware Detection and CVE Association Using Large Language Models](https://arxiv.org/abs/2510.15567v2)** | 2026-02-02 |  |
| **[Alignment-Aware Model Adaptation via Feedback-Guided Optimization](https://arxiv.org/abs/2602.02258v1)** | 2026-02-02 |  |
| **[HAMLOCK: HArdware-Model LOgically Combined attacK](https://arxiv.org/abs/2510.19145v3)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to usenix security 2026</p></details> |
| **[Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834v1)** | 2026-02-02 |  |
| **[DREAM: Dynamic Red-teaming across Environments for AI Models](https://arxiv.org/abs/2512.19016v2)** | 2026-02-02 |  |
| **[Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency](https://arxiv.org/abs/2602.01765v1)** | 2026-02-02 |  |
| **[RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](https://arxiv.org/abs/2505.15386v3)** | 2026-02-02 |  |
| **[Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning](https://arxiv.org/abs/2511.23402v2)** | 2026-02-02 |  |
| **[Membership Inference Attack Against Music Diffusion Models via Generative Manifold Perturbation](https://arxiv.org/abs/2602.01645v1)** | 2026-02-02 |  |
| **[SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models](https://arxiv.org/abs/2602.01574v1)** | 2026-02-02 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MalCVE: Malware Detection and CVE Association Using Large Language Models](https://arxiv.org/abs/2510.15567v2)** | 2026-02-02 |  |
| **[Alignment-Aware Model Adaptation via Feedback-Guided Optimization](https://arxiv.org/abs/2602.02258v1)** | 2026-02-02 |  |
| **[HAMLOCK: HArdware-Model LOgically Combined attacK](https://arxiv.org/abs/2510.19145v3)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to usenix security 2026</p></details> |
| **[Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834v1)** | 2026-02-02 |  |
| **[DREAM: Dynamic Red-teaming across Environments for AI Models](https://arxiv.org/abs/2512.19016v2)** | 2026-02-02 |  |
| **[Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency](https://arxiv.org/abs/2602.01765v1)** | 2026-02-02 |  |
| **[RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](https://arxiv.org/abs/2505.15386v3)** | 2026-02-02 |  |
| **[Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning](https://arxiv.org/abs/2511.23402v2)** | 2026-02-02 |  |
| **[Membership Inference Attack Against Music Diffusion Models via Generative Manifold Perturbation](https://arxiv.org/abs/2602.01645v1)** | 2026-02-02 |  |
| **[SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models](https://arxiv.org/abs/2602.01574v1)** | 2026-02-02 |  |

