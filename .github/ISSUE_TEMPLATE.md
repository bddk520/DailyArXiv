---
title: Latest 15 Papers - July 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v1)** | 2025-07-09 |  |
| **[GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods](http://arxiv.org/abs/2502.16903v2)** | 2025-07-09 | <details><summary>Homep...</summary><p>Homepage: https://sproutnan.github.io/AI-Safety_Benchmark/</p></details> |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v2)** | 2025-07-09 |  |
| **[Breaking PEFT Limitations: Leveraging Weak-to-Strong Knowledge Transfer for Backdoor Attacks in LLMs](http://arxiv.org/abs/2409.17946v4)** | 2025-07-09 |  |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](http://arxiv.org/abs/2507.06489v1)** | 2025-07-09 |  |
| **[Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](http://arxiv.org/abs/2507.06323v1)** | 2025-07-08 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v1)** | 2025-07-08 |  |
| **[Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](http://arxiv.org/abs/2507.06274v1)** | 2025-07-08 |  |
| **[ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis](http://arxiv.org/abs/2506.15790v2)** | 2025-07-08 | <details><summary>4 pag...</summary><p>4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on Internetware (Internetware 2025)</p></details> |
| **[Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs](http://arxiv.org/abs/2410.16327v2)** | 2025-07-08 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v1)** | 2025-07-09 |  |
| **[GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods](http://arxiv.org/abs/2502.16903v2)** | 2025-07-09 | <details><summary>Homep...</summary><p>Homepage: https://sproutnan.github.io/AI-Safety_Benchmark/</p></details> |
| **[Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking](http://arxiv.org/abs/2507.04446v2)** | 2025-07-09 |  |
| **[Breaking PEFT Limitations: Leveraging Weak-to-Strong Knowledge Transfer for Backdoor Attacks in LLMs](http://arxiv.org/abs/2409.17946v4)** | 2025-07-09 |  |
| **[On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](http://arxiv.org/abs/2507.06489v1)** | 2025-07-09 |  |
| **[Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](http://arxiv.org/abs/2507.06323v1)** | 2025-07-08 |  |
| **[CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations](http://arxiv.org/abs/2507.06043v1)** | 2025-07-08 |  |
| **[Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](http://arxiv.org/abs/2507.06274v1)** | 2025-07-08 |  |
| **[ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis](http://arxiv.org/abs/2506.15790v2)** | 2025-07-08 | <details><summary>4 pag...</summary><p>4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on Internetware (Internetware 2025)</p></details> |
| **[Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs](http://arxiv.org/abs/2410.16327v2)** | 2025-07-08 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BarkBeetle: Stealing Decision Tree Models with Fault Injection](http://arxiv.org/abs/2507.06986v1)** | 2025-07-09 |  |
| **[Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](http://arxiv.org/abs/2506.11111v2)** | 2025-07-09 | 33 pages, 5 figures |
| **[Can adversarial attacks by large language models be attributed?](http://arxiv.org/abs/2411.08003v2)** | 2025-07-09 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 2 tables</p></details> |
| **[Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](http://arxiv.org/abs/2507.06466v1)** | 2025-07-09 | <details><summary>67 pa...</summary><p>67 pages, accepted to RLC 2025</p></details> |
| **[On Jailbreaking Quantized Language Models Through Fault Injection Attacks](http://arxiv.org/abs/2507.03236v2)** | 2025-07-08 | <details><summary>This ...</summary><p>This work has been published in GLSVLSI 2025</p></details> |
| **[Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](http://arxiv.org/abs/2507.06380v1)** | 2025-07-08 | 7 pages, 7 figures |
| **[On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving](http://arxiv.org/abs/2506.11472v2)** | 2025-07-08 |  |
| **[ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models](http://arxiv.org/abs/2507.06078v1)** | 2025-07-08 |  |
| **[From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks](http://arxiv.org/abs/2502.05325v2)** | 2025-07-08 |  |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v3)** | 2025-07-08 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BarkBeetle: Stealing Decision Tree Models with Fault Injection](http://arxiv.org/abs/2507.06986v1)** | 2025-07-09 |  |
| **[Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](http://arxiv.org/abs/2506.11111v2)** | 2025-07-09 | 33 pages, 5 figures |
| **[Can adversarial attacks by large language models be attributed?](http://arxiv.org/abs/2411.08003v2)** | 2025-07-09 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 2 tables</p></details> |
| **[Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](http://arxiv.org/abs/2507.06466v1)** | 2025-07-09 | <details><summary>67 pa...</summary><p>67 pages, accepted to RLC 2025</p></details> |
| **[On Jailbreaking Quantized Language Models Through Fault Injection Attacks](http://arxiv.org/abs/2507.03236v2)** | 2025-07-08 | <details><summary>This ...</summary><p>This work has been published in GLSVLSI 2025</p></details> |
| **[Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](http://arxiv.org/abs/2507.06380v1)** | 2025-07-08 | 7 pages, 7 figures |
| **[On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving](http://arxiv.org/abs/2506.11472v2)** | 2025-07-08 |  |
| **[ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models](http://arxiv.org/abs/2507.06078v1)** | 2025-07-08 |  |
| **[From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks](http://arxiv.org/abs/2502.05325v2)** | 2025-07-08 |  |
| **[MEF: A Capability-Aware Multi-Encryption Framework for Evaluating Vulnerabilities in Black-Box Large Language Models](http://arxiv.org/abs/2505.23404v3)** | 2025-07-08 |  |

