---
title: Latest 15 Papers - November 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[XBreaking: Understanding how LLMs security alignment can be broken](http://arxiv.org/abs/2504.21700v3)** | 2025-11-07 |  |
| **[TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](http://arxiv.org/abs/2511.05269v1)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted at ICML 2025 MAS Workshop. This version includes additional experiments and analysis</p></details> |
| **[Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities](http://arxiv.org/abs/2410.18469v6)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted to NAACL 2025 Main (Oral)</p></details> |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v2)** | 2025-11-07 |  |
| **[AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](http://arxiv.org/abs/2511.04316v1)** | 2025-11-06 |  |
| **[GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs](http://arxiv.org/abs/2411.14133v3)** | 2025-11-06 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025. Project page and demos: https://air-ml.org/project/gasp/</p></details> |
| **[Measuring the Security of Mobile LLM Agents under Adversarial Prompts from Untrusted Third-Party Channels](http://arxiv.org/abs/2510.27140v2)** | 2025-11-06 |  |
| **[Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs](http://arxiv.org/abs/2511.03271v1)** | 2025-11-05 |  |
| **[From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](http://arxiv.org/abs/2511.03128v1)** | 2025-11-05 | <details><summary>Findi...</summary><p>Findings of the Association for Computational Linguistics: EMNLP 2025 (camera-ready)</p></details> |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[XBreaking: Understanding how LLMs security alignment can be broken](http://arxiv.org/abs/2504.21700v3)** | 2025-11-07 |  |
| **[TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](http://arxiv.org/abs/2511.05269v1)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted at ICML 2025 MAS Workshop. This version includes additional experiments and analysis</p></details> |
| **[Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities](http://arxiv.org/abs/2410.18469v6)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted to NAACL 2025 Main (Oral)</p></details> |
| **[CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](http://arxiv.org/abs/2510.22963v2)** | 2025-11-07 |  |
| **[AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](http://arxiv.org/abs/2511.04316v1)** | 2025-11-06 |  |
| **[GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs](http://arxiv.org/abs/2411.14133v3)** | 2025-11-06 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025. Project page and demos: https://air-ml.org/project/gasp/</p></details> |
| **[Measuring the Security of Mobile LLM Agents under Adversarial Prompts from Untrusted Third-Party Channels](http://arxiv.org/abs/2510.27140v2)** | 2025-11-06 |  |
| **[Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs](http://arxiv.org/abs/2511.03271v1)** | 2025-11-05 |  |
| **[From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](http://arxiv.org/abs/2511.03128v1)** | 2025-11-05 | <details><summary>Findi...</summary><p>Findings of the Association for Computational Linguistics: EMNLP 2025 (camera-ready)</p></details> |
| **[Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?](http://arxiv.org/abs/2511.00689v2)** | 2025-11-04 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](http://arxiv.org/abs/2511.05476v1)** | 2025-11-07 | <details><summary>The p...</summary><p>The paper is currently under review at a peer-reviewed journal</p></details> |
| **[Deep learning models are vulnerable, but adversarial examples are even more vulnerable](http://arxiv.org/abs/2511.05073v1)** | 2025-11-07 | 25 pages,12 figures |
| **[Zero Trust Security Model Implementation in Microservices Architectures Using Identity Federation](http://arxiv.org/abs/2511.04925v1)** | 2025-11-07 |  |
| **[A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems](http://arxiv.org/abs/2511.04523v1)** | 2025-11-06 |  |
| **[Large Language Models for Cyber Security](http://arxiv.org/abs/2511.04508v1)** | 2025-11-06 |  |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v4)** | 2025-11-06 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |
| **[P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models](http://arxiv.org/abs/2511.04716v1)** | 2025-11-06 |  |
| **[VERA: Variational Inference Framework for Jailbreaking Large Language Models](http://arxiv.org/abs/2506.22666v2)** | 2025-11-06 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Whisper Leak: a side-channel attack on Large Language Models](http://arxiv.org/abs/2511.03675v1)** | 2025-11-05 | 14 pages, 7 figures |
| **[Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models](http://arxiv.org/abs/2409.13174v4)** | 2025-11-05 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](http://arxiv.org/abs/2511.05476v1)** | 2025-11-07 | <details><summary>The p...</summary><p>The paper is currently under review at a peer-reviewed journal</p></details> |
| **[Deep learning models are vulnerable, but adversarial examples are even more vulnerable](http://arxiv.org/abs/2511.05073v1)** | 2025-11-07 | 25 pages,12 figures |
| **[Zero Trust Security Model Implementation in Microservices Architectures Using Identity Federation](http://arxiv.org/abs/2511.04925v1)** | 2025-11-07 |  |
| **[A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems](http://arxiv.org/abs/2511.04523v1)** | 2025-11-06 |  |
| **[Large Language Models for Cyber Security](http://arxiv.org/abs/2511.04508v1)** | 2025-11-06 |  |
| **[HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model](http://arxiv.org/abs/2506.04704v4)** | 2025-11-06 | <details><summary>Proje...</summary><p>Project page: https://youngwanlee.github.io/holisafe</p></details> |
| **[P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models](http://arxiv.org/abs/2511.04716v1)** | 2025-11-06 |  |
| **[VERA: Variational Inference Framework for Jailbreaking Large Language Models](http://arxiv.org/abs/2506.22666v2)** | 2025-11-06 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Whisper Leak: a side-channel attack on Large Language Models](http://arxiv.org/abs/2511.03675v1)** | 2025-11-05 | 14 pages, 7 figures |
| **[Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models](http://arxiv.org/abs/2409.13174v4)** | 2025-11-05 |  |

