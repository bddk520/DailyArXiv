---
title: Latest 15 Papers - February 26, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **["Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems](https://arxiv.org/abs/2602.21127v1)** | 2026-02-24 |  |
| **[A Simple and Efficient Jailbreak Method Exploiting LLMs' Helpfulness](https://arxiv.org/abs/2509.14297v2)** | 2026-02-24 |  |
| **[AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs](https://arxiv.org/abs/2602.20720v1)** | 2026-02-24 | 11 pages |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](https://arxiv.org/abs/2510.22620v2)** | 2026-02-24 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services](https://arxiv.org/abs/2602.20595v1)** | 2026-02-24 |  |
| **[MalTool: Malicious Tool Attacks on LLM Agents](https://arxiv.org/abs/2602.12194v2)** | 2026-02-23 |  |
| **[BarrierSteer: LLM Safety via Learning Barrier Steering](https://arxiv.org/abs/2602.20102v1)** | 2026-02-23 | <details><summary>This ...</summary><p>This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs</p></details> |
| **[AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs](https://arxiv.org/abs/2509.06326v2)** | 2026-02-23 | accept to DAC 2026 |
| **[LLM-enabled Applications Require System-Level Threat Monitoring](https://arxiv.org/abs/2602.19844v1)** | 2026-02-23 | 26 pages |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](https://arxiv.org/abs/2510.10987v3)** | 2026-02-23 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 (Oral)</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **["Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems](https://arxiv.org/abs/2602.21127v1)** | 2026-02-24 |  |
| **[A Simple and Efficient Jailbreak Method Exploiting LLMs' Helpfulness](https://arxiv.org/abs/2509.14297v2)** | 2026-02-24 |  |
| **[AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs](https://arxiv.org/abs/2602.20720v1)** | 2026-02-24 | 11 pages |
| **[Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](https://arxiv.org/abs/2510.22620v2)** | 2026-02-24 | <details><summary>Julia...</summary><p>Julia Bazinska and Max Mathys contributed equally</p></details> |
| **[OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services](https://arxiv.org/abs/2602.20595v1)** | 2026-02-24 |  |
| **[MalTool: Malicious Tool Attacks on LLM Agents](https://arxiv.org/abs/2602.12194v2)** | 2026-02-23 |  |
| **[BarrierSteer: LLM Safety via Learning Barrier Steering](https://arxiv.org/abs/2602.20102v1)** | 2026-02-23 | <details><summary>This ...</summary><p>This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs</p></details> |
| **[AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs](https://arxiv.org/abs/2509.06326v2)** | 2026-02-23 | accept to DAC 2026 |
| **[LLM-enabled Applications Require System-Level Threat Monitoring](https://arxiv.org/abs/2602.19844v1)** | 2026-02-23 | 26 pages |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](https://arxiv.org/abs/2510.10987v3)** | 2026-02-23 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 (Oral)</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models](https://arxiv.org/abs/2602.20999v1)** | 2026-02-24 | <details><summary>Proje...</summary><p>Project page: https://Zbwwwwwwww.github.io/VII</p></details> |
| **[MUSE: Multi-Tenant Model Serving With Seamless Model Updates](https://arxiv.org/abs/2602.11776v2)** | 2026-02-24 | <details><summary>Curre...</summary><p>Currently under review for KDD 2026 (Applied Data Science)</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v3)** | 2026-02-24 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[CREDIT: Certified Ownership Verification of Deep Neural Networks Against Model Extraction Attacks](https://arxiv.org/abs/2602.20419v1)** | 2026-02-23 |  |
| **[CITED: A Decision Boundary-Aware Signature for GNNs Towards Model Extraction Defense](https://arxiv.org/abs/2602.20418v1)** | 2026-02-23 |  |
| **[SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models](https://arxiv.org/abs/2602.19818v1)** | 2026-02-23 |  |
| **[Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing](https://arxiv.org/abs/2506.01783v2)** | 2026-02-23 | Accepted to CVPR2026 |
| **[Sampling-aware Adversarial Attacks Against Large Language Models](https://arxiv.org/abs/2507.04446v4)** | 2026-02-22 |  |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](https://arxiv.org/abs/2505.16789v3)** | 2026-02-22 | <details><summary>Secon...</summary><p>Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI 2026)</p></details> |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models](https://arxiv.org/abs/2602.20999v1)** | 2026-02-24 | <details><summary>Proje...</summary><p>Project page: https://Zbwwwwwwww.github.io/VII</p></details> |
| **[MUSE: Multi-Tenant Model Serving With Seamless Model Updates](https://arxiv.org/abs/2602.11776v2)** | 2026-02-24 | <details><summary>Curre...</summary><p>Currently under review for KDD 2026 (Applied Data Science)</p></details> |
| **[MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents](https://arxiv.org/abs/2602.14281v3)** | 2026-02-24 | <details><summary>21 pa...</summary><p>21 pages, 5 figures, 6 tables</p></details> |
| **[CREDIT: Certified Ownership Verification of Deep Neural Networks Against Model Extraction Attacks](https://arxiv.org/abs/2602.20419v1)** | 2026-02-23 |  |
| **[CITED: A Decision Boundary-Aware Signature for GNNs Towards Model Extraction Defense](https://arxiv.org/abs/2602.20418v1)** | 2026-02-23 |  |
| **[SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models](https://arxiv.org/abs/2602.19818v1)** | 2026-02-23 |  |
| **[Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing](https://arxiv.org/abs/2506.01783v2)** | 2026-02-23 | Accepted to CVPR2026 |
| **[Sampling-aware Adversarial Attacks Against Large Language Models](https://arxiv.org/abs/2507.04446v4)** | 2026-02-22 |  |
| **[Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards](https://arxiv.org/abs/2505.16789v3)** | 2026-02-22 | <details><summary>Secon...</summary><p>Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI 2026)</p></details> |
| **[LLM Scalability Risk for Agentic-AI and Model Supply Chain Security](https://arxiv.org/abs/2602.19021v1)** | 2026-02-22 | <details><summary>Accep...</summary><p>Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670</p></details> |

