---
title: Latest 15 Papers - September 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](http://arxiv.org/abs/2509.12672v1)** | 2025-09-16 |  |
| **[A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs](http://arxiv.org/abs/2509.12649v1)** | 2025-09-16 | 25 pages |
| **[Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs](http://arxiv.org/abs/2509.11177v2)** | 2025-09-16 | Preprint |
| **[Redefining Website Fingerprinting Attacks With Multiagent LLMs](http://arxiv.org/abs/2509.12462v1)** | 2025-09-15 |  |
| **[Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System](http://arxiv.org/abs/2509.05755v2)** | 2025-09-15 |  |
| **[NeuroStrike: Neuron-Level Attacks on Aligned LLMs](http://arxiv.org/abs/2509.11864v1)** | 2025-09-15 |  |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v2)** | 2025-09-15 |  |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v2)** | 2025-09-15 |  |
| **[Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment](http://arxiv.org/abs/2410.14827v3)** | 2025-09-15 |  |
| **[Character-Level Perturbations Disrupt LLM Watermarks](http://arxiv.org/abs/2509.09112v2)** | 2025-09-14 | <details><summary>accep...</summary><p>accepted by Network and Distributed System Security (NDSS) Symposium 2026</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](http://arxiv.org/abs/2509.12672v1)** | 2025-09-16 |  |
| **[A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs](http://arxiv.org/abs/2509.12649v1)** | 2025-09-16 | 25 pages |
| **[Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs](http://arxiv.org/abs/2509.11177v2)** | 2025-09-16 | Preprint |
| **[Redefining Website Fingerprinting Attacks With Multiagent LLMs](http://arxiv.org/abs/2509.12462v1)** | 2025-09-15 |  |
| **[Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System](http://arxiv.org/abs/2509.05755v2)** | 2025-09-15 |  |
| **[NeuroStrike: Neuron-Level Attacks on Aligned LLMs](http://arxiv.org/abs/2509.11864v1)** | 2025-09-15 |  |
| **[Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v2)** | 2025-09-15 |  |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v2)** | 2025-09-15 |  |
| **[Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment](http://arxiv.org/abs/2410.14827v3)** | 2025-09-15 |  |
| **[Character-Level Perturbations Disrupt LLM Watermarks](http://arxiv.org/abs/2509.09112v2)** | 2025-09-14 | <details><summary>accep...</summary><p>accepted by Network and Distributed System Security (NDSS) Symposium 2026</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Context-Aware Membership Inference Attacks against Pre-trained Large Language Models](http://arxiv.org/abs/2409.13745v2)** | 2025-09-16 |  |
| **[Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection](http://arxiv.org/abs/2502.13061v4)** | 2025-09-16 | <details><summary>EMNLP...</summary><p>EMNLP 2025 Main (Oral)</p></details> |
| **[Bridging Threat Models and Detections: Formal Verification via CADP](http://arxiv.org/abs/2509.13035v1)** | 2025-09-16 | <details><summary>In Pr...</summary><p>In Proceedings FROM 2025, arXiv:2509.11877</p></details> |
| **[Adversarial Prompt Distillation for Vision-Language Models](http://arxiv.org/abs/2411.15244v3)** | 2025-09-16 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval](http://arxiv.org/abs/2509.12824v1)** | 2025-09-16 |  |
| **[Gradient-Free Adversarial Purification with Diffusion Models](http://arxiv.org/abs/2501.13336v2)** | 2025-09-16 |  |
| **[Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models](http://arxiv.org/abs/2509.12724v1)** | 2025-09-16 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models](http://arxiv.org/abs/2509.04245v2)** | 2025-09-16 |  |
| **[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](http://arxiv.org/abs/2509.11173v2)** | 2025-09-16 |  |
| **[When MoE Meets Blockchain: A Trustworthy Distributed Framework of Large Models](http://arxiv.org/abs/2509.12141v2)** | 2025-09-16 | <details><summary>We ne...</summary><p>We need to revise the content of this article</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Context-Aware Membership Inference Attacks against Pre-trained Large Language Models](http://arxiv.org/abs/2409.13745v2)** | 2025-09-16 |  |
| **[Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection](http://arxiv.org/abs/2502.13061v4)** | 2025-09-16 | <details><summary>EMNLP...</summary><p>EMNLP 2025 Main (Oral)</p></details> |
| **[Bridging Threat Models and Detections: Formal Verification via CADP](http://arxiv.org/abs/2509.13035v1)** | 2025-09-16 | <details><summary>In Pr...</summary><p>In Proceedings FROM 2025, arXiv:2509.11877</p></details> |
| **[Adversarial Prompt Distillation for Vision-Language Models](http://arxiv.org/abs/2411.15244v3)** | 2025-09-16 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval](http://arxiv.org/abs/2509.12824v1)** | 2025-09-16 |  |
| **[Gradient-Free Adversarial Purification with Diffusion Models](http://arxiv.org/abs/2501.13336v2)** | 2025-09-16 |  |
| **[Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models](http://arxiv.org/abs/2509.12724v1)** | 2025-09-16 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models](http://arxiv.org/abs/2509.04245v2)** | 2025-09-16 |  |
| **[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](http://arxiv.org/abs/2509.11173v2)** | 2025-09-16 |  |
| **[When MoE Meets Blockchain: A Trustworthy Distributed Framework of Large Models](http://arxiv.org/abs/2509.12141v2)** | 2025-09-16 | <details><summary>We ne...</summary><p>We need to revise the content of this article</p></details> |

