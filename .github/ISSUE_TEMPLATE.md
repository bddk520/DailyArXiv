---
title: Latest 15 Papers - November 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](http://arxiv.org/abs/2510.10987v2)** | 2025-11-03 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, preprint</p></details> |
| **[SLIP: Securing LLMs IP Using Weights Decomposition](http://arxiv.org/abs/2407.10886v3)** | 2025-11-01 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v3)** | 2025-11-01 |  |
| **[Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization](http://arxiv.org/abs/2509.05831v2)** | 2025-10-31 |  |
| **[Measuring the Security of Mobile LLM Agents under Adversarial Prompts from Untrusted Third-Party Channels](http://arxiv.org/abs/2510.27140v1)** | 2025-10-31 |  |
| **[LLM-based Multi-class Attack Analysis and Mitigation Framework in IoT/IIoT Networks](http://arxiv.org/abs/2510.26941v1)** | 2025-10-30 |  |
| **[PVMark: Enabling Public Verifiability for LLM Watermarking Schemes](http://arxiv.org/abs/2510.26274v1)** | 2025-10-30 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Improving LLM Safety Alignment with Dual-Objective Optimization](http://arxiv.org/abs/2503.03710v3)** | 2025-10-30 | ICML 2025 |
| **[SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning](http://arxiv.org/abs/2510.26037v1)** | 2025-10-30 |  |
| **[SoK: Honeypots & LLMs, More Than the Sum of Their Parts?](http://arxiv.org/abs/2510.25939v1)** | 2025-10-29 | <details><summary>Syste...</summary><p>Systemization of Knowledge</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](http://arxiv.org/abs/2510.10987v2)** | 2025-11-03 | <details><summary>14 pa...</summary><p>14 pages, 4 figures, preprint</p></details> |
| **[SLIP: Securing LLMs IP Using Weights Decomposition](http://arxiv.org/abs/2407.10886v3)** | 2025-11-01 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v3)** | 2025-11-01 |  |
| **[Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization](http://arxiv.org/abs/2509.05831v2)** | 2025-10-31 |  |
| **[Measuring the Security of Mobile LLM Agents under Adversarial Prompts from Untrusted Third-Party Channels](http://arxiv.org/abs/2510.27140v1)** | 2025-10-31 |  |
| **[LLM-based Multi-class Attack Analysis and Mitigation Framework in IoT/IIoT Networks](http://arxiv.org/abs/2510.26941v1)** | 2025-10-30 |  |
| **[PVMark: Enabling Public Verifiability for LLM Watermarking Schemes](http://arxiv.org/abs/2510.26274v1)** | 2025-10-30 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Improving LLM Safety Alignment with Dual-Objective Optimization](http://arxiv.org/abs/2503.03710v3)** | 2025-10-30 | ICML 2025 |
| **[SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning](http://arxiv.org/abs/2510.26037v1)** | 2025-10-30 |  |
| **[SoK: Honeypots & LLMs, More Than the Sum of Their Parts?](http://arxiv.org/abs/2510.25939v1)** | 2025-10-29 | <details><summary>Syste...</summary><p>Systemization of Knowledge</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v2)** | 2025-11-03 |  |
| **[Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2510.13698v2)** | 2025-11-03 |  |
| **[Exploring the limits of strong membership inference attacks on large language models](http://arxiv.org/abs/2505.18773v2)** | 2025-11-02 | NeurIPS 2025 |
| **[SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks](http://arxiv.org/abs/2502.11090v3)** | 2025-11-02 |  |
| **[CoP: Agentic Red-teaming for Large Language Models using Composition of Principles](http://arxiv.org/abs/2506.00781v2)** | 2025-11-01 |  |
| **[BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](http://arxiv.org/abs/2510.20792v2)** | 2025-10-31 |  |
| **[Eliciting Secret Knowledge from Language Models](http://arxiv.org/abs/2510.01070v2)** | 2025-10-31 |  |
| **[Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](http://arxiv.org/abs/2510.27172v1)** | 2025-10-31 |  |
| **[Characterizing Selective Refusal Bias in Large Language Models](http://arxiv.org/abs/2510.27087v1)** | 2025-10-31 | <details><summary>21 pa...</summary><p>21 pages, 12 figures, 14 tables</p></details> |
| **[Adapting Large Language Models to Emerging Cybersecurity using Retrieval Augmented Generation](http://arxiv.org/abs/2510.27080v1)** | 2025-10-31 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v2)** | 2025-11-03 |  |
| **[Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](http://arxiv.org/abs/2510.13698v2)** | 2025-11-03 |  |
| **[Exploring the limits of strong membership inference attacks on large language models](http://arxiv.org/abs/2505.18773v2)** | 2025-11-02 | NeurIPS 2025 |
| **[SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks](http://arxiv.org/abs/2502.11090v3)** | 2025-11-02 |  |
| **[CoP: Agentic Red-teaming for Large Language Models using Composition of Principles](http://arxiv.org/abs/2506.00781v2)** | 2025-11-01 |  |
| **[BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](http://arxiv.org/abs/2510.20792v2)** | 2025-10-31 |  |
| **[Eliciting Secret Knowledge from Language Models](http://arxiv.org/abs/2510.01070v2)** | 2025-10-31 |  |
| **[Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](http://arxiv.org/abs/2510.27172v1)** | 2025-10-31 |  |
| **[Characterizing Selective Refusal Bias in Large Language Models](http://arxiv.org/abs/2510.27087v1)** | 2025-10-31 | <details><summary>21 pa...</summary><p>21 pages, 12 figures, 14 tables</p></details> |
| **[Adapting Large Language Models to Emerging Cybersecurity using Retrieval Augmented Generation](http://arxiv.org/abs/2510.27080v1)** | 2025-10-31 |  |

