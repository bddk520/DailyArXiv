---
title: Latest 15 Papers - April 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |
| **[Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation](http://arxiv.org/abs/2504.12108v1)** | 2025-04-16 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v3)** | 2025-04-16 |  |
| **[Progent: Programmable Privilege Control for LLM Agents](http://arxiv.org/abs/2504.11703v1)** | 2025-04-16 |  |
| **[Making Acoustic Side-Channel Attacks on Noisy Keyboards Viable with LLM-Assisted Spectrograms' "Typo" Correction](http://arxiv.org/abs/2504.11622v1)** | 2025-04-15 | <details><summary>Lengt...</summary><p>Length: 13 pages Figures: 5 figures Tables: 7 tables Keywords: Acoustic side-channel attacks, machine learning, Visual Transformers, Large Language Models (LLMs), security Conference: Accepted at the 19th USENIX WOOT Conference on Offensive Technologies (WOOT '25). Licensing: This paper is submitted under the CC BY Creative Commons Attribution license. arXiv admin note: text overlap with arXiv:2502.09782</p></details> |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |
| **[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](http://arxiv.org/abs/2504.11182v1)** | 2025-04-15 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails](http://arxiv.org/abs/2504.11168v2)** | 2025-04-16 | <details><summary>12 pa...</summary><p>12 pages, 5 figures, 6 tables</p></details> |
| **[Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space](http://arxiv.org/abs/2402.09063v2)** | 2025-04-16 | <details><summary>Trigg...</summary><p>Trigger Warning: the appendix contains LLM-generated text with violence and harassment</p></details> |
| **[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks](http://arxiv.org/abs/2504.10185v2)** | 2025-04-16 |  |
| **[Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation](http://arxiv.org/abs/2504.12108v1)** | 2025-04-16 |  |
| **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v3)** | 2025-04-16 |  |
| **[Progent: Programmable Privilege Control for LLM Agents](http://arxiv.org/abs/2504.11703v1)** | 2025-04-16 |  |
| **[Making Acoustic Side-Channel Attacks on Noisy Keyboards Viable with LLM-Assisted Spectrograms' "Typo" Correction](http://arxiv.org/abs/2504.11622v1)** | 2025-04-15 | <details><summary>Lengt...</summary><p>Length: 13 pages Figures: 5 figures Tables: 7 tables Keywords: Acoustic side-channel attacks, machine learning, Visual Transformers, Large Language Models (LLMs), security Conference: Accepted at the 19th USENIX WOOT Conference on Offensive Technologies (WOOT '25). Licensing: This paper is submitted under the CC BY Creative Commons Attribution license. arXiv admin note: text overlap with arXiv:2502.09782</p></details> |
| **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)** | 2025-04-15 |  |
| **[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](http://arxiv.org/abs/2504.11182v1)** | 2025-04-15 |  |
| **[Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](http://arxiv.org/abs/2504.10112v1)** | 2025-04-14 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Human Aligned Compression for Robust Models](http://arxiv.org/abs/2504.12255v1)** | 2025-04-16 | <details><summary>Prese...</summary><p>Presented at the Workshop AdvML at CVPR 2025</p></details> |
| **[RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning](http://arxiv.org/abs/2502.08989v2)** | 2025-04-16 | 16 pages, 10 Figures |
| **[Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets](http://arxiv.org/abs/2504.11990v1)** | 2025-04-16 | <details><summary>To ap...</summary><p>To appear at IEEE Symposium on Security and Privacy 2025, 20 pages</p></details> |
| **[SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models](http://arxiv.org/abs/2504.11923v1)** | 2025-04-16 |  |
| **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility](http://arxiv.org/abs/2504.11774v1)** | 2025-04-16 |  |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v1)** | 2025-04-15 | CVPR 2025 |
| **[Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models](http://arxiv.org/abs/2504.11106v1)** | 2025-04-15 |  |
| **[FLSSM: A Federated Learning Storage Security Model with Homomorphic Encryption](http://arxiv.org/abs/2504.11088v1)** | 2025-04-15 |  |
| **[MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness](http://arxiv.org/abs/2312.04960v4)** | 2025-04-15 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Human Aligned Compression for Robust Models](http://arxiv.org/abs/2504.12255v1)** | 2025-04-16 | <details><summary>Prese...</summary><p>Presented at the Workshop AdvML at CVPR 2025</p></details> |
| **[RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning](http://arxiv.org/abs/2502.08989v2)** | 2025-04-16 | 16 pages, 10 Figures |
| **[Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets](http://arxiv.org/abs/2504.11990v1)** | 2025-04-16 | <details><summary>To ap...</summary><p>To appear at IEEE Symposium on Security and Privacy 2025, 20 pages</p></details> |
| **[SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models](http://arxiv.org/abs/2504.11923v1)** | 2025-04-16 |  |
| **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility](http://arxiv.org/abs/2504.11774v1)** | 2025-04-16 |  |
| **[Lateral Phishing With Large Language Models: A Large Organization Comparative Study](http://arxiv.org/abs/2401.09727v2)** | 2025-04-15 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Access. This version includes revisions following peer review</p></details> |
| **[R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning](http://arxiv.org/abs/2504.11195v1)** | 2025-04-15 | CVPR 2025 |
| **[Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models](http://arxiv.org/abs/2504.11106v1)** | 2025-04-15 |  |
| **[FLSSM: A Federated Learning Storage Security Model with Homomorphic Encryption](http://arxiv.org/abs/2504.11088v1)** | 2025-04-15 |  |
| **[MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness](http://arxiv.org/abs/2312.04960v4)** | 2025-04-15 |  |

