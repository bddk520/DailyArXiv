---
title: Latest 15 Papers - July 01, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v3)** | 2025-06-27 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v3)** | 2025-06-27 |  |
| **[Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses](http://arxiv.org/abs/2506.21972v1)** | 2025-06-27 |  |
| **[More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents](http://arxiv.org/abs/2506.21967v1)** | 2025-06-27 |  |
| **[Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](http://arxiv.org/abs/2506.21443v1)** | 2025-06-26 |  |
| **[TracLLM: A Generic Framework for Attributing Long Context LLMs](http://arxiv.org/abs/2506.04202v3)** | 2025-06-26 | <details><summary>To ap...</summary><p>To appear in USENIX Security Symposium 2025. The code and data are at: https://github.com/Wang-Yanting/TracLLM</p></details> |
| **[WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis](http://arxiv.org/abs/2412.03359v2)** | 2025-06-26 |  |
| **[Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](http://arxiv.org/abs/2506.20856v1)** | 2025-06-25 |  |
| **[GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs](http://arxiv.org/abs/2411.14133v2)** | 2025-06-25 | <details><summary>38 pa...</summary><p>38 pages, 8 tables, 18 figures</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v3)** | 2025-06-27 |  |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](http://arxiv.org/abs/2505.02862v3)** | 2025-06-27 |  |
| **[Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses](http://arxiv.org/abs/2506.21972v1)** | 2025-06-27 |  |
| **[More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents](http://arxiv.org/abs/2506.21967v1)** | 2025-06-27 |  |
| **[Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](http://arxiv.org/abs/2506.21443v1)** | 2025-06-26 |  |
| **[TracLLM: A Generic Framework for Attributing Long Context LLMs](http://arxiv.org/abs/2506.04202v3)** | 2025-06-26 | <details><summary>To ap...</summary><p>To appear in USENIX Security Symposium 2025. The code and data are at: https://github.com/Wang-Yanting/TracLLM</p></details> |
| **[WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis](http://arxiv.org/abs/2412.03359v2)** | 2025-06-26 |  |
| **[Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](http://arxiv.org/abs/2506.20856v1)** | 2025-06-25 |  |
| **[GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs](http://arxiv.org/abs/2411.14133v2)** | 2025-06-25 | <details><summary>38 pa...</summary><p>38 pages, 8 tables, 18 figures</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency](http://arxiv.org/abs/2501.04931v2)** | 2025-06-27 | ICCV2025 |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling](http://arxiv.org/abs/2506.21874v1)** | 2025-06-27 | <details><summary>ACM C...</summary><p>ACM Conference on Computer and Communications Security 2025</p></details> |
| **[Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors](http://arxiv.org/abs/2411.13047v2)** | 2025-06-25 | <details><summary>Accep...</summary><p>Accepted at ECML-PKDD2025. Please refer to the conference proceedings for the final version. Source codes: https://zenodo.org/records/15641464</p></details> |
| **[Towards Backdoor Stealthiness in Model Parameter Space](http://arxiv.org/abs/2501.05928v2)** | 2025-06-24 | <details><summary>to ap...</summary><p>to appear at CCS 2025</p></details> |
| **[Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models](http://arxiv.org/abs/2408.00523v3)** | 2025-06-24 |  |
| **[Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale](http://arxiv.org/abs/2506.19899v1)** | 2025-06-24 | 13 pages, 5 apdx |
| **[Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy](http://arxiv.org/abs/2506.19486v1)** | 2025-06-24 | IJCAI 2025 |
| **[Privacy Attacks on Image AutoRegressive Models](http://arxiv.org/abs/2502.02514v4)** | 2025-06-24 | Accepted at ICML2025 |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency](http://arxiv.org/abs/2501.04931v2)** | 2025-06-27 | ICCV2025 |
| **[Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](http://arxiv.org/abs/2505.17066v2)** | 2025-06-27 | <details><summary>Under...</summary><p>Under review at IEEE Access. Supplementary material is included in the main PDF</p></details> |
| **[On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling](http://arxiv.org/abs/2506.21874v1)** | 2025-06-27 | <details><summary>ACM C...</summary><p>ACM Conference on Computer and Communications Security 2025</p></details> |
| **[An introduction to Causal Modelling](http://arxiv.org/abs/2506.16486v2)** | 2025-06-26 |  |
| **[CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](http://arxiv.org/abs/2506.20926v1)** | 2025-06-26 | 13 pages |
| **[Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors](http://arxiv.org/abs/2411.13047v2)** | 2025-06-25 | <details><summary>Accep...</summary><p>Accepted at ECML-PKDD2025. Please refer to the conference proceedings for the final version. Source codes: https://zenodo.org/records/15641464</p></details> |
| **[Towards Backdoor Stealthiness in Model Parameter Space](http://arxiv.org/abs/2501.05928v2)** | 2025-06-24 | <details><summary>to ap...</summary><p>to appear at CCS 2025</p></details> |
| **[Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models](http://arxiv.org/abs/2408.00523v3)** | 2025-06-24 |  |
| **[Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale](http://arxiv.org/abs/2506.19899v1)** | 2025-06-24 | 13 pages, 5 apdx |

