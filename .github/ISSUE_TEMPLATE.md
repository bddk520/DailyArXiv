---
title: Latest 15 Papers - January 26, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Membership Inference Attacks on LLM-based Recommender Systems](https://arxiv.org/abs/2508.18665v5)** | 2026-01-22 | <details><summary>This ...</summary><p>This is paper is under review ACL 2026</p></details> |
| **[Can LLM Infer Risk Information From MCP Server System Logs?](https://arxiv.org/abs/2511.05867v3)** | 2026-01-22 |  |
| **[Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform](https://arxiv.org/abs/2601.15528v1)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted by AISC 2026</p></details> |
| **[Lightweight LLMs for Network Attack Detection in IoT Networks](https://arxiv.org/abs/2601.15269v1)** | 2026-01-21 | <details><summary>6 pag...</summary><p>6 pages with 2 figures, This paper was accepted and presented at the 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), held in Madrid, Spain, during 14th to 17th December 2025</p></details> |
| **[Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs](https://arxiv.org/abs/2501.16534v3)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted to 2026 IEEE Secure and Trustworthy Machine Learning Conference (SaTML)</p></details> |
| **[INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.14667v1)** | 2026-01-21 |  |
| **[NeuroFilter: Privacy Guardrails for Conversational LLM Agents](https://arxiv.org/abs/2601.14660v1)** | 2026-01-21 |  |
| **[Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](https://arxiv.org/abs/2509.01631v2)** | 2026-01-21 | EACL 2026 |
| **[An LLM Agent-based Framework for Whaling Countermeasures](https://arxiv.org/abs/2601.14606v1)** | 2026-01-21 |  |
| **[Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks](https://arxiv.org/abs/2601.14601v1)** | 2026-01-21 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Membership Inference Attacks on LLM-based Recommender Systems](https://arxiv.org/abs/2508.18665v5)** | 2026-01-22 | <details><summary>This ...</summary><p>This is paper is under review ACL 2026</p></details> |
| **[Can LLM Infer Risk Information From MCP Server System Logs?](https://arxiv.org/abs/2511.05867v3)** | 2026-01-22 |  |
| **[Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform](https://arxiv.org/abs/2601.15528v1)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted by AISC 2026</p></details> |
| **[Lightweight LLMs for Network Attack Detection in IoT Networks](https://arxiv.org/abs/2601.15269v1)** | 2026-01-21 | <details><summary>6 pag...</summary><p>6 pages with 2 figures, This paper was accepted and presented at the 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), held in Madrid, Spain, during 14th to 17th December 2025</p></details> |
| **[Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs](https://arxiv.org/abs/2501.16534v3)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted to 2026 IEEE Secure and Trustworthy Machine Learning Conference (SaTML)</p></details> |
| **[INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.14667v1)** | 2026-01-21 |  |
| **[NeuroFilter: Privacy Guardrails for Conversational LLM Agents](https://arxiv.org/abs/2601.14660v1)** | 2026-01-21 |  |
| **[Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](https://arxiv.org/abs/2509.01631v2)** | 2026-01-21 | EACL 2026 |
| **[An LLM Agent-based Framework for Whaling Countermeasures](https://arxiv.org/abs/2601.14606v1)** | 2026-01-21 |  |
| **[Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks](https://arxiv.org/abs/2601.14601v1)** | 2026-01-21 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing](https://arxiv.org/abs/2601.16200v1)** | 2026-01-22 | Under review |
| **[Attacks on Approximate Caches in Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.20424v3)** | 2026-01-22 | <details><summary>Accep...</summary><p>Accepted by Usenix Security 2026</p></details> |
| **[Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137v2)** | 2026-01-22 | 13 pages, 5 figures |
| **[Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801v1)** | 2026-01-22 |  |
| **[Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization](https://arxiv.org/abs/2601.01747v4)** | 2026-01-22 | EACL |
| **[Robust Fake News Detection using Large Language Models under Adversarial Sentiment Attacks](https://arxiv.org/abs/2601.15277v1)** | 2026-01-21 |  |
| **[Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111v1)** | 2026-01-21 | EACL 2026 Main |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v3)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version). Update the cited references</p></details> |
| **[STEAD: Robust Provably Secure Linguistic Steganography with Diffusion Language Model](https://arxiv.org/abs/2601.14778v1)** | 2026-01-21 | NeurIPS 2025 poster |
| **[Neural Honeytrace: Plug&Play Watermarking Framework against Model Extraction Attacks](https://arxiv.org/abs/2501.09328v4)** | 2026-01-21 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing](https://arxiv.org/abs/2601.16200v1)** | 2026-01-22 | Under review |
| **[Attacks on Approximate Caches in Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.20424v3)** | 2026-01-22 | <details><summary>Accep...</summary><p>Accepted by Usenix Security 2026</p></details> |
| **[Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137v2)** | 2026-01-22 | 13 pages, 5 figures |
| **[Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801v1)** | 2026-01-22 |  |
| **[Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization](https://arxiv.org/abs/2601.01747v4)** | 2026-01-22 | EACL |
| **[Robust Fake News Detection using Large Language Models under Adversarial Sentiment Attacks](https://arxiv.org/abs/2601.15277v1)** | 2026-01-21 |  |
| **[Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111v1)** | 2026-01-21 | EACL 2026 Main |
| **[PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration](https://arxiv.org/abs/2512.08809v3)** | 2026-01-21 | <details><summary>Accep...</summary><p>Accepted at IEEE INFOCOM 2026 (full version). Update the cited references</p></details> |
| **[STEAD: Robust Provably Secure Linguistic Steganography with Diffusion Language Model](https://arxiv.org/abs/2601.14778v1)** | 2026-01-21 | NeurIPS 2025 poster |
| **[Neural Honeytrace: Plug&Play Watermarking Framework against Model Extraction Attacks](https://arxiv.org/abs/2501.09328v4)** | 2026-01-21 |  |

