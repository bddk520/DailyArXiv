---
title: Latest 15 Papers - June 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v4)** | 2025-06-09 |  |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v1)** | 2025-06-09 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](http://arxiv.org/abs/2412.15289v4)** | 2025-06-09 | <details><summary>To ap...</summary><p>To appear at Findings of ACL 2025</p></details> |
| **[Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](http://arxiv.org/abs/2506.07645v1)** | 2025-06-09 |  |
| **[Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](http://arxiv.org/abs/2506.07402v1)** | 2025-06-09 |  |
| **[Watermark under Fire: A Robustness Evaluation of LLM Watermarking](http://arxiv.org/abs/2411.13425v3)** | 2025-06-07 | 22 pages |
| **[Short-length Adversarial Training Helps LLMs Defend Long-length Jailbreak Attacks: Theoretical and Empirical Evidence](http://arxiv.org/abs/2502.04204v2)** | 2025-06-07 |  |
| **[Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance](http://arxiv.org/abs/2506.06444v1)** | 2025-06-06 | 19 pages |
| **[The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text](http://arxiv.org/abs/2502.14921v2)** | 2025-06-06 | <details><summary>42nd ...</summary><p>42nd International Conference on Machine Learning (ICML 2025)</p></details> |
| **[FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting](http://arxiv.org/abs/2501.16029v2)** | 2025-06-06 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Is poisoning a real threat to LLM alignment? Maybe more so than you think](http://arxiv.org/abs/2406.12091v4)** | 2025-06-09 |  |
| **[RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](http://arxiv.org/abs/2506.07736v1)** | 2025-06-09 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](http://arxiv.org/abs/2412.15289v4)** | 2025-06-09 | <details><summary>To ap...</summary><p>To appear at Findings of ACL 2025</p></details> |
| **[Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](http://arxiv.org/abs/2506.07645v1)** | 2025-06-09 |  |
| **[TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts](http://arxiv.org/abs/2506.07596v1)** | 2025-06-09 | <details><summary>26 pa...</summary><p>26 pages, 25 tables, 13 figures, 2 algorithms, to appear in the 43th USENIX Security Symposium (USENIX Security 2025)</p></details> |
| **[Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](http://arxiv.org/abs/2506.07402v1)** | 2025-06-09 |  |
| **[Watermark under Fire: A Robustness Evaluation of LLM Watermarking](http://arxiv.org/abs/2411.13425v3)** | 2025-06-07 | 22 pages |
| **[Short-length Adversarial Training Helps LLMs Defend Long-length Jailbreak Attacks: Theoretical and Empirical Evidence](http://arxiv.org/abs/2502.04204v2)** | 2025-06-07 |  |
| **[Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance](http://arxiv.org/abs/2506.06444v1)** | 2025-06-06 | 19 pages |
| **[The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text](http://arxiv.org/abs/2502.14921v2)** | 2025-06-06 | <details><summary>42nd ...</summary><p>42nd International Conference on Machine Learning (ICML 2025)</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TokenBreak: Bypassing Text Classification Models Through Token Manipulation](http://arxiv.org/abs/2506.07948v1)** | 2025-06-09 |  |
| **[Adversarial Attack Classification and Robustness Testing for Large Language Models for Code](http://arxiv.org/abs/2506.07942v1)** | 2025-06-09 |  |
| **[SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark](http://arxiv.org/abs/2506.07888v1)** | 2025-06-09 | <details><summary>To Ap...</summary><p>To Appear in the 34th USENIX Security Symposium, August 13-15, 2025</p></details> |
| **[Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability](http://arxiv.org/abs/2506.07804v1)** | 2025-06-09 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v2)** | 2025-06-09 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (main)</p></details> |
| **[Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](http://arxiv.org/abs/2506.07645v1)** | 2025-06-09 |  |
| **[Explore the vulnerability of black-box models via diffusion models](http://arxiv.org/abs/2506.07590v1)** | 2025-06-09 |  |
| **[MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity](http://arxiv.org/abs/2506.07586v1)** | 2025-06-09 |  |
| **[Attacking Attention of Foundation Models Disrupts Downstream Tasks](http://arxiv.org/abs/2506.05394v2)** | 2025-06-09 | <details><summary>Paper...</summary><p>Paper published at CVPR 2025 Workshop Advml</p></details> |
| **[Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](http://arxiv.org/abs/2506.07468v1)** | 2025-06-09 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TokenBreak: Bypassing Text Classification Models Through Token Manipulation](http://arxiv.org/abs/2506.07948v1)** | 2025-06-09 |  |
| **[Adversarial Attack Classification and Robustness Testing for Large Language Models for Code](http://arxiv.org/abs/2506.07942v1)** | 2025-06-09 |  |
| **[SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark](http://arxiv.org/abs/2506.07888v1)** | 2025-06-09 | <details><summary>To Ap...</summary><p>To Appear in the 34th USENIX Security Symposium, August 13-15, 2025</p></details> |
| **[Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability](http://arxiv.org/abs/2506.07804v1)** | 2025-06-09 |  |
| **[Representation Bending for Large Language Model Safety](http://arxiv.org/abs/2504.01550v2)** | 2025-06-09 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (main)</p></details> |
| **[Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](http://arxiv.org/abs/2506.07645v1)** | 2025-06-09 |  |
| **[Explore the vulnerability of black-box models via diffusion models](http://arxiv.org/abs/2506.07590v1)** | 2025-06-09 |  |
| **[MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity](http://arxiv.org/abs/2506.07586v1)** | 2025-06-09 |  |
| **[Attacking Attention of Foundation Models Disrupts Downstream Tasks](http://arxiv.org/abs/2506.05394v2)** | 2025-06-09 | <details><summary>Paper...</summary><p>Paper published at CVPR 2025 Workshop Advml</p></details> |
| **[Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](http://arxiv.org/abs/2506.07468v1)** | 2025-06-09 |  |

