---
title: Latest 15 Papers - November 26, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization](https://arxiv.org/abs/2511.19218v1)** | 2025-11-24 |  |
| **[Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment](https://arxiv.org/abs/2511.06852v4)** | 2025-11-24 | AAAI-26-AIA |
| **[RoguePrompt: Dual-Layer Ciphering for Self-Reconstruction to Circumvent LLM Moderation](https://arxiv.org/abs/2511.18790v1)** | 2025-11-24 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](https://arxiv.org/abs/2412.15289v5)** | 2025-11-24 | <details><summary>ACL F...</summary><p>ACL Findings 2025. Welcome to employ SATA as a baseline</p></details> |
| **[DarkMind: Latent Chain-of-Thought Backdoor in Customized LLMs](https://arxiv.org/abs/2501.18617v2)** | 2025-11-23 | <details><summary>19 pa...</summary><p>19 pages, 15 figures, 12 tables</p></details> |
| **[TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization](https://arxiv.org/abs/2511.18581v1)** | 2025-11-23 |  |
| **[Shadows in the Code: Exploring the Risks and Defenses of LLM-based Multi-Agent Software Development Systems](https://arxiv.org/abs/2511.18467v1)** | 2025-11-23 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026 Alignment Track</p></details> |
| **[Exploring Potential Prompt Injection Attacks in Federated Military LLMs and Their Mitigation](https://arxiv.org/abs/2501.18416v2)** | 2025-11-23 | <details><summary>Accep...</summary><p>Accepted to the 3rd International Workshop on Dataspaces and Digital Twins for Critical Entities and Smart Urban Communities - IEEE BigData 2025</p></details> |
| **[Think Fast: Real-Time IoT Intrusion Reasoning Using IDS and LLMs at the Edge Gateway](https://arxiv.org/abs/2511.18230v1)** | 2025-11-23 |  |
| **[Incalmo: An Autonomous LLM-assisted System for Red Teaming Multi-Host Networks](https://arxiv.org/abs/2501.16466v4)** | 2025-11-22 | 18 pages, 15 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization](https://arxiv.org/abs/2511.19218v1)** | 2025-11-24 |  |
| **[Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment](https://arxiv.org/abs/2511.06852v4)** | 2025-11-24 | AAAI-26-AIA |
| **[RoguePrompt: Dual-Layer Ciphering for Self-Reconstruction to Circumvent LLM Moderation](https://arxiv.org/abs/2511.18790v1)** | 2025-11-24 |  |
| **[SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage](https://arxiv.org/abs/2412.15289v5)** | 2025-11-24 | <details><summary>ACL F...</summary><p>ACL Findings 2025. Welcome to employ SATA as a baseline</p></details> |
| **[DarkMind: Latent Chain-of-Thought Backdoor in Customized LLMs](https://arxiv.org/abs/2501.18617v2)** | 2025-11-23 | <details><summary>19 pa...</summary><p>19 pages, 15 figures, 12 tables</p></details> |
| **[TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization](https://arxiv.org/abs/2511.18581v1)** | 2025-11-23 |  |
| **[Shadows in the Code: Exploring the Risks and Defenses of LLM-based Multi-Agent Software Development Systems](https://arxiv.org/abs/2511.18467v1)** | 2025-11-23 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026 Alignment Track</p></details> |
| **[Exploring Potential Prompt Injection Attacks in Federated Military LLMs and Their Mitigation](https://arxiv.org/abs/2501.18416v2)** | 2025-11-23 | <details><summary>Accep...</summary><p>Accepted to the 3rd International Workshop on Dataspaces and Digital Twins for Critical Entities and Smart Urban Communities - IEEE BigData 2025</p></details> |
| **[Think Fast: Real-Time IoT Intrusion Reasoning Using IDS and LLMs at the Edge Gateway](https://arxiv.org/abs/2511.18230v1)** | 2025-11-23 |  |
| **[Incalmo: An Autonomous LLM-assisted System for Red Teaming Multi-Host Networks](https://arxiv.org/abs/2501.16466v4)** | 2025-11-22 | 18 pages, 15 figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization](https://arxiv.org/abs/2511.19248v1)** | 2025-11-24 | <details><summary>13 pa...</summary><p>13 pages, 3 figures, 2 tables</p></details> |
| **[Defending Large Language Models Against Jailbreak Exploits with Responsible AI Considerations](https://arxiv.org/abs/2511.18933v1)** | 2025-11-24 | <details><summary>20 pa...</summary><p>20 pages including appendix; technical report; NeurIPS 2024 style</p></details> |
| **[BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://arxiv.org/abs/2511.18921v1)** | 2025-11-24 |  |
| **[Future-Back Threat Modeling: A Foresight-Driven Security Framework](https://arxiv.org/abs/2511.16088v2)** | 2025-11-24 |  |
| **[Large Language Model Unlearning for Source Code](https://arxiv.org/abs/2506.17125v2)** | 2025-11-24 | Accepted to AAAI'26 |
| **[SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Global Game-Theoretic Analysis of Asymmetric Threats](https://arxiv.org/abs/2411.11195v5)** | 2025-11-24 |  |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](https://arxiv.org/abs/2510.02712v2)** | 2025-11-23 |  |
| **[When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models](https://arxiv.org/abs/2511.16203v2)** | 2025-11-23 |  |
| **[BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792v3)** | 2025-11-23 |  |
| **[Do Spikes Protect Privacy? Investigating Black-Box Model Inversion Attacks in Spiking Neural Networks](https://arxiv.org/abs/2502.05509v2)** | 2025-11-23 | 7 pages, 4 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization](https://arxiv.org/abs/2511.19248v1)** | 2025-11-24 | <details><summary>13 pa...</summary><p>13 pages, 3 figures, 2 tables</p></details> |
| **[Defending Large Language Models Against Jailbreak Exploits with Responsible AI Considerations](https://arxiv.org/abs/2511.18933v1)** | 2025-11-24 | <details><summary>20 pa...</summary><p>20 pages including appendix; technical report; NeurIPS 2024 style</p></details> |
| **[BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://arxiv.org/abs/2511.18921v1)** | 2025-11-24 |  |
| **[Future-Back Threat Modeling: A Foresight-Driven Security Framework](https://arxiv.org/abs/2511.16088v2)** | 2025-11-24 |  |
| **[Large Language Model Unlearning for Source Code](https://arxiv.org/abs/2506.17125v2)** | 2025-11-24 | Accepted to AAAI'26 |
| **[SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Global Game-Theoretic Analysis of Asymmetric Threats](https://arxiv.org/abs/2411.11195v5)** | 2025-11-24 |  |
| **[Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks](https://arxiv.org/abs/2510.02712v2)** | 2025-11-23 |  |
| **[When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models](https://arxiv.org/abs/2511.16203v2)** | 2025-11-23 |  |
| **[BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](https://arxiv.org/abs/2510.20792v3)** | 2025-11-23 |  |
| **[Do Spikes Protect Privacy? Investigating Black-Box Model Inversion Attacks in Spiking Neural Networks](https://arxiv.org/abs/2502.05509v2)** | 2025-11-23 | 7 pages, 4 figures |

