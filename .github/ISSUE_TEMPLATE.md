---
title: Latest 15 Papers - February 24, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092v1)** | 2026-02-20 | 39 pages, 10 figures |
| **[Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778v1)** | 2026-02-19 | Pre-print |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |
| **[Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346v2)** | 2026-02-19 |  |
| **[AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901v1)** | 2026-02-18 |  |
| **[NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835v1)** | 2026-02-18 |  |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238v2)** | 2026-02-18 |  |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v2)** | 2026-02-18 |  |
| **[The Trojan Example: Jailbreaking LLMs through Template Filling and Unsafety Reasoning](https://arxiv.org/abs/2510.21190v2)** | 2026-02-18 | under review |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092v1)** | 2026-02-20 | 39 pages, 10 figures |
| **[Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778v1)** | 2026-02-19 | Pre-print |
| **[What Makes a Good LLM Agent for Real-world Penetration Testing?](https://arxiv.org/abs/2602.17622v1)** | 2026-02-19 |  |
| **[Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346v2)** | 2026-02-19 |  |
| **[AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901v1)** | 2026-02-18 |  |
| **[NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835v1)** | 2026-02-18 |  |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238v2)** | 2026-02-18 |  |
| **[Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001v2)** | 2026-02-18 |  |
| **[The Trojan Example: Jailbreaking LLMs through Template Filling and Unsafety Reasoning](https://arxiv.org/abs/2510.21190v2)** | 2026-02-18 | under review |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models](https://arxiv.org/abs/2602.11495v2)** | 2026-02-20 |  |
| **[ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031v2)** | 2026-02-20 |  |
| **[TFL: Targeted Bit-Flip Attack on Large Language Model](https://arxiv.org/abs/2602.17837v1)** | 2026-02-19 | <details><summary>13 pa...</summary><p>13 pages, 11 figures. Preprint</p></details> |
| **[Defining and Evaluating Physical Safety for Large Language Models](https://arxiv.org/abs/2411.02317v2)** | 2026-02-19 |  |
| **[Grothendieck Topologies and Sheaf-Theoretic Foundations of Cryptographic Security: Attacker Models and $Σ$-Protocols as the First Step](https://arxiv.org/abs/2602.17301v1)** | 2026-02-19 | <details><summary>9 pag...</summary><p>9 pages (12pt). We present a categorical and Grothendieck-topological model of Σ-protocols, providing a formal structural interpretation of interactive proof systems, knowledge soundness, and attacker models</p></details> |
| **[Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977v1)** | 2026-02-19 | Pre-print |
| **[IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832v1)** | 2026-02-18 | <details><summary>Accep...</summary><p>Accepted in EACL Industry Track Oral, 2026</p></details> |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents](https://arxiv.org/abs/2602.16520v1)** | 2026-02-18 | <details><summary>5 pag...</summary><p>5 pages and 1 figure. Appendix: an additional 5 pages</p></details> |
| **[Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks](https://arxiv.org/abs/2602.16760v1)** | 2026-02-18 | <details><summary>21 pa...</summary><p>21 pages, 21 tables, no figures</p></details> |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models](https://arxiv.org/abs/2602.11495v2)** | 2026-02-20 |  |
| **[ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031v2)** | 2026-02-20 |  |
| **[TFL: Targeted Bit-Flip Attack on Large Language Model](https://arxiv.org/abs/2602.17837v1)** | 2026-02-19 | <details><summary>13 pa...</summary><p>13 pages, 11 figures. Preprint</p></details> |
| **[Defining and Evaluating Physical Safety for Large Language Models](https://arxiv.org/abs/2411.02317v2)** | 2026-02-19 |  |
| **[Grothendieck Topologies and Sheaf-Theoretic Foundations of Cryptographic Security: Attacker Models and $Σ$-Protocols as the First Step](https://arxiv.org/abs/2602.17301v1)** | 2026-02-19 | <details><summary>9 pag...</summary><p>9 pages (12pt). We present a categorical and Grothendieck-topological model of Σ-protocols, providing a formal structural interpretation of interactive proof systems, knowledge soundness, and attacker models</p></details> |
| **[Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977v1)** | 2026-02-19 | Pre-print |
| **[IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832v1)** | 2026-02-18 | <details><summary>Accep...</summary><p>Accepted in EACL Industry Track Oral, 2026</p></details> |
| **[Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800v1)** | 2026-02-18 | 24 pages, 10 figures |
| **[Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents](https://arxiv.org/abs/2602.16520v1)** | 2026-02-18 | <details><summary>5 pag...</summary><p>5 pages and 1 figure. Appendix: an additional 5 pages</p></details> |
| **[Privacy-Aware Split Inference with Speculative Decoding for Large Language Models over Wide-Area Networks](https://arxiv.org/abs/2602.16760v1)** | 2026-02-18 | <details><summary>21 pa...</summary><p>21 pages, 21 tables, no figures</p></details> |

