---
title: Latest 15 Papers - January 29, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410v1)** | 2026-01-27 |  |
| **[Reasoning Hijacking: Subverting LLM Classification via Decision-Criteria Injection](https://arxiv.org/abs/2601.10294v2)** | 2026-01-27 |  |
| **[SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks](https://arxiv.org/abs/2601.19174v1)** | 2026-01-27 |  |
| **[Proactive Hardening of LLM Defenses with HASTE](https://arxiv.org/abs/2601.19051v1)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted at peer review NDSS 2026, Last-X workshop. Camera ready copy forthcoming</p></details> |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v1)** | 2026-01-26 |  |
| **[AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110v1)** | 2026-01-26 |  |
| **[Jailbreak-as-a-Service++: Unveiling Distributed AI-Driven Malicious Information Campaigns Powered by LLM Crowdsourcing](https://arxiv.org/abs/2505.21184v4)** | 2026-01-24 |  |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697v2)** | 2026-01-24 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410v1)** | 2026-01-27 |  |
| **[Reasoning Hijacking: Subverting LLM Classification via Decision-Criteria Injection](https://arxiv.org/abs/2601.10294v2)** | 2026-01-27 |  |
| **[SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks](https://arxiv.org/abs/2601.19174v1)** | 2026-01-27 |  |
| **[Proactive Hardening of LLM Defenses with HASTE](https://arxiv.org/abs/2601.19051v1)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted at peer review NDSS 2026, Last-X workshop. Camera ready copy forthcoming</p></details> |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292v1)** | 2026-01-26 |  |
| **[AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110v1)** | 2026-01-26 |  |
| **[Jailbreak-as-a-Service++: Unveiling Distributed AI-Driven Malicious Information Campaigns Powered by LLM Crowdsourcing](https://arxiv.org/abs/2505.21184v4)** | 2026-01-24 |  |
| **[Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549v1)** | 2026-01-24 |  |
| **[Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697v2)** | 2026-01-24 | <details><summary>Proje...</summary><p>Project Hompage: https://tokenbuncher.github.io/</p></details> |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Learning to Detect Unseen Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2508.09201v4)** | 2026-01-27 | <details><summary>12 pa...</summary><p>12 pages; Previously this version appeared as arXiv:2510.15430 which was submitted as a new work by accident</p></details> |
| **[Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models](https://arxiv.org/abs/2601.13948v2)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted by ICASSP2026</p></details> |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303v4)** | 2026-01-27 | <details><summary>To ap...</summary><p>To appear in WWW 2026. 12 pages</p></details> |
| **[Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation](https://arxiv.org/abs/2601.19090v1)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted by IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</p></details> |
| **[Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models](https://arxiv.org/abs/2601.19061v1)** | 2026-01-27 |  |
| **[Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models](https://arxiv.org/abs/2411.07559v2)** | 2026-01-26 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 Main</p></details> |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[CtrlRAG: Black-box Document Poisoning Attacks for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2503.06950v2)** | 2026-01-26 |  |
| **[Beyond Data Privacy: New Privacy Risks for Large Language Models](https://arxiv.org/abs/2509.14278v2)** | 2026-01-26 | <details><summary>Publi...</summary><p>Published in the IEEE Data Engineering Bulletin: http://sites.computer.org/debull/A25dec/issue1.htm</p></details> |
| **[Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection](https://arxiv.org/abs/2601.18845v1)** | 2026-01-26 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Learning to Detect Unseen Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2508.09201v4)** | 2026-01-27 | <details><summary>12 pa...</summary><p>12 pages; Previously this version appeared as arXiv:2510.15430 which was submitted as a new work by accident</p></details> |
| **[Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models](https://arxiv.org/abs/2601.13948v2)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted by ICASSP2026</p></details> |
| **[DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing](https://arxiv.org/abs/2510.15303v4)** | 2026-01-27 | <details><summary>To ap...</summary><p>To appear in WWW 2026. 12 pages</p></details> |
| **[Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation](https://arxiv.org/abs/2601.19090v1)** | 2026-01-27 | <details><summary>Accep...</summary><p>Accepted by IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)</p></details> |
| **[Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models](https://arxiv.org/abs/2601.19061v1)** | 2026-01-27 |  |
| **[Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models](https://arxiv.org/abs/2411.07559v2)** | 2026-01-26 | <details><summary>Accep...</summary><p>Accepted to EACL 2026 Main</p></details> |
| **[$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754v1)** | 2026-01-26 |  |
| **[CtrlRAG: Black-box Document Poisoning Attacks for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2503.06950v2)** | 2026-01-26 |  |
| **[Beyond Data Privacy: New Privacy Risks for Large Language Models](https://arxiv.org/abs/2509.14278v2)** | 2026-01-26 | <details><summary>Publi...</summary><p>Published in the IEEE Data Engineering Bulletin: http://sites.computer.org/debull/A25dec/issue1.htm</p></details> |
| **[Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection](https://arxiv.org/abs/2601.18845v1)** | 2026-01-26 |  |

