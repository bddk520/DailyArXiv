---
title: Latest 15 Papers - March 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework to Assess Multilingual Vulnerabilities of LLMs](http://arxiv.org/abs/2503.13081v1)** | 2025-03-17 |  |
| **[TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning](http://arxiv.org/abs/2404.19597v3)** | 2025-03-17 | work in progress |
| **[Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning](http://arxiv.org/abs/2406.13356v4)** | 2025-03-17 | <details><summary>ICLR ...</summary><p>ICLR 2025, 32 pages, 8 figures, 9 tables</p></details> |
| **[When "Competency" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers](http://arxiv.org/abs/2402.10601v3)** | 2025-03-16 |  |
| **[JailGuard: A Universal Detection Framework for LLM Prompt-based Attacks](http://arxiv.org/abs/2312.10766v4)** | 2025-03-15 | 40 pages, 12 figures |
| **[The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](http://arxiv.org/abs/2406.12480v2)** | 2025-03-12 | ICLR 2025 Spotlight |
| **[CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data](http://arxiv.org/abs/2503.09334v1)** | 2025-03-12 | <details><summary>The p...</summary><p>The paper is submitted to "The 48th International ACM SIGIR Conference on Research and Development in Information Retrieval" and is currently under review</p></details> |
| **[DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios](http://arxiv.org/abs/2410.23746v3)** | 2025-03-12 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)</p></details> |
| **[A Survey on Trustworthy LLM Agents: Threats and Countermeasures](http://arxiv.org/abs/2503.09648v1)** | 2025-03-12 |  |
| **[Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States](http://arxiv.org/abs/2503.09066v1)** | 2025-03-12 | 4 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Framework to Assess Multilingual Vulnerabilities of LLMs](http://arxiv.org/abs/2503.13081v1)** | 2025-03-17 |  |
| **[TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning](http://arxiv.org/abs/2404.19597v3)** | 2025-03-17 | work in progress |
| **[Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning](http://arxiv.org/abs/2406.13356v4)** | 2025-03-17 | <details><summary>ICLR ...</summary><p>ICLR 2025, 32 pages, 8 figures, 9 tables</p></details> |
| **[When "Competency" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers](http://arxiv.org/abs/2402.10601v3)** | 2025-03-16 |  |
| **[Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking](http://arxiv.org/abs/2503.04636v2)** | 2025-03-15 | <details><summary>Accep...</summary><p>Accepted by the ICLR 2025 Workshop on GenAI Watermarking</p></details> |
| **[JailGuard: A Universal Detection Framework for LLM Prompt-based Attacks](http://arxiv.org/abs/2312.10766v4)** | 2025-03-15 | 40 pages, 12 figures |
| **[The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](http://arxiv.org/abs/2406.12480v2)** | 2025-03-12 | ICLR 2025 Spotlight |
| **[CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data](http://arxiv.org/abs/2503.09334v1)** | 2025-03-12 | <details><summary>The p...</summary><p>The paper is submitted to "The 48th International ACM SIGIR Conference on Research and Development in Information Retrieval" and is currently under review</p></details> |
| **[DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios](http://arxiv.org/abs/2410.23746v3)** | 2025-03-12 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)</p></details> |
| **[A Survey on Trustworthy LLM Agents: Threats and Countermeasures](http://arxiv.org/abs/2503.09648v1)** | 2025-03-12 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation](http://arxiv.org/abs/2409.01586v4)** | 2025-03-17 |  |
| **[ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction](http://arxiv.org/abs/2503.13224v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted at the ICLR Workshop on Neural Network Weights as a New Data Modality 2025</p></details> |
| **[How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark](http://arxiv.org/abs/2503.12990v1)** | 2025-03-17 |  |
| **[BLIA: Detect model memorization in binary classification model through passive Label Inference attack](http://arxiv.org/abs/2503.12801v1)** | 2025-03-17 |  |
| **[A Model Stealing Attack Against Multi-Exit Networks](http://arxiv.org/abs/2305.13584v2)** | 2025-03-17 |  |
| **[Algebraic Adversarial Attacks on Explainability Models](http://arxiv.org/abs/2503.12683v1)** | 2025-03-16 |  |
| **[Poisoned Source Code Detection in Code Models](http://arxiv.org/abs/2502.13459v2)** | 2025-03-16 |  |
| **[Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy](http://arxiv.org/abs/2503.12497v1)** | 2025-03-16 | <details><summary>11 pa...</summary><p>11 pages, 7 figures, published in AAAI 2025</p></details> |
| **[h4rm3l: A language for Composable Jailbreak Attack Synthesis](http://arxiv.org/abs/2408.04811v3)** | 2025-03-16 |  |
| **[From ML to LLM: Evaluating the Robustness of Phishing Webpage Detection Models against Adversarial Attacks](http://arxiv.org/abs/2407.20361v3)** | 2025-03-15 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation](http://arxiv.org/abs/2409.01586v4)** | 2025-03-17 |  |
| **[ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction](http://arxiv.org/abs/2503.13224v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted at the ICLR Workshop on Neural Network Weights as a New Data Modality 2025</p></details> |
| **[How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark](http://arxiv.org/abs/2503.12990v1)** | 2025-03-17 |  |
| **[BLIA: Detect model memorization in binary classification model through passive Label Inference attack](http://arxiv.org/abs/2503.12801v1)** | 2025-03-17 |  |
| **[A Model Stealing Attack Against Multi-Exit Networks](http://arxiv.org/abs/2305.13584v2)** | 2025-03-17 |  |
| **[Algebraic Adversarial Attacks on Explainability Models](http://arxiv.org/abs/2503.12683v1)** | 2025-03-16 |  |
| **[Poisoned Source Code Detection in Code Models](http://arxiv.org/abs/2502.13459v2)** | 2025-03-16 |  |
| **[Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy](http://arxiv.org/abs/2503.12497v1)** | 2025-03-16 | <details><summary>11 pa...</summary><p>11 pages, 7 figures, published in AAAI 2025</p></details> |
| **[h4rm3l: A language for Composable Jailbreak Attack Synthesis](http://arxiv.org/abs/2408.04811v3)** | 2025-03-16 |  |
| **[Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking](http://arxiv.org/abs/2503.04636v2)** | 2025-03-15 | <details><summary>Accep...</summary><p>Accepted by the ICLR 2025 Workshop on GenAI Watermarking</p></details> |

