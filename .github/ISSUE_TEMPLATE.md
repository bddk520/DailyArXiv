---
title: Latest 15 Papers - January 09, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SearchAttack: Red-Teaming LLMs against Real-World Threats via Framing Unsafe Web Information-Seeking Tasks](https://arxiv.org/abs/2601.04093v1)** | 2026-01-07 | <details><summary>We fi...</summary><p>We find that the key to jailbreak the LLM is objectifying its safety responsibility, thus we delegate the open-web to inject harmful semantics and get the huge gain from unmoderated web resources</p></details> |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](https://arxiv.org/abs/2508.10390v3)** | 2026-01-07 |  |
| **[Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](https://arxiv.org/abs/2509.01211v2)** | 2026-01-07 |  |
| **[Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools](https://arxiv.org/abs/2508.02110v2)** | 2026-01-07 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases](https://arxiv.org/abs/2601.03630v1)** | 2026-01-07 | 11 pages, 4 figures |
| **[ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification](https://arxiv.org/abs/2601.03600v1)** | 2026-01-07 |  |
| **[Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense](https://arxiv.org/abs/2601.03594v1)** | 2026-01-07 |  |
| **[Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks](https://arxiv.org/abs/2601.03420v1)** | 2026-01-06 |  |
| **[Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584v2)** | 2026-01-06 | <details><summary>Code ...</summary><p>Code is available at https://github.com/j-hoscilowicz/instrumental_steering</p></details> |
| **[The Anatomy of Conversational Scams: A Topic-Based Red Teaming Analysis of Multi-Turn Interactions in LLMs](https://arxiv.org/abs/2601.03134v1)** | 2026-01-06 |  |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SearchAttack: Red-Teaming LLMs against Real-World Threats via Framing Unsafe Web Information-Seeking Tasks](https://arxiv.org/abs/2601.04093v1)** | 2026-01-07 | <details><summary>We fi...</summary><p>We find that the key to jailbreak the LLM is objectifying its safety responsibility, thus we delegate the open-web to inject harmful semantics and get the huge gain from unmoderated web resources</p></details> |
| **[Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts](https://arxiv.org/abs/2508.10390v3)** | 2026-01-07 |  |
| **[Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](https://arxiv.org/abs/2509.01211v2)** | 2026-01-07 |  |
| **[Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools](https://arxiv.org/abs/2508.02110v2)** | 2026-01-07 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases](https://arxiv.org/abs/2601.03630v1)** | 2026-01-07 | 11 pages, 4 figures |
| **[ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification](https://arxiv.org/abs/2601.03600v1)** | 2026-01-07 |  |
| **[Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense](https://arxiv.org/abs/2601.03594v1)** | 2026-01-07 |  |
| **[Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks](https://arxiv.org/abs/2601.03420v1)** | 2026-01-06 |  |
| **[Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584v2)** | 2026-01-06 | <details><summary>Code ...</summary><p>Code is available at https://github.com/j-hoscilowicz/instrumental_steering</p></details> |
| **[The Anatomy of Conversational Scams: A Topic-Based Red Teaming Analysis of Multi-Turn Interactions in LLMs](https://arxiv.org/abs/2601.03134v1)** | 2026-01-06 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense](https://arxiv.org/abs/2601.04034v1)** | 2026-01-07 |  |
| **[TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](https://arxiv.org/abs/2505.20118v4)** | 2026-01-07 | <details><summary>9 pag...</summary><p>9 pages, 5 figures To be presented in the Conference on Empirical Methods in Natural Language Processing, 2025</p></details> |
| **[Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://arxiv.org/abs/2512.12069v2)** | 2026-01-07 | 37 pages, 13 figures |
| **[Inference Attacks Against Graph Generative Diffusion Models](https://arxiv.org/abs/2601.03701v1)** | 2026-01-07 | <details><summary>This ...</summary><p>This work has been accepted by USENIX Security 2026</p></details> |
| **[RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models](https://arxiv.org/abs/2601.03699v1)** | 2026-01-07 |  |
| **[Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases](https://arxiv.org/abs/2601.03630v1)** | 2026-01-07 | 11 pages, 4 figures |
| **[DeepLeak: Privacy Enhancing Hardening of Model Explanations Against Membership Leakage](https://arxiv.org/abs/2601.03429v1)** | 2026-01-06 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 8 tables. This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (IEEE SaTML 2026)</p></details> |
| **[GAMBIT: A Gamified Jailbreak Framework for Multimodal Large Language Models](https://arxiv.org/abs/2601.03416v1)** | 2026-01-06 |  |
| **[Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042v2)** | 2026-01-06 |  |
| **[Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972v2)** | 2026-01-06 | 17 pages, 4 figures |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense](https://arxiv.org/abs/2601.04034v1)** | 2026-01-07 |  |
| **[TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](https://arxiv.org/abs/2505.20118v4)** | 2026-01-07 | <details><summary>9 pag...</summary><p>9 pages, 5 figures To be presented in the Conference on Empirical Methods in Natural Language Processing, 2025</p></details> |
| **[Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://arxiv.org/abs/2512.12069v2)** | 2026-01-07 | 37 pages, 13 figures |
| **[Inference Attacks Against Graph Generative Diffusion Models](https://arxiv.org/abs/2601.03701v1)** | 2026-01-07 | <details><summary>This ...</summary><p>This work has been accepted by USENIX Security 2026</p></details> |
| **[RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models](https://arxiv.org/abs/2601.03699v1)** | 2026-01-07 |  |
| **[Reasoning Model Is Superior LLM-Judge, Yet Suffers from Biases](https://arxiv.org/abs/2601.03630v1)** | 2026-01-07 | 11 pages, 4 figures |
| **[DeepLeak: Privacy Enhancing Hardening of Model Explanations Against Membership Leakage](https://arxiv.org/abs/2601.03429v1)** | 2026-01-06 | <details><summary>17 pa...</summary><p>17 pages, 6 figures, 8 tables. This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (IEEE SaTML 2026)</p></details> |
| **[GAMBIT: A Gamified Jailbreak Framework for Multimodal Large Language Models](https://arxiv.org/abs/2601.03416v1)** | 2026-01-06 |  |
| **[Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042v2)** | 2026-01-06 |  |
| **[Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972v2)** | 2026-01-06 | 17 pages, 4 figures |

