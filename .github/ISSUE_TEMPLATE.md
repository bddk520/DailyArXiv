---
title: Latest 15 Papers - August 26, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v1)** | 2025-08-22 |  |
| **[Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](http://arxiv.org/abs/2508.05469v2)** | 2025-08-21 | <details><summary>Add A...</summary><p>Add AUC results, pre-reg conformance, theory section clarification. 12 pages</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v2)** | 2025-08-21 |  |
| **[Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](http://arxiv.org/abs/2508.15449v1)** | 2025-08-21 | <details><summary>10 pa...</summary><p>10 pages, 9 figures, Under review as a full paper at AAAI 2026. A preliminary version is under review at the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](http://arxiv.org/abs/2508.15310v1)** | 2025-08-21 | EMNLP 2025 |
| **[MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs](http://arxiv.org/abs/2508.15036v1)** | 2025-08-20 | <details><summary>This ...</summary><p>This paper will appear in CCS 2025</p></details> |
| **[Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion](http://arxiv.org/abs/2508.15848v1)** | 2025-08-20 |  |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection](http://arxiv.org/abs/2508.14128v1)** | 2025-08-19 | 11 pages, 1 figure |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](http://arxiv.org/abs/2508.16347v1)** | 2025-08-22 |  |
| **[Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](http://arxiv.org/abs/2508.05469v2)** | 2025-08-21 | <details><summary>Add A...</summary><p>Add AUC results, pre-reg conformance, theory section clarification. 12 pages</p></details> |
| **[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v2)** | 2025-08-21 |  |
| **[Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](http://arxiv.org/abs/2508.15449v1)** | 2025-08-21 | <details><summary>10 pa...</summary><p>10 pages, 9 figures, Under review as a full paper at AAAI 2026. A preliminary version is under review at the NeurIPS 2025 Workshop on Reliable ML from Unreliable Data</p></details> |
| **[IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](http://arxiv.org/abs/2508.15310v1)** | 2025-08-21 | EMNLP 2025 |
| **[MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs](http://arxiv.org/abs/2508.15036v1)** | 2025-08-20 | <details><summary>This ...</summary><p>This paper will appear in CCS 2025</p></details> |
| **[Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion](http://arxiv.org/abs/2508.15848v1)** | 2025-08-20 |  |
| **["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](http://arxiv.org/abs/2505.14226v2)** | 2025-08-19 |  |
| **[Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](http://arxiv.org/abs/2508.09190v2)** | 2025-08-19 |  |
| **[CCFC: Core & Core-Full-Core Dual-Track Defense for LLM Jailbreak Protection](http://arxiv.org/abs/2508.14128v1)** | 2025-08-19 | 11 pages, 1 figure |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HAMSA: Hijacking Aligned Compact Models via Stealthy Automation](http://arxiv.org/abs/2508.16484v1)** | 2025-08-22 | <details><summary>9 pag...</summary><p>9 pages, 1 figure; article under review</p></details> |
| **[MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](http://arxiv.org/abs/2508.10991v2)** | 2025-08-22 |  |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v1)** | 2025-08-22 |  |
| **[from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors](http://arxiv.org/abs/2503.00038v4)** | 2025-08-22 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2412.12145</p></details> |
| **[An Investigation of Visual Foundation Models Robustness](http://arxiv.org/abs/2508.16225v1)** | 2025-08-22 |  |
| **[PickleBall: Secure Deserialization of Pickle-based Machine Learning Models](http://arxiv.org/abs/2508.15987v1)** | 2025-08-21 | <details><summary>To be...</summary><p>To be published in the proceedings of 2025 ACM CCS</p></details> |
| **[SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](http://arxiv.org/abs/2508.15648v1)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted by EMNLP 2025, 15 pages, 4 figures, 6 tables</p></details> |
| **[DualMark: Identifying Model and Training Data Origins in Generated Audio](http://arxiv.org/abs/2508.15521v1)** | 2025-08-21 | 13 pages, 5 figures |
| **[On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking](http://arxiv.org/abs/2508.15481v1)** | 2025-08-21 |  |
| **[A Study of Privacy-preserving Language Modeling Approaches](http://arxiv.org/abs/2508.15421v1)** | 2025-08-21 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HAMSA: Hijacking Aligned Compact Models via Stealthy Automation](http://arxiv.org/abs/2508.16484v1)** | 2025-08-22 | <details><summary>9 pag...</summary><p>9 pages, 1 figure; article under review</p></details> |
| **[MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](http://arxiv.org/abs/2508.10991v2)** | 2025-08-22 |  |
| **[Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](http://arxiv.org/abs/2508.16406v1)** | 2025-08-22 |  |
| **[from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors](http://arxiv.org/abs/2503.00038v4)** | 2025-08-22 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2412.12145</p></details> |
| **[An Investigation of Visual Foundation Models Robustness](http://arxiv.org/abs/2508.16225v1)** | 2025-08-22 |  |
| **[PickleBall: Secure Deserialization of Pickle-based Machine Learning Models](http://arxiv.org/abs/2508.15987v1)** | 2025-08-21 | <details><summary>To be...</summary><p>To be published in the proceedings of 2025 ACM CCS</p></details> |
| **[SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](http://arxiv.org/abs/2508.15648v1)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted by EMNLP 2025, 15 pages, 4 figures, 6 tables</p></details> |
| **[DualMark: Identifying Model and Training Data Origins in Generated Audio](http://arxiv.org/abs/2508.15521v1)** | 2025-08-21 | 13 pages, 5 figures |
| **[On Evaluating the Adversarial Robustness of Foundation Models for Multimodal Entity Linking](http://arxiv.org/abs/2508.15481v1)** | 2025-08-21 |  |
| **[A Study of Privacy-preserving Language Modeling Approaches](http://arxiv.org/abs/2508.15421v1)** | 2025-08-21 |  |

