---
title: Latest 15 Papers - February 11, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SearchAttack: Red-Teaming LLMs against Knowledge-to-Action Threats under Online Web Search](https://arxiv.org/abs/2601.04093v2)** | 2026-02-09 | <details><summary>Misus...</summary><p>Misusing LLM-driven search for harmful information-seeking poses serious risks. We characterize its usability and impact through a comprehensive red-teaming and evaluation</p></details> |
| **[Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.08621v1)** | 2026-02-09 |  |
| **[LLMs + Security = Trouble](https://arxiv.org/abs/2602.08422v1)** | 2026-02-09 |  |
| **[SoK: Trust-Authorization Mismatch in LLM Agent Interactions](https://arxiv.org/abs/2512.06914v2)** | 2026-02-09 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364v4)** | 2026-02-09 |  |
| **[Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation](https://arxiv.org/abs/2602.08062v1)** | 2026-02-08 |  |
| **[CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment](https://arxiv.org/abs/2602.08023v1)** | 2026-02-08 |  |
| **[Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software](https://arxiv.org/abs/2602.04894v2)** | 2026-02-08 | Preprint |
| **[Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model](https://arxiv.org/abs/2602.07878v1)** | 2026-02-08 |  |
| **[Capability-Based Scaling Trends for LLM-Based Red-Teaming](https://arxiv.org/abs/2505.20162v2)** | 2026-02-08 | <details><summary>Publi...</summary><p>Published as a conference paper at ICLR 2026</p></details> |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SearchAttack: Red-Teaming LLMs against Knowledge-to-Action Threats under Online Web Search](https://arxiv.org/abs/2601.04093v2)** | 2026-02-09 | <details><summary>Misus...</summary><p>Misusing LLM-driven search for harmful information-seeking poses serious risks. We characterize its usability and impact through a comprehensive red-teaming and evaluation</p></details> |
| **[Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.08621v1)** | 2026-02-09 |  |
| **[Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs](https://arxiv.org/abs/2602.08563v1)** | 2026-02-09 | <details><summary>Accep...</summary><p>Accepted at IEEE SaTML 2026</p></details> |
| **[LLMs + Security = Trouble](https://arxiv.org/abs/2602.08422v1)** | 2026-02-09 |  |
| **[SoK: Trust-Authorization Mismatch in LLM Agent Interactions](https://arxiv.org/abs/2512.06914v2)** | 2026-02-09 |  |
| **[Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364v4)** | 2026-02-09 |  |
| **[Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation](https://arxiv.org/abs/2602.08062v1)** | 2026-02-08 |  |
| **[CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment](https://arxiv.org/abs/2602.08023v1)** | 2026-02-08 |  |
| **[Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software](https://arxiv.org/abs/2602.04894v2)** | 2026-02-08 | Preprint |
| **[Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model](https://arxiv.org/abs/2602.07878v1)** | 2026-02-08 |  |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476v3)** | 2026-02-09 | <details><summary>This ...</summary><p>This paper is a revised version of a manuscript currently under revision at the Journal of Systems and Software</p></details> |
| **[Is Reasoning Capability Enough for Safety in Long-Context Language Models?](https://arxiv.org/abs/2602.08874v1)** | 2026-02-09 | 25 pages, 7 figures |
| **[ASIDE: Architectural Separation of Instructions and Data in Language Models](https://arxiv.org/abs/2503.10566v4)** | 2026-02-09 | ICLR 2026 paper |
| **[Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing](https://arxiv.org/abs/2602.08741v1)** | 2026-02-09 |  |
| **[Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.08621v1)** | 2026-02-09 |  |
| **[RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks](https://arxiv.org/abs/2602.08446v1)** | 2026-02-09 | <details><summary>This ...</summary><p>This paper has been accepted for publication in IEEE ICC 2026 and will be indexed in the IEEE Xplore Digital Library</p></details> |
| **[Multi-Robot Data-Free Continual Communicative Learning (CCL) from Black-Box Visual Place Recognition Models](https://arxiv.org/abs/2503.02256v3)** | 2026-02-09 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, technical report</p></details> |
| **[Grokking in Linear Models for Logistic Regression](https://arxiv.org/abs/2602.08302v1)** | 2026-02-09 |  |
| **[Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models](https://arxiv.org/abs/2601.10313v2)** | 2026-02-09 | 10 pages, 7 figures |
| **[Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?](https://arxiv.org/abs/2512.15769v2)** | 2026-02-09 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476v3)** | 2026-02-09 | <details><summary>This ...</summary><p>This paper is a revised version of a manuscript currently under revision at the Journal of Systems and Software</p></details> |
| **[Is Reasoning Capability Enough for Safety in Long-Context Language Models?](https://arxiv.org/abs/2602.08874v1)** | 2026-02-09 | 25 pages, 7 figures |
| **[ASIDE: Architectural Separation of Instructions and Data in Language Models](https://arxiv.org/abs/2503.10566v4)** | 2026-02-09 | ICLR 2026 paper |
| **[Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing](https://arxiv.org/abs/2602.08741v1)** | 2026-02-09 |  |
| **[Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs](https://arxiv.org/abs/2602.08621v1)** | 2026-02-09 |  |
| **[RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks](https://arxiv.org/abs/2602.08446v1)** | 2026-02-09 | <details><summary>This ...</summary><p>This paper has been accepted for publication in IEEE ICC 2026 and will be indexed in the IEEE Xplore Digital Library</p></details> |
| **[Multi-Robot Data-Free Continual Communicative Learning (CCL) from Black-Box Visual Place Recognition Models](https://arxiv.org/abs/2503.02256v3)** | 2026-02-09 | <details><summary>6 pag...</summary><p>6 pages, 4 figures, technical report</p></details> |
| **[Grokking in Linear Models for Logistic Regression](https://arxiv.org/abs/2602.08302v1)** | 2026-02-09 |  |
| **[Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models](https://arxiv.org/abs/2601.10313v2)** | 2026-02-09 | 10 pages, 7 figures |
| **[Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?](https://arxiv.org/abs/2512.15769v2)** | 2026-02-09 |  |

