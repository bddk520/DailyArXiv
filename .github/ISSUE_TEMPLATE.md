---
title: Latest 15 Papers - February 27, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Efficient Safety Retrofitting Against Jailbreaking for LLMs](http://arxiv.org/abs/2502.13603v2)** | 2025-02-25 |  |
| **[Towards Effective Evaluations and Comparisons for LLM Unlearning Methods](http://arxiv.org/abs/2406.09179v2)** | 2025-02-25 |  |
| **[Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM](http://arxiv.org/abs/2502.17763v1)** | 2025-02-25 |  |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v4)** | 2025-02-24 |  |
| **[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](http://arxiv.org/abs/2502.16730v1)** | 2025-02-23 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v2)** | 2025-02-23 |  |
| **[On Calibration of LLM-based Guard Models for Reliable Content Moderation](http://arxiv.org/abs/2410.10414v2)** | 2025-02-23 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025</p></details> |
| **[A generative approach to LLM harmfulness detection with special red flag tokens](http://arxiv.org/abs/2502.16366v1)** | 2025-02-22 | 13 pages, 6 figures |
| **[Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors](http://arxiv.org/abs/2410.19230v2)** | 2025-02-22 | 29 pages |
| **[Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging](http://arxiv.org/abs/2502.16094v1)** | 2025-02-22 | 17 pages, 3 figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Efficient Safety Retrofitting Against Jailbreaking for LLMs](http://arxiv.org/abs/2502.13603v2)** | 2025-02-25 |  |
| **[Towards Effective Evaluations and Comparisons for LLM Unlearning Methods](http://arxiv.org/abs/2406.09179v2)** | 2025-02-25 |  |
| **[Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM](http://arxiv.org/abs/2502.17763v1)** | 2025-02-25 |  |
| **[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](http://arxiv.org/abs/2502.17424v1)** | 2025-02-24 | 10 pages, 9 figures |
| **[PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs](http://arxiv.org/abs/2409.14866v4)** | 2025-02-24 |  |
| **[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](http://arxiv.org/abs/2502.16730v1)** | 2025-02-23 |  |
| **[Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond](http://arxiv.org/abs/2502.05374v2)** | 2025-02-23 |  |
| **[On Calibration of LLM-based Guard Models for Reliable Content Moderation](http://arxiv.org/abs/2410.10414v2)** | 2025-02-23 | <details><summary>Accep...</summary><p>Accepted to ICLR 2025</p></details> |
| **[A generative approach to LLM harmfulness detection with special red flag tokens](http://arxiv.org/abs/2502.16366v1)** | 2025-02-22 | 13 pages, 6 figures |
| **[Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors](http://arxiv.org/abs/2410.19230v2)** | 2025-02-22 | 29 pages |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models](http://arxiv.org/abs/2502.18290v1)** | 2025-02-25 |  |
| **[Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2502.01386v2)** | 2025-02-25 |  |
| **[CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense](http://arxiv.org/abs/2410.23091v7)** | 2025-02-25 | <details><summary>accep...</summary><p>accepted by NeurIPS 2024</p></details> |
| **[Examining the Threat Landscape: Foundation Models and Model Stealing](http://arxiv.org/abs/2502.18077v1)** | 2025-02-25 | <details><summary>Accep...</summary><p>Accepted to BMVC 2024</p></details> |
| **[Model-Free Adversarial Purification via Coarse-To-Fine Tensor Network Representation](http://arxiv.org/abs/2502.17972v1)** | 2025-02-25 |  |
| **[The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1](http://arxiv.org/abs/2502.12659v2)** | 2025-02-25 |  |
| **[VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution](http://arxiv.org/abs/2502.17880v1)** | 2025-02-25 |  |
| **[Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility](http://arxiv.org/abs/2502.17591v1)** | 2025-02-24 | <details><summary>ICLR'...</summary><p>ICLR'25 Poster. Project page and code is available at https://ppa-iclr2025.my.canva.site/</p></details> |
| **[The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence](http://arxiv.org/abs/2502.17420v1)** | 2025-02-24 |  |
| **[Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction](http://arxiv.org/abs/2502.17541v1)** | 2025-02-24 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models](http://arxiv.org/abs/2502.18290v1)** | 2025-02-25 |  |
| **[Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models](http://arxiv.org/abs/2502.01386v2)** | 2025-02-25 |  |
| **[CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense](http://arxiv.org/abs/2410.23091v7)** | 2025-02-25 | <details><summary>accep...</summary><p>accepted by NeurIPS 2024</p></details> |
| **[Examining the Threat Landscape: Foundation Models and Model Stealing](http://arxiv.org/abs/2502.18077v1)** | 2025-02-25 | <details><summary>Accep...</summary><p>Accepted to BMVC 2024</p></details> |
| **[Model-Free Adversarial Purification via Coarse-To-Fine Tensor Network Representation](http://arxiv.org/abs/2502.17972v1)** | 2025-02-25 |  |
| **[The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1](http://arxiv.org/abs/2502.12659v2)** | 2025-02-25 |  |
| **[VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution](http://arxiv.org/abs/2502.17880v1)** | 2025-02-25 |  |
| **[Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility](http://arxiv.org/abs/2502.17591v1)** | 2025-02-24 | <details><summary>ICLR'...</summary><p>ICLR'25 Poster. Project page and code is available at https://ppa-iclr2025.my.canva.site/</p></details> |
| **[The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence](http://arxiv.org/abs/2502.17420v1)** | 2025-02-24 |  |
| **[Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction](http://arxiv.org/abs/2502.17541v1)** | 2025-02-24 |  |

