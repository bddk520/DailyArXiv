---
title: Latest 15 Papers - May 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLMs unlock new paths to monetizing exploits](http://arxiv.org/abs/2505.11449v1)** | 2025-05-16 |  |
| **[CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](http://arxiv.org/abs/2505.11413v1)** | 2025-05-16 |  |
| **[Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](http://arxiv.org/abs/2501.02406v4)** | 2025-05-16 |  |
| **[On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks](http://arxiv.org/abs/2501.16466v3)** | 2025-05-16 | 18 pages, 15 figures |
| **[PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](http://arxiv.org/abs/2505.09921v2)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (main)</p></details> |
| **[LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](http://arxiv.org/abs/2505.10838v1)** | 2025-05-16 |  |
| **[Dark LLMs: The Growing Threat of Unaligned AI Models](http://arxiv.org/abs/2505.10066v1)** | 2025-05-15 |  |
| **[Adversarial Suffix Filtering: a Defense Pipeline for LLMs](http://arxiv.org/abs/2505.09602v1)** | 2025-05-14 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v2)** | 2025-05-14 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLMs unlock new paths to monetizing exploits](http://arxiv.org/abs/2505.11449v1)** | 2025-05-16 |  |
| **[CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](http://arxiv.org/abs/2505.11413v1)** | 2025-05-16 |  |
| **[Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](http://arxiv.org/abs/2501.02406v4)** | 2025-05-16 |  |
| **[On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks](http://arxiv.org/abs/2501.16466v3)** | 2025-05-16 | 18 pages, 15 figures |
| **[PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](http://arxiv.org/abs/2505.09921v2)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted to ACL 2025 (main)</p></details> |
| **[LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](http://arxiv.org/abs/2505.10838v1)** | 2025-05-16 |  |
| **[Dark LLMs: The Growing Threat of Unaligned AI Models](http://arxiv.org/abs/2505.10066v1)** | 2025-05-15 |  |
| **[Adversarial Suffix Filtering: a Defense Pipeline for LLMs](http://arxiv.org/abs/2505.09602v1)** | 2025-05-14 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v2)** | 2025-05-14 |  |
| **[Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](http://arxiv.org/abs/2505.04806v2)** | 2025-05-13 | 7 Pages, 6 Figures |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts](http://arxiv.org/abs/2503.16529v2)** | 2025-05-16 | <details><summary>21 pa...</summary><p>21 pages, 13 figures, 4 tables</p></details> |
| **[MPMA: Preference Manipulation Attack Against Model Context Protocol](http://arxiv.org/abs/2505.11154v1)** | 2025-05-16 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v4)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models](http://arxiv.org/abs/2505.10983v1)** | 2025-05-16 |  |
| **[AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models](http://arxiv.org/abs/2505.10846v1)** | 2025-05-16 | 9 pages |
| **[Safety in Large Reasoning Models: A Survey](http://arxiv.org/abs/2504.17704v2)** | 2025-05-16 |  |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v2)** | 2025-05-16 |  |
| **[Dynamics of Adversarial Attacks on Large Language Model-Based Search Engines](http://arxiv.org/abs/2501.00745v2)** | 2025-05-15 |  |
| **[Dark LLMs: The Growing Threat of Unaligned AI Models](http://arxiv.org/abs/2505.10066v1)** | 2025-05-15 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts](http://arxiv.org/abs/2503.16529v2)** | 2025-05-16 | <details><summary>21 pa...</summary><p>21 pages, 13 figures, 4 tables</p></details> |
| **[MPMA: Preference Manipulation Attack Against Model Context Protocol](http://arxiv.org/abs/2505.11154v1)** | 2025-05-16 |  |
| **[SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models](http://arxiv.org/abs/2504.04893v4)** | 2025-05-16 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop EVAL-FoMo-2</p></details> |
| **[GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models](http://arxiv.org/abs/2505.10983v1)** | 2025-05-16 |  |
| **[AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models](http://arxiv.org/abs/2505.10846v1)** | 2025-05-16 | 9 pages |
| **[Safety in Large Reasoning Models: A Survey](http://arxiv.org/abs/2504.17704v2)** | 2025-05-16 |  |
| **[SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](http://arxiv.org/abs/2505.07584v2)** | 2025-05-16 |  |
| **[Dynamics of Adversarial Attacks on Large Language Model-Based Search Engines](http://arxiv.org/abs/2501.00745v2)** | 2025-05-15 |  |
| **[Dark LLMs: The Growing Threat of Unaligned AI Models](http://arxiv.org/abs/2505.10066v1)** | 2025-05-15 |  |

