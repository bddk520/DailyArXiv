---
title: Latest 15 Papers - January 14, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## LLM AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations](https://arxiv.org/abs/2601.07835v1)** | 2026-01-12 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v3)** | 2026-01-12 |  |
| **[Memory Poisoning Attack and Defense on Memory Based LLM-Agents](https://arxiv.org/abs/2601.05504v2)** | 2026-01-12 |  |
| **[Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2601.07122v1)** | 2026-01-12 |  |
| **[NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144v2)** | 2026-01-11 |  |
| **[Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems](https://arxiv.org/abs/2601.07072v1)** | 2026-01-11 |  |
| **[Paraphrasing Adversarial Attack on LLM-as-a-Reviewer](https://arxiv.org/abs/2601.06884v1)** | 2026-01-11 |  |
| **[CHASE: LLM Agents for Dissecting Malicious PyPI Packages](https://arxiv.org/abs/2601.06838v1)** | 2026-01-11 | <details><summary>Accep...</summary><p>Accepted for publication and presented at the 2nd IEEE International Conference on AI-powered Software (AIware 2025). 10 pages, 3 figures</p></details> |
| **[BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents](https://arxiv.org/abs/2601.04566v2)** | 2026-01-11 |  |
| **[CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation](https://arxiv.org/abs/2601.06779v1)** | 2026-01-11 | 12 pages |

## LLM AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SecureCAI: Injection-Resilient LLM Assistants for Cybersecurity Operations](https://arxiv.org/abs/2601.07835v1)** | 2026-01-12 |  |
| **[Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs](https://arxiv.org/abs/2512.04668v3)** | 2026-01-12 |  |
| **[Memory Poisoning Attack and Defense on Memory Based LLM-Agents](https://arxiv.org/abs/2601.05504v2)** | 2026-01-12 |  |
| **[Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2601.07122v1)** | 2026-01-12 |  |
| **[NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144v2)** | 2026-01-11 |  |
| **[Overcoming the Retrieval Barrier: Indirect Prompt Injection in the Wild for LLM Systems](https://arxiv.org/abs/2601.07072v1)** | 2026-01-11 |  |
| **[Paraphrasing Adversarial Attack on LLM-as-a-Reviewer](https://arxiv.org/abs/2601.06884v1)** | 2026-01-11 |  |
| **[CHASE: LLM Agents for Dissecting Malicious PyPI Packages](https://arxiv.org/abs/2601.06838v1)** | 2026-01-11 | <details><summary>Accep...</summary><p>Accepted for publication and presented at the 2nd IEEE International Conference on AI-powered Software (AIware 2025). 10 pages, 3 figures</p></details> |
| **[BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents](https://arxiv.org/abs/2601.04566v2)** | 2026-01-11 |  |
| **[CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation](https://arxiv.org/abs/2601.06779v1)** | 2026-01-11 | 12 pages |

## large language model AND attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Measuring the Impact of Student Gaming Behaviors on Learner Modeling](https://arxiv.org/abs/2512.18659v3)** | 2026-01-12 | <details><summary>Full ...</summary><p>Full research paper accepted at Learning Analytics and Knowledge (LAK '26) conference, see https://doi.org/10.1145/3785022.3785036</p></details> |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](https://arxiv.org/abs/2510.05699v2)** | 2026-01-12 | <details><summary>To ap...</summary><p>To appear at USENIX Security Symposium 2026</p></details> |
| **[From static to adaptive: immune memory-based jailbreak detection for large language models](https://arxiv.org/abs/2512.03356v2)** | 2026-01-12 |  |
| **[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772v4)** | 2026-01-12 |  |
| **[A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291v1)** | 2026-01-12 |  |
| **[Safe-FedLLM: Delving into the Safety of Federated Large Language Models](https://arxiv.org/abs/2601.07177v1)** | 2026-01-12 |  |
| **[MacPrompt: Maraconic-guided Jailbreak against Text-to-Image Models](https://arxiv.org/abs/2601.07141v1)** | 2026-01-12 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses](https://arxiv.org/abs/2502.15567v2)** | 2026-01-11 |  |
| **[zkRansomware: Proof-of-Data Recoverability and Multi-round Game Theoretic Modeling of Ransomware Decisions](https://arxiv.org/abs/2601.06667v1)** | 2026-01-10 |  |
| **[A Bayesian Network-Driven Zero Trust Model for Cyber Risk Quantification in Small-Medium Businesses](https://arxiv.org/abs/2601.06553v1)** | 2026-01-10 |  |

## large language model AND Backdoor Attack
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Measuring the Impact of Student Gaming Behaviors on Learner Modeling](https://arxiv.org/abs/2512.18659v3)** | 2026-01-12 | <details><summary>Full ...</summary><p>Full research paper accepted at Learning Analytics and Knowledge (LAK '26) conference, see https://doi.org/10.1145/3785022.3785036</p></details> |
| **[Membership Inference Attacks on Tokenizers of Large Language Models](https://arxiv.org/abs/2510.05699v2)** | 2026-01-12 | <details><summary>To ap...</summary><p>To appear at USENIX Security Symposium 2026</p></details> |
| **[From static to adaptive: immune memory-based jailbreak detection for large language models](https://arxiv.org/abs/2512.03356v2)** | 2026-01-12 |  |
| **[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772v4)** | 2026-01-12 |  |
| **[A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291v1)** | 2026-01-12 |  |
| **[Safe-FedLLM: Delving into the Safety of Federated Large Language Models](https://arxiv.org/abs/2601.07177v1)** | 2026-01-12 |  |
| **[MacPrompt: Maraconic-guided Jailbreak against Text-to-Image Models](https://arxiv.org/abs/2601.07141v1)** | 2026-01-12 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses](https://arxiv.org/abs/2502.15567v2)** | 2026-01-11 |  |
| **[zkRansomware: Proof-of-Data Recoverability and Multi-round Game Theoretic Modeling of Ransomware Decisions](https://arxiv.org/abs/2601.06667v1)** | 2026-01-10 |  |
| **[A Bayesian Network-Driven Zero Trust Model for Cyber Risk Quantification in Small-Medium Businesses](https://arxiv.org/abs/2601.06553v1)** | 2026-01-10 |  |

